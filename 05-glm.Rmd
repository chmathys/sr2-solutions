# Generalized Linear Models

The fifth week covers [Chapter 10 (Big Entropy and the Generalized Linear Model)](https://bookdown.org/content/4857/big-entropy-and-the-generalized-linear-model.html), and [Chapter 11 (God Spiked the Integers)](https://bookdown.org/content/4857/god-spiked-the-integers.html).

## Lectures

Lecture 9:

```{r lecture-9, echo = FALSE, out.width = "100%"}
knitr::include_url("https://www.youtube.com/embed/nPi5yGbfxuo")
```

Lecture 10:

```{r lecture-10, echo = FALSE, out.width = "100%"}
knitr::include_url("https://www.youtube.com/embed/YrwL6t0kW2I")
```

## Exercises

### Chapter 10

Chapter 10 is a conceptual chapter, so there are no exercises to complete.

### Chapter 11

:::question
> **11E1.** If an event has probability 0.35, what are the log-odds of this event?
:::

The log-odds are given by the logit link:

$$
\log\frac{p}{1-p}
$$

In code:

```{r e11e1-1}
log(0.35 / (1 - 0.35))
```


:::question
> **11E2.** If an event has log-odds 3.2, what is the probability of this event?
:::

To convert from log-odds to probability, we use the inverse logit, which is given by:

$$
\frac{\exp(\alpha)}{\exp(\alpha) + 1}
$$
In code:

```{r e11e2-1}
exp(3.2) / (exp(3.2) + 1)
```


:::question
> **11E3.** Suppose that a coefficient in a logistic regression has value 1.7. What does this imply about the proportional change in odds of the outcome?
:::

We can calculate the proportional odds by exponentiating the coefficient.

```{r e11e3-1}
exp(1.7)
```

A proportional odds of about 5.5 means that each unit increase in the predictor multiplies the odds of the outcome occurring by 5.5.


:::question
> **11E4.** Why do Poisson regressions sometimes require the use of an *offset*? Provide an example.
:::

An offset is the duration that a count was accumulated during. If all of the observations were accumulated during the same observation periods, then an offset is not needed. However, if there are differences (e.g., some counts are weekly while others are daily), an offset is needed.

As an example, say you were modeling how many houses Realtor sells. If some Realtors provide you data with weekly counts of houses sold, and some provide monthly data, you will need an offset to account for the fact that we expect larger counts from longer periods of time.

:::question
> **11M1.** As explained in the chapter, binomial data can be organized in aggregated and disaggregated forms, without any impact on inference. But the likelihood of the data does change when the data are converted between the two formats. Can you explain why?
:::

The likelihood of the aggregated binomial includes a multiplicative term to account for all the different ways that we could get the observed number of counts. For example, say we saw 2 success in 5 trials. In aggregated form, the likelihood hood is:

$$
\frac{5!}{2!(5-2)!}p^2(1-p)^{5-2}
$$
The fraction out front is the multiplicative term, accounting for all the ways we could see 2 successes out of five trials. In the long disaggregated format, the likelihood would only be:

$$
p^2(1-p)^{5-2}
$$

This is because we know exactly how we got 2 out 5 from the series of 1s and 0s. Because there is no multiplicative factor the likelihoods will be different. However, because that multiplicative factor is not a function of $p$, the posterior distributions, and therefore the inferences, are unaffected.


:::question
> **11M2.** If a coefficient in a Poisson regression has value 1.7, what does this imply about the change in the outcome?
:::

There is no straightforward answer. Poisson models typically use the log link. Therefore, a change in the outcome resulting from a 1.7 unit change in the predictor depends on the values of the other parameters, and the scale of the predictor. The best we can do is calculate a proportional change in the odds. Doing that, this question is the same as **11E3.**, and a 1.7 unit change in the predictor results in 5.5 times increase in the odds.


:::question
> **11M3.** Explain why the logit link is appropriate for a binomial generalized linear model.
:::

In binomial models, we need to map the continuous values from the linear model to the probability space constrained between 0 and 1. The logit link is on possible way to do this. Other link function can accomplish the same thing (e.g., the probit link), but any function that will map continuous values to a [0,1] bounded space will do the trick.


:::question
> **11M4.** Explain why the log link is appropriate for a Poisson generalized linear model.
:::

Similar to the previous question, we now need a function that maps the continuous linear model to a strictly positive space. The log link accomplishes this. The inverse of the log link is the exponential, and any value that is exponentiated will be positive.


:::question
> **11M5.** What would it imply to use a logit link for the mean of a Poisson generalized linear model? Can you think of a real research problem for which this would make sense?
:::

A logit link would imply a model with a known maximum count. Normally, this value is 1, but it could be any arbitrary number such as, where $M$ is the maximum count:

$$
\begin{align}
  y_i &\sim \text{Poisson}(\mu_i) \\
  \log\frac{\mu_i}{M - \mu_i} &= \alpha + \beta x_i
\end{align}
$$
Usually, if there is a known maximum, it makes more sense to use a binomial model. However, if $M$ is very large such that you may never reach it, and the probability is low, this type of logit-Poisson could be used.


:::question
> **11M6.** State the constraints for which the binomial and Poisson distributions have maximum entropy. Are the constraints different at all for binomial and Poisson? Why or why not?
:::

The constraints for the binomial and Poisson are the same because the Poisson is the same as a binomial model where the number of trials is very large and the probability of observing the event is very low. The constraints are:

1. Discrete binary outcomes
2. Constant probability of the event across trials


:::question
> **11M7.** Use `quap` to construct a quadratic approximate posterior distribution for the chimpanzee model that includes a unique intercept for each action, `m11.4` (page 330). Compare the quadratic approximation to the posterior distribution produced instead from MCMC. Can you explain both the differences and the similarities between the approximate and the MCMC distributions? Relax the prior on the actor intercepts to Normal(0,10). Re-estimate the posterior using both `ulam` and `quap`. Do the difference increase or decrease? Why?
:::

We'll start by estimating `m11.4` with both `quap()` and `brm()`.

```{r e11m7-1}
data("chimpanzees")

chimp_dat <- chimpanzees %>% 
  mutate(treatment = 1 + prosoc_left + 2 * condition,
         treatment = factor(treatment),
         actor = factor(actor))

dat_list <- list(pulled_left = chimp_dat$pulled_left,
                 actor = as.integer(chimp_dat$actor),
                 treatment = as.integer(chimp_dat$treatment))

q11.4 <- quap(alist(pulled_left ~ dbinom(1, p),
                     logit(p) <- a[actor] + b[treatment],
                     a[actor] ~ dnorm(0, 1.5),
                     b[treatment] ~ dnorm(0, 0.5)),
               data = dat_list)

b11.4 <- brm(bf(pulled_left ~ a + b,
                a ~ 0 + actor,
                b ~ 0 + treatment,
                nl = TRUE), data = chimp_dat, family = bernoulli,
             prior = c(prior(normal(0, 1.5), class = b, nlpar = a),
                       prior(normal(0, 0.5), class = b, nlpar = b)),
             iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,
             file = here("fits", "chp11", "b11.4"))
```

Looking at the posterior distributions, the quadratic approximation and MCMC are very similar. The only parameter that shows a noticeable difference is Actor 2. Looking a little closer, we see that for Actor 2, MCMC results in a posterior shifted slightly to the right. This is because the MCMC posterior is slightly skewed, whereas the QUAP posterior is forced to be Gaussian. Therefore, more density is given to the lower tail and less to the upper tail than in the MCMC posterior.

```{r e11m7-2}
q_samp <- extract.samples(q11.4)

q_draws <- bind_cols(
  q_samp$a %>% 
    as_tibble(.name_repair = ~paste0("b_a_actor", 1:ncol(q_samp$a))) %>% 
    slice_sample(n = 8000) %>% 
    rowid_to_column(var = ".draw"),
  q_samp$b %>% 
    as_tibble(.name_repair = ~paste0("b_b_treatment", 1:ncol(q_samp$b))) %>% 
    slice_sample(n = 8000)
) %>% 
  pivot_longer(-.draw, names_to = "parameter", values_to = "QUAP")

b_draws <- as_draws_df(b11.4) %>% 
  as_tibble() %>% 
  select(-lp__) %>% 
  pivot_longer(cols = -c(.chain, .iteration, .draw),
               names_to = "parameter", values_to = "MCMC")

post_comp <- full_join(b_draws, q_draws, by = c(".draw", "parameter")) %>% 
  pivot_longer(cols = c(MCMC, QUAP), names_to = "type") %>% 
  mutate(parameter = str_replace_all(parameter, "b_[a|b]_([a-z]*)([0-9])",
                                     "\\1 \\2"),
         parameter = str_to_title(parameter))

post_comp %>% 
  ggplot(aes(x = value, color = type)) +
  facet_wrap(~parameter, nrow = 3) +
  geom_density(key_glyph = "timeseries") +
  scale_color_okabeito() +
  labs(x = "Value", y = "Density", color = NULL)
```

```{r e11m7-3}
post_comp %>% 
  filter(parameter == "Actor 2") %>% 
  ggplot(aes(x = value, color = type)) +
  geom_density(key_glyph = "timeseries") +
  scale_color_okabeito() +
  labs(x = "Actor 2", y = "Density", color = NULL)
```

Now let's modify our prior distributions. By loosening the prior, we're letting the actor intercepts take even more extreme values. This should have the effect of letting the posterior become even more skewed.

```{r e11m7-4}
q11.4_wide <- quap(alist(pulled_left ~ dbinom(1, p),
                         logit(p) <- a[actor] + b[treatment],
                         a[actor] ~ dnorm(0, 10),
                         b[treatment] ~ dnorm(0, 0.5)),
                   data = dat_list)

b11.4_wide <- brm(bf(pulled_left ~ a + b,
                     a ~ 0 + actor,
                     b ~ 0 + treatment,
                     nl = TRUE), data = chimp_dat, family = bernoulli,
                  prior = c(prior(normal(0, 10), class = b, nlpar = a),
                            prior(normal(0, 0.5), class = b, nlpar = b)),
                  iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,
                  file = here("fits", "chp11", "b11.4-wide"))
```

Let's look at Actor 2 again. We see that the MCMC posterior has much more skew now. However the QUAP posterior is still constrained to be Gaussian. In this case, QUAP is a pretty bad approximation of the true shape of the posterior.

```{r e11m7-5}
q_samp <- extract.samples(q11.4_wide)

q_draws <- bind_cols(
  q_samp$a %>% 
    as_tibble(.name_repair = ~paste0("b_a_actor", 1:ncol(q_samp$a))) %>% 
    slice_sample(n = 8000) %>% 
    rowid_to_column(var = ".draw"),
  q_samp$b %>% 
    as_tibble(.name_repair = ~paste0("b_b_treatment", 1:ncol(q_samp$b))) %>% 
    slice_sample(n = 8000)
) %>% 
  pivot_longer(-.draw, names_to = "parameter", values_to = "QUAP")

b_draws <- as_draws_df(b11.4_wide) %>% 
  as_tibble() %>% 
  select(-lp__) %>% 
  pivot_longer(cols = -c(.chain, .iteration, .draw),
               names_to = "parameter", values_to = "MCMC")

post_comp <- full_join(b_draws, q_draws, by = c(".draw", "parameter")) %>% 
  pivot_longer(cols = c(MCMC, QUAP), names_to = "type") %>% 
  mutate(parameter = str_replace_all(parameter, "b_[a|b]_([a-z]*)([0-9])",
                                     "\\1 \\2"),
         parameter = str_to_title(parameter))

post_comp %>% 
  filter(parameter == "Actor 2") %>% 
  ggplot(aes(x = value, color = type)) +
  geom_density(key_glyph = "timeseries") +
  scale_color_okabeito() +
  labs(x = "Actor 2", y = "Density", color = NULL)
```


:::question
> **11M8.** Revisit the `data(Kline)` islands example. This time drop Hawaii from the sample and refit the models. What changes do you observe?
:::

First the data and fitting the same model from the chapter.

```{r e11m8-1}
data("Kline")

kline_dat <- Kline %>% 
  mutate(P = standardize(log(population)))

no_hawaii <- filter(kline_dat, culture != "Hawaii")

b11.10b <- brm(bf(total_tools ~ a + b * P,
                  a ~ 0 + contact,
                  b ~ 0 + contact,
                  nl = TRUE), data = no_hawaii, family = poisson,
               prior = c(prior(normal(3, 0.5), class = b, nlpar = a),
                         prior(normal(0, 0.2), class = b, nlpar = b)),
               iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,
               file = here("fits", "chp11", "b11.10b"))

summary(b11.10b)
```

In this model without Hawaii, the slopes (`b_*` parameters in the summary) are nearly identical. This is different than the chapter, where high and low contact had different slopes. Thus, it appears that Hawaii was driving the difference in slopes.


:::question
> **11H1.** Use WAIC or PSIS to compare the chimpanzee model that includes a unique intercept for each actor, `m11.4` (page 330), to the simpler models fit in the same section. Interpret the results.
:::




:::question
> **11H2.** The data contained in `library(MASS);data(eagles)` are records of salmon pirating attempts by Bald Eagles in Washington State. See `?eagles` for details. While one eagle feeds, sometime another will swoop in and try to steal the salmon from it. Call the feeding eagle the "victim" and the thief the "pirate." Use the available data to build a binomial GLM of successful pirating attempts.

>  (a) Consider the following model:
  $$
  \begin{align}
    y_i &\sim \text{Binomial}(n_i,p_i) \\
    \text{logit}(p_i) &= \alpha + \beta_PP_i + \beta_VV_i + \beta_AA_i \\
    \alpha &\sim \text{Normal}(0, 1.5) \\
    \beta_P,\beta_V,\beta_A &\sim \text{Normal}(0, 0.5)
  \end{align}
  $$

> where $y$ is the number of successful attempts, $n$ is the total number of attempts, $P$ is a dummy variable indicating whether or not the pirate had large body size, $V$ is a dummy variable indicating whether or not the victim had large body size, and finally $A$ is a dummy variable indicating whether or not the pirate was an adult. Fit the model above to the `eagles` data, using both `quap` and `ulam`. Is the quadratic approximation okay?
:::




:::question
>  (b) Now interpret the estimates. If the quadratic approximation turned out okay, then it's okay to use the `quap` estimates. Otherwise stick to `ulam` estimates. Then plot the posterior predictions. Compute and display both (1) the predicted **probability** of success and its 89% interval for each row (*i*) in the data, as well as (2) the predicted success **count** and its 89% interval. What different information does each type of posterior prediction provide?
:::




:::question
>  (c) Now try to improve the model. Consider an interaction between the pirate's size and age (immature or adult). Compare this model to the previous one, using WAIC. Interpret.
:::




:::question
> **11H3.** The data contained in `data(salamanders)` are counts of salamanders (*Plethodon elongatus*) from 47 different 49-m^2^ plots in northern California. The column `SALAMAN` is the count in each plot, and the columns `PCTCOVER` and `FORESTAGE` are percent of ground cover and age of trees in the plot, respectively. You will model `SALAMAN` as a Poisson variable.

>  (a) Model the relationship between density and percent cover, using a log-link (same as the example in the book and lecture). Use weakly informative priors of your choosing. Check the quadratic approximation again, by comparing `quap` to `ulam`. Then plot the expected counts and their 89% interval against percent cover. In which ways does the model do a good job? A bad job?
:::




:::question
>  (b) Can you improve the model by using the other predictor, `FORESTAGE`? Try any models you think useful. Can you explain why `FORESTAGE` helps or does not help with prediction?
:::




:::question
> **11H4.** The data in `data(NWOGrants)` are outcomes for scientific funding applications for the Netherlands Organization for Scientific Research (NWO) from 2010--2012 [see @vanderlee for data and context]. These data have a very similar structure to the `UCBAdmit` data discussed in the chapter. I want you to consider a similar question: What are the total and indirect causal effects of gender on grant awards? Consider a mediation path (a pipe) through discipline. Draw the corresponding DAG and then use one or more binomial GLMs to answer the question. What is your causal interpretation? If NWO's goal is to equalize rates of funding between men and women, what type of intervention would be most effective?
:::




:::question
> **11H5.** Suppose that the NWO Grants sample has an unobserved confound that influences both choice of discipline and the probability of an award. One example of such a confound could be the career stage of each applicant. Suppose that in some disciplines, junior scholars apply for most of the grants. In other disciplines, scholars from all career stages compete. As a result, career stage influences discipline as well as the probability of being awarded a grant. Add these influences to your DAG from the previous problem. What happens now when you condition on discipline? Does it provide an un-confounded estimate of the direct path from gender to an award? Why or why not? Justify your answer with the backdoor criterion. If you have trouble thinking this though, try simulating fake data, assuming your DAG is true. Then analyze it using the model from the previous problem. What do you conclude? Is it possible for gender to have a real direct causal influence but for a regression conditioning on both gender and discipline to suggest zero influence?
:::




:::question
> **11H6.** The data in `data(Primates301)` are 301 primate species and associated measures. In this problem, you will consider how brain size is associated with social learning. There are three parts.

>  (a) Model the number of observations of `social_learning` for each species as a function of the log brain size. Use a Poisson distribution for the `social_learning` outcome variable. Interpret the resulting posterior.
:::


:::question
>  (b) Some species are studied much more than others. So the number of reported instances of `social_learning` could be a product of research effort. Use the `research_effort` variable, specifically its logarithm, as an additional predictor variable. Interpret the coefficient for log `research_effort`. How does this model differ from the previous one?
:::


:::question
>  (c) Draw a DAG to represent how you think the variables `social_learning`, `brain`, and `research_effort` interact. Justify the DAG with the measured associations in the two models above (and any other models you used).
:::


## Homework

:::question
> **1.** The data in `data(NWOGrants)` are outcomes for scientific funding applications for the Netherlands Organization for Scientific Research (NWO) from 2010--2012 [see @vanderlee]. These data have a very similar structure to the UCBAdmit data discussed in Chapter 11. Draw a DAG for this sample and then use one or more binomial GLMs to estimate the TOTAL causal effect of gender on grant awards.
:::

First, let's take a look at the data. As the question identified, this data is nearly identical to the `UCBAdmit` data, with the exception that department has been replaced with discipline.

```{r w5h1-1}
data("NWOGrants")

nwo_dat <- NWOGrants %>% 
  mutate(gender = factor(gender, levels = c("m", "f")))

nwo_dat
```

We'll denote gender as $G$, discipline as $D$, and award as $A$. Our DAG can then be defined as in the figure below. Gender influences both whether or not an award is given, as well as which discipline an individual might go into.

```{r w5h1-2, out.width = "40%", echo = FALSE}
library(ggdag)

nwo_dag <- dagitty("dag { G -> D -> A <- G }")
coordinates(nwo_dag) <- list(
  x = c(G = 1, D = 2, A = 3),
  y = c(G = 1, D = 2, A = 1)
)

tidy_dagitty(nwo_dag) %>% 
  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_text(color = "black", size = 10) +
  geom_dag_edges(edge_color = "black", edge_width = 2,
                 arrow_directed = grid::arrow(length = grid::unit(15, "pt"),
                                              type = "closed")) +
  theme_void()
```

For the total effect, we don't need to condition on any other variables. We can confirm this with {dagitty}.

```{r w5h1-3}
library(dagitty)

adjustmentSets(nwo_dag, exposure = "G", outcome = "A")
```

We can now fit our model.

```{r w5h1-4}
w5h1 <- brm(awards | trials(applications) ~ 0 + gender, data = nwo_dat,
            family = binomial,
            prior = prior(normal(0, 1.5), class = b),
            iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,
            file = here("fits", "hw5", "w5h1"))

summary(w5h1)
```

From the summary, it appears that females are less likely to get be awarded grants, but we need to compute the contrast to know for certain. The plot below shows the contrast for males compared to females. On average, males are favored by about 3 percentage points. The contrast is fairly reliably above 0, indicating some bias in favor of males.

```{r w5h1-5}
as_draws_df(w5h1) %>% 
  mutate(diff_male = inv_logit_scaled(b_genderm) - inv_logit_scaled(b_genderf)) %>% 
  ggplot(aes(x = diff_male)) +
  stat_halfeye(.width = c(0.67, 0.89, 0.97), fill = "#009FB7") +
  labs(x = "&beta;<sub>M</sub> &minus; &beta;<sub>F</sub>", y = "Density")
```


:::question
> **2.** Now estimate the DIRECT causal effect of gender on grant awards. Compute the average direct causal effect of gender, weighting each discipline in proportion to the number of applications in the sample. Refer to the marginal effect example in Lecture 9 for help.
:::

For the direct effect we need to condition on the discipline.

```{r w5h2-1}
adjustmentSets(nwo_dag, exposure = "G", outcome = "A", effect = "direct")
```

Let's fit the model, stratifying by both gender and discipline.

```{r w5h2-2}
w5h2 <- brm(bf(awards | trials(applications) ~ g + d + i,
               g ~ 0 + gender,
               d ~ 0 + discipline,
               i ~ 0 + gender:discipline,
               nl = TRUE), data = nwo_dat, family = binomial,
            prior = c(prior(normal(0, 1.5), nlpar = g),
                      prior(normal(0, 1.5), nlpar = d),
                      prior(normal(0, 1.5), nlpar = i)),
            iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,
            file = here("fits", "hw5", "w5h2"))

summary(w5h2)
```

Now let's compute the marginal effect. Overall, there is a slight bias toward males, who are on average about 1.5 percentage points more likely to be awarded a grant. The 89% interval is about &minus;0.12 to 0.12. Thus, overall, the advantages are relatively balanced, and after statistically removing the effect of discipline, there does not appear to be a strong effect of gender on the awarding of grants.

```{r w5h2-3, cache = TRUE}
apps_per_dept <- nwo_dat %>% 
  group_by(discipline) %>% 
  summarize(applications = sum(applications))

# simulate as if all applications are from males
male_dat <- apps_per_dept %>% 
  mutate(gender = "m") %>% 
  uncount(applications) %>% 
  mutate(applications = 1L)

# simulate as if all applications are from females
female_dat <- apps_per_dept %>% 
  mutate(gender = "f") %>% 
  uncount(applications) %>% 
  mutate(applications = 1L)

marg_eff <- bind_rows(add_epred_draws(male_dat, w5h2),
                      add_epred_draws(female_dat, w5h2)) %>% 
  pivot_wider(names_from = "gender", values_from = ".epred") %>% 
  mutate(diff = m - f)

mean_qi(marg_eff$diff, .width = c(0.67, 0.89, 0.97))

ggplot(marg_eff, aes(x = diff)) +
  stat_halfeye(.width = c(0.67, 0.89, 0.97), fill = "#009FB7") +
  geom_vline(xintercept = 0, linetype = "dashed") +
  labs(x = "Difference in Awards (Male - Female)", y = "Density")
```


:::question
> **3.** Considering the total effect (problem 1) and direct effect (problem 2) of gender, what causes contribute to the average difference between women and men in award rate in this sample? It is not necessary to say whether or not there is evidence of discrimination. Simply explain how the direct effects you have estimated make sense (or not) of the total effect.
:::

The results from the first two problems indicate that 1) total effect of gender is that females are disadvantaged, but also that 2) the direct effect is a balanced disadvantage to both males and females depending on the discipline. This is because, in this data, females tended to apply slightly more to disciplines with lower overall award rates.

The figure below shows, for each discipline, the proportion of female and male applications that were submitted. That is, of all applications submitted by females, just under 35% were submitted to the social sciences. Similarly, about 25% of male applications were to the social sciences. Thus, disciplines below the dashed line are those where a relatively larger proportion of females submitted applications. Finally, the size of the points represents the award rate for each discipline (i.e., granted awards out of total applications).

Overall we see that disciplines above the dashed line (i.e., those where males were relatively more likely to apply) tended to have higher award rates than those below the dashed line. Thus, because females were relatively more likely to apply to disciplines with lower award rates, females were less likely overall to be awarded a grant.

```{r w5h3-1}
nwo_dat %>% 
  group_by(discipline) %>% 
  summarize(f = sum(applications[which(gender == "f")]),
            m = sum(applications[which(gender == "m")]),
            total_apps = sum(applications),
            total_awards = sum(awards)) %>% 
  mutate(female_pct = f / sum(f),
         male_pct = m / sum(m),
         award_pct = total_awards / total_apps) %>% 
  ggplot(aes(x = female_pct, y = male_pct)) +
  geom_point(aes(size = award_pct, color = abs(female_pct - male_pct) > 0.05)) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
  geom_label_repel(data = ~filter(.x, abs(female_pct - male_pct) > 0.05),
                   aes(label = discipline),
                   max.overlaps = Inf, nudge_y = 0.03) +
  scale_size(breaks = seq(0.1, 0.3, by = 0.04)) +
  scale_color_manual(values = c("black", "#009FB7")) +
  guides(color = "none") +
  expand_limits(x = c(0, 0.35), y = c(0, 0.35)) +
  coord_equal() +
  labs(x = "Female Application Rate", y = "Male Application Rate",
       size = "Award Rate") +
  theme(legend.position = "right")
```



