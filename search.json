[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"project companion Richard McElreath’s Statistical Rethinking (2nd Edition) (McElreath, 2020), 2022 version accompanying course. 10 weeks, course (materials provided ), work exercises chapter covered week assigned homework problems. Like Solomon Kurz, take {tidyverse} (Wickham et al., 2019; Wickham, 2021) {brms} (Bürkner, 2017, 2018, 2021) approach solving problems. translation actual book text {tidyverse} {brms} style code, please check project, Statistical rethinking brms, ggplot2, tidyverse: Second edition.can purchase Statistical Rethinking: Bayesian Course R Stan (McElreath, 2020) CRC Press.","code":""},{"path":"index.html","id":"disclaimer","chapter":"Welcome","heading":"Disclaimer","text":"project work progress. ’d like follow along, can find GitHub repository . solutions checked anybody, undoubtedly errors. find , please contribute let know!several ways contribute. simple edits suggestions, can use “Edit page” link sidebar right screen. can also create fork repository submit pull request open issue.Please note project released Contributor Code Conduct. participating project agree abide terms.","code":""},{"path":"index.html","id":"license","chapter":"Welcome","heading":"License","text":"project licensed Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.","code":""},{"path":"index.html","id":"colophon","chapter":"Welcome","heading":"Colophon","text":"project built :","code":"\ndeps <- renv::dependencies() %>% \n  distinct(Package) %>% \n  arrange() %>% \n  pull()\n#> Finding R package dependencies ... [8/18] [9/18] [10/18] [11/18] [12/18] [13/18] [14/18] [15/18] [16/18] [17/18] [18/18] Done!\n\nsessioninfo::session_info(deps)\n#> ─ Session info ───────────────────────────────────────────────────────────────\n#>  setting  value\n#>  version  R version 4.1.2 (2021-11-01)\n#>  os       Ubuntu 20.04.3 LTS\n#>  system   x86_64, linux-gnu\n#>  ui       X11\n#>  language (EN)\n#>  collate  C.UTF-8\n#>  ctype    C.UTF-8\n#>  tz       UTC\n#>  date     2022-02-21\n#>  pandoc   2.14.2 @ /usr/bin/ (via rmarkdown)\n#> \n#> ─ Packages ───────────────────────────────────────────────────────────────────\n#>  ! package        * version    date (UTC) lib source\n#>  P abind            1.4-5      2016-07-21 [?] CRAN (R 4.1.2)\n#>  P arrayhelpers     1.1-0      2020-02-04 [?] CRAN (R 4.1.2)\n#>    askpass          1.1        2019-01-13 [1] CRAN (R 4.1.2)\n#>  P assertthat       0.2.1      2019-03-21 [?] CRAN (R 4.1.2)\n#>  P backports        1.4.1      2021-12-13 [?] CRAN (R 4.1.2)\n#>  P base64enc        0.1-3      2015-07-28 [?] CRAN (R 4.1.2)\n#>  P bayesplot        1.8.1      2021-06-14 [?] CRAN (R 4.1.2)\n#>    BH               1.78.0-0   2021-12-15 [1] CRAN (R 4.1.2)\n#>    bit              4.0.4      2020-08-04 [1] CRAN (R 4.1.2)\n#>    bit64            4.0.5      2020-08-30 [1] CRAN (R 4.1.2)\n#>    bitops           1.0-7      2021-04-24 [1] CRAN (R 4.1.2)\n#>    blob             1.2.2      2021-07-23 [1] CRAN (R 4.1.2)\n#>  P bookdown         0.24       2021-09-02 [?] CRAN (R 4.1.2)\n#>    boot             1.3-28     2021-05-03 [2] CRAN (R 4.1.2)\n#>    brew             1.0-6      2011-04-13 [1] CRAN (R 4.1.2)\n#>  P bridgesampling   1.1-2      2021-04-16 [?] CRAN (R 4.1.2)\n#>    brio             1.1.3      2021-11-30 [1] CRAN (R 4.1.2)\n#>  P brms           * 2.16.3     2021-11-22 [?] CRAN (R 4.1.2)\n#>  P Brobdingnag      1.2-6      2018-08-13 [?] CRAN (R 4.1.2)\n#>  P broom            0.7.12     2022-01-28 [?] CRAN (R 4.1.2)\n#>  P bslib            0.3.1      2021-10-06 [?] CRAN (R 4.1.2)\n#>  P cachem           1.0.6      2021-08-19 [?] CRAN (R 4.1.2)\n#>  P callr            3.7.0      2021-04-20 [?] CRAN (R 4.1.2)\n#>  P cellranger       1.1.0      2016-07-27 [?] CRAN (R 4.1.2)\n#>  P checkmate        2.0.0      2020-02-06 [?] CRAN (R 4.1.2)\n#>    class            7.3-19     2021-05-03 [2] CRAN (R 4.1.2)\n#>    classInt         0.4-3      2020-04-07 [1] CRAN (R 4.1.2)\n#>  P cli              3.1.1.9000 2022-02-21 [?] Github (r-lib/cli@a1d4569)\n#>    clipr            0.7.1      2020-10-08 [1] CRAN (R 4.1.2)\n#>  P cmdstanr       * 0.4.0.9001 2022-02-21 [?] Github (stan-dev/cmdstanr@a2a97d9)\n#>  P coda             0.19-4     2020-09-30 [?] CRAN (R 4.1.2)\n#>    codetools        0.2-18     2020-11-04 [2] CRAN (R 4.1.2)\n#>  P colorspace       2.0-2      2021-06-24 [?] CRAN (R 4.1.2)\n#>  P colourpicker     1.1.1      2021-10-04 [?] CRAN (R 4.1.2)\n#>    commonmark       1.7        2018-12-01 [1] CRAN (R 4.1.2)\n#>    cpp11            0.4.2      2021-11-30 [1] CRAN (R 4.1.2)\n#>  P crayon           1.4.2      2021-10-29 [?] CRAN (R 4.1.2)\n#>    credentials      1.3.2      2021-11-29 [1] CRAN (R 4.1.2)\n#>  P crosstalk        1.2.0      2021-11-04 [?] CRAN (R 4.1.2)\n#>  P curl             4.3.2      2021-06-23 [?] CRAN (R 4.1.2)\n#>  P dagitty        * 0.3-1      2021-01-21 [?] CRAN (R 4.1.2)\n#>    data.table       1.14.2     2021-09-27 [1] CRAN (R 4.1.2)\n#>  P DBI              1.1.2      2021-12-20 [?] CRAN (R 4.1.2)\n#>  P dbplyr           2.1.1      2021-04-06 [?] CRAN (R 4.1.2)\n#>    desc             1.4.0      2021-09-28 [1] CRAN (R 4.1.2)\n#>    devtools         2.4.3      2021-11-30 [1] CRAN (R 4.1.2)\n#>    diffobj          0.3.5      2021-10-05 [1] CRAN (R 4.1.2)\n#>  P digest           0.6.29     2021-12-01 [?] CRAN (R 4.1.2)\n#>  P distributional   0.3.0      2022-01-05 [?] CRAN (R 4.1.2)\n#>  P downlit          0.4.0.9000 2022-02-21 [?] Github (r-lib/downlit@4011b2f)\n#>  P dplyr          * 1.0.7      2021-06-18 [?] CRAN (R 4.1.2)\n#>  P DT               0.20       2021-11-15 [?] CRAN (R 4.1.2)\n#>    dtplyr           1.2.1      2022-01-19 [1] CRAN (R 4.1.2)\n#>  P dygraphs         1.1.1.6    2018-07-11 [?] CRAN (R 4.1.2)\n#>    e1071            1.7-9      2021-09-16 [1] CRAN (R 4.1.2)\n#>  P ellipsis         0.3.2      2021-04-29 [?] CRAN (R 4.1.2)\n#>    emo              0.0.0.9000 2022-02-21 [1] Github (hadley/emo@3f03b11)\n#>  P evaluate         0.14       2019-05-28 [?] CRAN (R 4.1.2)\n#>  P extrafont        0.17       2014-12-08 [?] CRAN (R 4.1.2)\n#>  P extrafontdb      1.0        2012-06-11 [?] CRAN (R 4.1.2)\n#>  P fansi            1.0.2      2022-01-14 [?] CRAN (R 4.1.2)\n#>  P farver           2.1.0      2021-02-28 [?] CRAN (R 4.1.2)\n#>  P fastmap          1.1.0      2021-01-25 [?] CRAN (R 4.1.2)\n#>    fontawesome      0.2.2      2021-07-02 [1] CRAN (R 4.1.2)\n#>  P forcats        * 0.5.1      2021-01-27 [?] CRAN (R 4.1.2)\n#>  P fs               1.5.2      2021-12-08 [?] CRAN (R 4.1.2)\n#>    future           1.23.0     2021-10-31 [1] CRAN (R 4.1.2)\n#>    gargle           1.2.0      2021-07-02 [1] CRAN (R 4.1.2)\n#>  P gdtools          0.2.3      2021-01-06 [?] CRAN (R 4.1.2)\n#>  P generics         0.1.1      2021-10-25 [?] CRAN (R 4.1.2)\n#>  P geomtextpath   * 0.1.0.9000 2022-02-21 [?] Github (allancameron/geomtextpath@0612ba8)\n#>    gert             1.5.0      2022-01-03 [1] CRAN (R 4.1.2)\n#>    gganimate        1.0.7      2020-10-15 [1] CRAN (R 4.1.2)\n#>    ggdag            0.2.4      2021-10-10 [1] CRAN (R 4.1.2)\n#>  P ggdist         * 3.0.1      2021-11-30 [?] CRAN (R 4.1.2)\n#>    ggforce          0.3.3      2021-03-05 [1] CRAN (R 4.1.2)\n#>    gghighlight      0.3.2      2021-06-05 [1] CRAN (R 4.1.2)\n#>  P ggplot2        * 3.3.5      2021-06-25 [?] CRAN (R 4.1.2)\n#>    ggraph           2.0.5      2021-02-23 [1] CRAN (R 4.1.2)\n#>  P ggrepel        * 0.9.1      2021-01-15 [?] CRAN (R 4.1.2)\n#>  P ggridges       * 0.5.3      2021-01-08 [?] CRAN (R 4.1.2)\n#>  P ggtext         * 0.1.1      2020-12-17 [?] CRAN (R 4.1.2)\n#>    gh               1.3.0      2021-04-30 [1] CRAN (R 4.1.2)\n#>    gifski           1.4.3-1    2021-05-02 [1] CRAN (R 4.1.2)\n#>    gitcreds         0.1.1      2020-12-04 [1] CRAN (R 4.1.2)\n#>    globals          0.14.0     2020-11-22 [1] CRAN (R 4.1.2)\n#>  P glue           * 1.6.1      2022-01-22 [?] CRAN (R 4.1.2)\n#>    googledrive      2.0.0      2021-07-08 [1] CRAN (R 4.1.2)\n#>    googlesheets4    1.0.0      2021-07-21 [1] CRAN (R 4.1.2)\n#>    graphlayouts     0.8.0      2022-01-03 [1] CRAN (R 4.1.2)\n#>  P gridExtra        2.3        2017-09-09 [?] CRAN (R 4.1.2)\n#>  P gridtext         0.1.4      2020-12-10 [?] CRAN (R 4.1.2)\n#>    gt               0.3.1      2021-08-07 [1] CRAN (R 4.1.2)\n#>  P gtable           0.3.0      2019-03-25 [?] CRAN (R 4.1.2)\n#>  P gtools           3.9.2      2021-06-06 [?] CRAN (R 4.1.2)\n#>  P haven            2.4.3      2021-08-04 [?] CRAN (R 4.1.2)\n#>    HDInterval       0.2.2      2020-05-23 [1] CRAN (R 4.1.2)\n#>  P here           * 1.0.1      2020-12-13 [?] CRAN (R 4.1.2)\n#>    highr            0.9        2021-04-16 [1] CRAN (R 4.1.2)\n#>  P hms              1.1.1      2021-09-26 [?] CRAN (R 4.1.2)\n#>  P hrbrthemes       0.8.0      2020-03-06 [?] CRAN (R 4.1.2)\n#>  P htmltools        0.5.2      2021-08-25 [?] CRAN (R 4.1.2)\n#>  P htmlwidgets      1.5.4      2021-09-08 [?] CRAN (R 4.1.2)\n#>  P httpuv           1.6.5      2022-01-05 [?] CRAN (R 4.1.2)\n#>  P httr             1.4.2      2020-07-20 [?] CRAN (R 4.1.2)\n#>    ids              1.0.1      2017-05-31 [1] CRAN (R 4.1.2)\n#>  P igraph           1.2.11     2022-01-04 [?] CRAN (R 4.1.2)\n#>    ini              0.3.1      2018-05-20 [1] CRAN (R 4.1.2)\n#>  P inline           0.3.19     2021-05-31 [?] CRAN (R 4.1.2)\n#>    isoband          0.2.5      2021-07-13 [1] CRAN (R 4.1.2)\n#>    jpeg             0.1-9      2021-07-24 [1] CRAN (R 4.1.2)\n#>  P jquerylib        0.1.4      2021-04-26 [?] CRAN (R 4.1.2)\n#>  P jsonlite         1.7.3      2022-01-17 [?] CRAN (R 4.1.2)\n#>    kableExtra       1.3.4      2021-02-20 [1] CRAN (R 4.1.2)\n#>    KernSmooth       2.23-20    2021-05-03 [2] CRAN (R 4.1.2)\n#>  P knitr            1.37       2021-12-16 [?] CRAN (R 4.1.2)\n#>    labeling         0.4.2      2020-10-20 [1] CRAN (R 4.1.2)\n#>  P later            1.3.0      2021-08-18 [?] CRAN (R 4.1.2)\n#>    lattice          0.20-45    2021-09-22 [2] CRAN (R 4.1.2)\n#>    lazyeval         0.2.2      2019-03-15 [1] CRAN (R 4.1.2)\n#>  P lifecycle        1.0.1.9000 2022-02-21 [?] Github (r-lib/lifecycle@56eafa4)\n#>    listenv          0.8.0      2019-12-05 [1] CRAN (R 4.1.2)\n#>  P loo            * 2.4.1      2020-12-09 [?] CRAN (R 4.1.2)\n#>    lpSolve          5.6.15     2020-01-24 [1] CRAN (R 4.1.2)\n#>  P lubridate        1.8.0      2021-10-07 [?] CRAN (R 4.1.2)\n#>  P magrittr         2.0.2      2022-01-26 [?] CRAN (R 4.1.2)\n#>  P markdown         1.1        2019-08-07 [?] CRAN (R 4.1.2)\n#>    MASS             7.3-54     2021-05-03 [2] CRAN (R 4.1.2)\n#>    Matrix           1.3-4      2021-06-01 [2] CRAN (R 4.1.2)\n#>  P matrixStats      0.61.0     2021-09-17 [?] CRAN (R 4.1.2)\n#>  P memoise          2.0.1      2021-11-26 [?] CRAN (R 4.1.2)\n#>    mgcv             1.8-38     2021-10-06 [2] CRAN (R 4.1.2)\n#>  P mime             0.12       2021-09-28 [?] CRAN (R 4.1.2)\n#>  P miniUI           0.1.1.1    2018-05-18 [?] CRAN (R 4.1.2)\n#>  P modelr           0.1.8      2020-05-19 [?] CRAN (R 4.1.2)\n#>  P munsell          0.5.0      2018-06-12 [?] CRAN (R 4.1.2)\n#>  P mvtnorm          1.1-3      2021-10-08 [?] CRAN (R 4.1.2)\n#>    nleqslv          3.3.2      2018-05-17 [1] CRAN (R 4.1.2)\n#>    nlme             3.1-153    2021-09-07 [2] CRAN (R 4.1.2)\n#>    numDeriv         2016.8-1.1 2019-06-06 [1] CRAN (R 4.1.2)\n#>    officedown       0.2.3      2021-11-16 [1] CRAN (R 4.1.2)\n#>    officer          0.4.1      2021-11-14 [1] CRAN (R 4.1.2)\n#>    openssl          1.4.6      2021-12-19 [1] CRAN (R 4.1.2)\n#>    packrat          0.7.0      2021-08-20 [1] CRAN (R 4.1.2)\n#>    parallelly       1.30.0     2021-12-17 [1] CRAN (R 4.1.2)\n#>    patchwork        1.1.1      2020-12-17 [1] CRAN (R 4.1.2)\n#>  P pillar           1.6.5      2022-01-25 [?] CRAN (R 4.1.2)\n#>  P pkgbuild         1.3.1      2021-12-20 [?] CRAN (R 4.1.2)\n#>  P pkgconfig        2.0.3      2019-09-22 [?] CRAN (R 4.1.2)\n#>    pkgload          1.2.4      2021-11-30 [1] CRAN (R 4.1.2)\n#>  P plyr             1.8.6      2020-03-03 [?] CRAN (R 4.1.2)\n#>    png              0.1-7      2013-12-03 [1] CRAN (R 4.1.2)\n#>    polyclip         1.10-0     2019-03-14 [1] CRAN (R 4.1.2)\n#>  P posterior        1.2.0      2022-01-05 [?] CRAN (R 4.1.2)\n#>    praise           1.0.0      2015-08-11 [1] CRAN (R 4.1.2)\n#>  P prettyunits      1.1.1      2020-01-24 [?] CRAN (R 4.1.2)\n#>  P processx         3.5.2      2021-04-30 [?] CRAN (R 4.1.2)\n#>    progress         1.2.2      2019-05-16 [1] CRAN (R 4.1.2)\n#>  P promises         1.2.0.1    2021-02-11 [?] CRAN (R 4.1.2)\n#>    prompt           1.0.1      2022-02-21 [1] Github (gaborcsardi/prompt@7ef0f2e)\n#>    proxy            0.4-26     2021-06-07 [1] CRAN (R 4.1.2)\n#>  P ps               1.6.0      2021-02-28 [?] CRAN (R 4.1.2)\n#>  P purrr          * 0.3.4      2020-04-17 [?] CRAN (R 4.1.2)\n#>  R R                <NA>       <NA>       [?] <NA>\n#>  P R6               2.5.1      2021-08-19 [?] CRAN (R 4.1.2)\n#>  P ragg             1.2.1      2021-12-06 [?] CRAN (R 4.1.2)\n#>    rappdirs         0.3.3      2021-01-31 [1] CRAN (R 4.1.2)\n#>  P ratlas           0.0.0.9000 2022-02-21 [?] Github (atlas-aai/ratlas@ebb795b)\n#>    rcmdcheck        1.4.0      2021-09-27 [1] CRAN (R 4.1.2)\n#>    RColorBrewer     1.1-2      2014-12-07 [1] CRAN (R 4.1.2)\n#>  P Rcpp           * 1.0.8      2022-01-13 [?] CRAN (R 4.1.2)\n#>    RcppArmadillo    0.10.8.1.0 2022-01-24 [1] CRAN (R 4.1.2)\n#>    RcppEigen        0.3.3.9.1  2020-12-17 [1] CRAN (R 4.1.2)\n#>  P RcppParallel     5.1.5      2022-01-05 [?] CRAN (R 4.1.2)\n#>    RCurl            1.98-1.5   2021-09-17 [1] CRAN (R 4.1.2)\n#>  P readr          * 2.1.1      2021-11-30 [?] CRAN (R 4.1.2)\n#>  P readxl           1.3.1      2019-03-13 [?] CRAN (R 4.1.2)\n#>    rematch          1.0.1      2016-04-21 [1] CRAN (R 4.1.2)\n#>    rematch2         2.1.2      2020-05-01 [1] CRAN (R 4.1.2)\n#>    remotes          2.4.2      2021-11-30 [1] CRAN (R 4.1.2)\n#>    renv             0.15.2     2022-01-24 [1] CRAN (R 4.1.2)\n#>  P reprex           2.0.1      2021-08-05 [?] CRAN (R 4.1.2)\n#>  P reshape2         1.4.4      2020-04-09 [?] CRAN (R 4.1.2)\n#>  P rethinking     * 2.21       2022-02-21 [?] Github (rmcelreath/rethinking@783d111)\n#>    rJava            1.0-6      2021-12-10 [1] CRAN (R 4.1.2)\n#>  P rlang            1.0.0      2022-01-26 [?] CRAN (R 4.1.2)\n#>  P rmarkdown        2.11       2021-09-14 [?] CRAN (R 4.1.2)\n#>    roxygen2         7.1.2      2021-09-08 [1] CRAN (R 4.1.2)\n#>  P rprojroot        2.0.2      2020-11-15 [?] CRAN (R 4.1.2)\n#>  P rsconnect        0.8.25     2021-11-19 [?] CRAN (R 4.1.2)\n#>  P rstan          * 2.21.3     2021-12-19 [?] CRAN (R 4.1.2)\n#>  P rstantools       2.1.1      2020-07-06 [?] CRAN (R 4.1.2)\n#>    rstudioapi       0.13       2020-11-12 [1] CRAN (R 4.1.2)\n#>  P Rttf2pt1         1.3.9      2021-07-22 [?] CRAN (R 4.1.2)\n#>    rversions        2.1.1      2021-05-31 [1] CRAN (R 4.1.2)\n#>  P rvest            1.0.2      2021-10-16 [?] CRAN (R 4.1.2)\n#>    rvg              0.2.5      2020-06-30 [1] CRAN (R 4.1.2)\n#>    s2               1.0.7      2021-09-28 [1] CRAN (R 4.1.2)\n#>  P sass             0.4.0.9000 2022-02-21 [?] Github (rstudio/sass@f7a9540)\n#>  P scales           1.1.1      2020-05-11 [?] CRAN (R 4.1.2)\n#>    selectr          0.4-2      2019-11-20 [1] CRAN (R 4.1.2)\n#>    servr            0.24       2021-11-16 [1] CRAN (R 4.1.2)\n#>  P sessioninfo      1.2.2      2021-12-06 [?] CRAN (R 4.1.2)\n#>    sf               1.0-6      2022-02-04 [1] CRAN (R 4.1.2)\n#>  P shape            1.4.6      2021-05-19 [?] CRAN (R 4.1.2)\n#>  P shiny            1.7.1      2021-10-02 [?] CRAN (R 4.1.2)\n#>  P shinyjs          2.1.0      2021-12-23 [?] CRAN (R 4.1.2)\n#>  P shinystan        2.5.0      2018-05-01 [?] CRAN (R 4.1.2)\n#>  P shinythemes      1.2.0      2021-01-25 [?] CRAN (R 4.1.2)\n#>    sourcetools      0.1.7      2018-04-25 [1] CRAN (R 4.1.2)\n#>  P StanHeaders    * 2.21.0-7   2020-12-17 [?] CRAN (R 4.1.2)\n#>    staplr           3.1.1      2021-01-11 [1] CRAN (R 4.1.2)\n#>  P stringi          1.7.6      2021-11-29 [?] CRAN (R 4.1.2)\n#>  P stringr        * 1.4.0      2019-02-10 [?] CRAN (R 4.1.2)\n#>    svglite          2.0.0      2021-02-20 [1] CRAN (R 4.1.2)\n#>  P svUnit           1.0.6      2021-04-19 [?] CRAN (R 4.1.2)\n#>    sys              3.4        2020-07-23 [1] CRAN (R 4.1.2)\n#>  P systemfonts      1.0.3      2021-10-13 [?] CRAN (R 4.1.2)\n#>  P tensorA          0.36.2     2020-11-19 [?] CRAN (R 4.1.2)\n#>    testthat         3.1.2      2022-01-20 [1] CRAN (R 4.1.2)\n#>  P textshaping      0.3.6      2021-10-13 [?] CRAN (R 4.1.2)\n#>  P threejs          0.3.3      2020-01-21 [?] CRAN (R 4.1.2)\n#>  P tibble         * 3.1.6      2021-11-07 [?] CRAN (R 4.1.2)\n#>  P tidybayes      * 3.0.2      2022-01-05 [?] CRAN (R 4.1.2)\n#>    tidygraph        1.2.0      2020-05-12 [1] CRAN (R 4.1.2)\n#>  P tidyr          * 1.1.4      2021-09-27 [?] CRAN (R 4.1.2)\n#>  P tidyselect       1.1.1      2021-04-30 [?] CRAN (R 4.1.2)\n#>  P tidyverse      * 1.3.1      2021-04-15 [?] CRAN (R 4.1.2)\n#>    tinytex          0.36       2021-12-19 [1] CRAN (R 4.1.2)\n#>    transformr       0.1.3      2020-07-05 [1] CRAN (R 4.1.2)\n#>    tweenr           1.0.2      2021-03-23 [1] CRAN (R 4.1.2)\n#>  P tzdb             0.2.0      2021-10-27 [?] CRAN (R 4.1.2)\n#>    units            0.7-2      2021-06-08 [1] CRAN (R 4.1.2)\n#>    usethis          2.1.5      2021-12-09 [1] CRAN (R 4.1.2)\n#>  P utf8             1.2.2      2021-07-24 [?] CRAN (R 4.1.2)\n#>    uuid             1.0-3      2021-11-01 [1] CRAN (R 4.1.2)\n#>  P V8               4.0.0      2021-12-23 [?] CRAN (R 4.1.2)\n#>  P vctrs            0.3.8      2021-04-29 [?] CRAN (R 4.1.2)\n#>    viridis          0.6.2      2021-10-13 [1] CRAN (R 4.1.2)\n#>    viridisLite      0.4.0      2021-04-13 [1] CRAN (R 4.1.2)\n#>    vroom            1.5.7      2021-11-30 [1] CRAN (R 4.1.2)\n#>    waldo            0.3.1      2021-09-14 [1] CRAN (R 4.1.2)\n#>    webshot          0.5.2      2019-11-22 [1] CRAN (R 4.1.2)\n#>    whisker          0.4        2019-08-28 [1] CRAN (R 4.1.2)\n#>  P withr            2.4.3      2021-11-30 [?] CRAN (R 4.1.2)\n#>  P wjake          * 0.1.0      2022-02-21 [?] Github (wjakethompson/wjake@d3f00de)\n#>    wk               0.6.0      2022-01-03 [1] CRAN (R 4.1.2)\n#>    xaringan         0.22       2021-06-23 [1] CRAN (R 4.1.2)\n#>  P xfun             0.29       2021-12-14 [?] CRAN (R 4.1.2)\n#>    XML              3.99-0.8   2021-09-17 [1] CRAN (R 4.1.2)\n#>  P xml2             1.3.3      2021-11-30 [?] CRAN (R 4.1.2)\n#>    xopen            1.0.0      2018-09-17 [1] CRAN (R 4.1.2)\n#>  P xtable           1.8-4      2019-04-21 [?] CRAN (R 4.1.2)\n#>  P xts              0.12.1     2020-09-09 [?] CRAN (R 4.1.2)\n#>  P yaml             2.2.2      2022-01-25 [?] CRAN (R 4.1.2)\n#>    zip              2.2.0      2021-05-31 [1] CRAN (R 4.1.2)\n#>  P zoo              1.8-9      2021-03-09 [?] CRAN (R 4.1.2)\n#> \n#>  [1] /home/runner/.cache/R/renv/library/sr2-solutions-9e1c7ff5/R-4.1/x86_64-pc-linux-gnu\n#>  [2] /opt/R/4.1.2/lib/R/library\n#> \n#>  P ── Loaded and on-disk path mismatch.\n#>  R ── Package was removed from disk.\n#> \n#> ──────────────────────────────────────────────────────────────────────────────"},{"path":"bayesian-inference.html","id":"bayesian-inference","chapter":"Week 1: Bayesian Inference","heading":"Week 1: Bayesian Inference","text":"first week covers Chapter 1 (Golem Prague), Chapter 2 (Small Worlds Large Worlds), Chapter 3 (Sampling Imaginary).","code":""},{"path":"bayesian-inference.html","id":"lectures","chapter":"Week 1: Bayesian Inference","heading":"1.1 Lectures","text":"Lecture 1:Lecture 2:","code":""},{"path":"bayesian-inference.html","id":"exercises","chapter":"Week 1: Bayesian Inference","heading":"1.2 Exercises","text":"","code":""},{"path":"bayesian-inference.html","id":"chapter-1","chapter":"Week 1: Bayesian Inference","heading":"1.2.1 Chapter 1","text":"exercises Chapter 1.","code":""},{"path":"bayesian-inference.html","id":"chapter-2","chapter":"Week 1: Bayesian Inference","heading":"1.2.2 Chapter 2","text":"2E1. expressions correspond statement: probability rain Monday?\n(1) Pr(rain)\n(2) Pr(rain|Monday)\n(3) Pr(Monday|rain)\n(4) Pr(rain, Monday) / Pr(Monday)take question mean probability rain given Monday. means (2) (4) correct.2E2. following statements corresponds expression: Pr(Monday|rain)?\n(1) probability rain Monday.\n(2) probability rain, given Monday.\n(3) probability Monday, given raining.\n(4) probability Monday raining.answer (3) corresponds expression Pr(Monday|rain).2E3. following expressions correspond statement: probability Monday, given raining?\n(1) Pr(Monday|rain)\n(2) Pr(rain|Monday)\n(3) Pr(rain|Monday) Pr(Monday)\n(4) Pr(rain|Monday) Pr(Monday) / Pr(rain)\n(5) Pr(Monday|rain) Pr(rain) / Pr(Monday)two correct answers. Answer option (1) standard notation conditional probability. Answer option (4) equivalent, Bayes’ Theorem.2E4. Bayesian statistician Bruno de Finetti (1906–1985) began 1973 book probability theory dedication: “PROBABILITY EXIST.” capitals appeared original, imagine de Finetti wanted us shout statement. meant probability device describing uncertainty perspective observer limited knowledge; objective reality. Discuss globe tossing example chapter, light statement. mean say “probability water 0.7”?idea probability subjective perception likelihood something happen. globe tossing example, result always either “land” “water” (.e., 0 1). toss globe, don’t know result , know always “land” “water.” express uncertainty outcome, use probability. know water likely land, may say probability “water” 0.7; however, ’ll never actually observe result 0.7 waters, observe probability. ever observe two results “land” “water.”2M1. Recall globe tossing model chapter. Compute plot grid approximate posterior distribution following sets observations. case, assume uniform prior p.\n(1) W, W, W\n(2) W, W, W, L\n(3) L, W, W, L, W, W, W2M2. Now assume prior p equal zero p < 0.5 positive constant p ≥ 0.5. compute plot grid approximate posterior distribution sets observations problem just .problem can use code , just altering prior defined.2M3. Suppose two globes, one Earth one Mars. Earth globe 70% covered water. Mars globe 100% land. suppose one globes—don’t know —tossed air produced “land” observatiion. Assume globe equally likely tossed. Show posterior probability globe Earth, conditional seeing “land” (Pr(Earth|land)), 0.23.2M4. Suppose deck three cards. card two sides, side either black white. One card two black sides. second card one black one white side. third card two white sides. Now suppose three cards placed bag shuffled. Someone reaches bag pulls card places flat table. black side shown facing , don’t know color side facing . Show probability side also black 2/3. Use counting method (Section 2 chapter) approach problem. means counting ways card produce observed data (black side faceing table).2M5. Now suppose four cards: B/B, B/W, W/W, another B/B. suppose card drawn bag black side appears face . calculate probability side black.2M6. Imagine black ink heavy, cards black sides heavier cards white sides. result, ’s less likely card black sides pulled bag. assume three cards: B/B, B/W, W/W. experimenting number times, conclude every way pull B/B card bag, 2 ways pull B/W card 3 ways pull W/W card. suppose card pulled black side appears face . Show probability side black now 0.5. Use counting method, .2M7. Assume original card problem, single card showing black side face . looking side, draw another card bag lay face table. face shown new card white. Show probability first card, one showing black side, black side now 0.75. Use counting method, can. Hint: Treat like sequence globe tosses, countng ways see observation, possiible first card.2H1. Suppose two species panda bear. equally common wild live sample places. look exactly alike eat food, yet genetic assay capable telling apart. differ however family sizes. Species gives birth twins 10% time, otherwise birthing single infant. Species births twins 20% time, ottherwise birthing singleton infants. Assume numbers known certainty, many years field research.\nNow suppose managing captive panda breeding program. newe female panda unknown species, just given birth twins. probability next birth also twins?2H2. Recall facts problem . Now compute probability panda species , asssuming observed first birth twins.2H3. Continuing previous problem, suppose panda mother second birth twins, singleton infant. Compute posterior probability panda species .2H4. common boast Bayesian statisticians Bayesian inference makes easy use data, even data different types.\nsuppose now veterinarian comes along new genetic test claims can identify species mother panda. test, like tests, imperfect. information test:probability correctly identifies species panda 0.8.probability correctly identifies species B panda 0.65.vet administers test panda tells test positive species . First ignore previous information births compute posterior probability panda species . redo calculation, now using birth data well.","code":"\nlibrary(tidyverse)\n\ndist <- tibble(p_grid = seq(from = 0, to = 1, length.out = 20),\n               prior = rep(1, times = 20)) %>%\n  mutate(likelihood_1 = dbinom(3, size = 3, prob = p_grid),\n         likelihood_2 = dbinom(3, size = 4, prob = p_grid),\n         likelihood_3 = dbinom(5, size = 7, prob = p_grid),\n         across(starts_with(\"likelihood\"), ~ .x * prior),\n         across(starts_with(\"likelihood\"), ~ .x / sum(.x))) %>%\n  pivot_longer(cols = starts_with(\"likelihood\"), names_to = \"pattern\",\n               values_to = \"posterior\") %>%\n  separate(pattern, c(NA, \"pattern\"), sep = \"_\", convert = TRUE) %>%\n  mutate(obs = case_when(pattern == 1L ~ \"W, W, W\",\n                         pattern == 2L ~ \"W, W, W, L\",\n                         pattern == 3L ~ \"L, W, W, L, W, W, W\"))\n\nggplot(dist, aes(x = p_grid, y = posterior)) +\n  facet_wrap(vars(fct_inorder(obs)), nrow = 1) +\n  geom_line() +\n  geom_point() +\n  labs(x = \"Proportion Water (p)\", y = \"Posterior Density\")\ndist <- tibble(p_grid = seq(from = 0, to = 1, length.out = 20)) %>%\n  mutate(prior = case_when(p_grid < 0.5 ~ 0L,\n                           TRUE ~ 1L),\n         likelihood_1 = dbinom(3, size = 3, prob = p_grid),\n         likelihood_2 = dbinom(3, size = 4, prob = p_grid),\n         likelihood_3 = dbinom(5, size = 7, prob = p_grid),\n         across(starts_with(\"likelihood\"), ~ .x * prior),\n         across(starts_with(\"likelihood\"), ~ .x / sum(.x))) %>%\n  pivot_longer(cols = starts_with(\"likelihood\"), names_to = \"pattern\",\n               values_to = \"posterior\") %>%\n  separate(pattern, c(NA, \"pattern\"), sep = \"_\", convert = TRUE) %>%\n  mutate(obs = case_when(pattern == 1L ~ \"W, W, W\",\n                         pattern == 2L ~ \"W, W, W, L\",\n                         pattern == 3L ~ \"L, W, W, L, W, W, W\"))\n\nggplot(dist, aes(x = p_grid, y = posterior)) +\n  facet_wrap(vars(fct_inorder(obs)), nrow = 1) +\n  geom_line() +\n  geom_point() +\n  labs(x = \"Proportion Water (p)\", y = \"Posterior Density\")\n# probability of land, given Earth\np_le <- 0.3\n\n# probability of land, given Mars\np_lm <- 1.0\n\n# probability of Earth\np_e <- 0.5\n\n# probability of land\np_l <- (p_e * p_le) + ((1 - p_e) * p_lm)\n\n# probability of Earth, given land (using Bayes' Theorem)\np_el <- (p_le * p_e) / p_l\np_el\n#> [1] 0.231\ncard_bb_likelihood <- 2\ncard_bw_likelihood <- 1\ncard_ww_likelihood <- 0\n\nlikelihood <- c(card_bb_likelihood, card_bw_likelihood, card_ww_likelihood)\nprior <- c(1, 1, 1)\nposterior <- likelihood * prior\nposterior <- posterior / sum(posterior)\n\nposterior[1]\n#> [1] 0.667\ncard_bb_likelihood <- 2\ncard_bw_likelihood <- 1\ncard_ww_likelihood <- 0\n\nlikelihood <- c(card_bb_likelihood, card_bw_likelihood, card_ww_likelihood,\n                card_bb_likelihood)\nprior <- c(1, 1, 1, 1)\nposterior <- likelihood * prior\nposterior <- posterior / sum(posterior)\n\nposterior[1] + posterior[4]\n#> [1] 0.8\ncard_bb_likelihood <- 2\ncard_bw_likelihood <- 1\ncard_ww_likelihood <- 0\n\nlikelihood <- c(card_bb_likelihood, card_bw_likelihood, card_ww_likelihood)\nprior <- c(1, 2, 3)\nposterior <- likelihood * prior\nposterior <- posterior / sum(posterior)\n\nposterior[1]\n#> [1] 0.5\n# 2 choices for first card, with 3 options for second card: 2 W/W + 1 W/B\ncard_bb_likelihood <- 2 * 3 \ncard_wb_likelihood <- 1 * 2 \ncard_ww_likelihood <- 0\n\nlikelihood <- c(card_bb_likelihood, card_wb_likelihood, card_ww_likelihood)\nprior <- c(1,1,1)\nposterior <- prior * likelihood\nposterior <- posterior / sum(posterior)\n\nposterior[1]\n#> [1] 0.75\n# After first birth, likelihood of species A and B is equal to the rate the\n# species give birth to twins\na_likelihood <- 0.1\nb_likelihood <- 0.2\n\n# Next calculate the posterior probability that the panda belongs to each\n# species, assume species are equally likely\nlikelihood <- c(a_likelihood, b_likelihood)\nprior <- c(1, 1) \nposterior <- likelihood * prior\nposterior <- posterior / sum(posterior)\nposterior\n#> [1] 0.333 0.667\n\n# The probability the next birth is twins is the probability the panda belongs\n# to each species times the likelihood each species gives birth to twins\n(posterior[1] * a_likelihood) + (posterior[2] * b_likelihood)\n#> [1] 0.167\n# probability of species A\np_a <- 0.5\n\n# probability of twins, given species A\np_ta <- 0.1\n\n# probability of twins, given species B\np_tb <- 0.2\n\n# probability of twins\np_t <- (p_a * p_ta) + ((1 - p_a) * p_tb)\n\n# probability of species A, given twins (using Bayes' Theorem)\n# (note this is equivalent to `posterior[1]` above)\np_at <- (p_ta * p_a) / p_t\np_at\n#> [1] 0.333\n# likelihood for each species is Pr(twins) * Pr(singleton)\na_likelihood <- 0.1 * (1 - 0.1)\nb_likelihood <- 0.2 * (1 - 0.2)\n\n# compute posterior probabilities\nlikelihood <- c(a_likelihood, b_likelihood)\nprior <- c(1, 1)\nposterior <- likelihood * prior\nposterior <- posterior / sum(posterior)\n\nposterior[1]\n#> [1] 0.36\n# use Bayes' Theorem to determine the probability of species A, given a positive\n# test\np_ap <- (0.8 * 0.5) / ((0.5 * 0.8) + (0.5 * 0.35))\np_ap\n#> [1] 0.696\n\n\n# Now include test data with observed births\n# likelihood for each species is Pr(twins) * Pr(singleton)\na_likelihood <- 0.1 * (1 - 0.1)\nb_likelihood <- 0.2 * (1 - 0.2)\n\n# compute posterior probabilities, using test result as prior\nlikelihood <- c(a_likelihood, b_likelihood)\nprior <- c(p_ap, (1 - p_ap))\nposterior <- likelihood * prior\nposterior <- posterior / sum(posterior)\n\nposterior[1]\n#> [1] 0.563"},{"path":"bayesian-inference.html","id":"chapter-3","chapter":"Week 1: Bayesian Inference","heading":"1.2.3 Chapter 3","text":"Easy. Easy problems use sample posterior distribution globe tossing example. code give specific set samples, can check answers exactly.Use values samples answer questions follow.3E1. much posterior probability lies p = 0.2?3E2. much posterior probability lies p = 0.8?3E3. much posterior probability lies p = 0.2 p = 0.8?3E4. 20% posterior probability lies value p?3E5. 20% posterior probability lies value p?3E6. values p contain narrowest interval equal 66% posterior probability?3E7. values p contain 66% posterior probability, assuming equal posterior probability interval?3M1. Suppose globe tossing data turned 8 water 15 tosses. Constructe posterior distribution, using grid approximation. Use flat prior .3M2. Draw 10,000 samples grid approximation . use sample calculate 90% HPDI p.3M3. Construct posterior predictive check model data. means simulate distribution samples, averaging posterior uncertainty p. probability observing 8 water 15 tosses?3M4. Using posterior distribution constructed new (8/15) data, now calculate probability observing 6 water 9 tosses.3M5. Start 3M1, now use prior zero p = 0.5 constant p = 0.5. corresponds prior information majority Earth’s surface water. Repeat problem compare inferences (using priors) true value p = 0.7.HPDI 3M2 much narrower new prior ([.501, .711] vs. [.334, 0.722]). Additionally, probabilities observing 8 15 6 9 increased, value p < 0.5 longer taking posterior density. Thus model new prior giving us better information.3M6. Suppose want estimate Earth’s proportion water precisely. Specifically, want 99% percentile interval posterior distribution p 0.05 wide. means distance upper lower bound interval 0.05. many times toss globe ?figure shows average interval width 100 simulations given number tosses. , true proportion p 0.7 toss globe 1,000 times, average interval width approximately 0.074. get interval width .05 smaller, need around 2,300 tosses.Hard. Hard problems use data . data indicate gender (male = 1, female = 0) officially reported first second born children 100 two-child families. example, first family data reported boy (1) girl (0). second family reported girl (0) boy (1). third family reported two girls. can load tow vectors R’s memory typing:Use vectors data. example compute total number boys born across births, use:3H1. Using grid approximation, compute posterior distribution probability birth boy. Assume uniform prior probability. parameter value maximizes posterior probability?3H2. Using sample function, draw 10,000 random parameter values posterior distribution calculated . Use sample estimate 50%, 89%, 97% highest posterior density intervals.3H3. Use rbinom simulate 10,000 replicates 200 births. end 10,000 numbers, one count boys 200 births. Compare distribution predicted numbers boys actual count data (111 boys 200 births). many good ways visualize simulations, dens command (part rethinking package) prbably easiest way case. look like model fits data well? , distribution predictions include actual observation central, likely outcome?Based posterior predictive distribution, model appears fit well, observed value 111 middle distribution.3H4. Now compare 10,000 counts boys 100 simulated first borns number boys first births, birth1. model look light?Based first births , model appears fit less well. Specifically, model appears overestimating number first births boys. However, appear large discrepancy, observed value still within middle 66% interval.3H5. model assumes sex first second births independent. check assumption, focus now second births followed female first borns. Compare 10,000 simulated conts boys second births followed girls. correctly, need count number first borns girls simulate many births, 10,000 times. Compare counts boys simulations actual observed count boys following girls. model look light? guesses going data?model severely estimating number second-born boys first born child girl. Thus, assumption births independent appears violated.","code":"\np_grid <- seq(from = 0, to = 1, length.out = 1000)\nprior <- rep(1, 1000)\nlikelihood <- dbinom(6, size = 9, prob = p_grid)\nposterior <- likelihood * prior\nposterior <- posterior / sum(posterior)\n\nset.seed(100)\nsamples <- sample(p_grid, prob = posterior, size = 1e4, replace = TRUE)\nmean(samples < 0.2)\n#> [1] 4e-04\nmean(samples > 0.8)\n#> [1] 0.112\nlibrary(tidyverse)\nmean(between(samples, 0.2, 0.8))\n#> [1] 0.888\nquantile(samples, probs = 0.2)\n#>   20% \n#> 0.519\nquantile(samples, probs = 0.8)\n#>   80% \n#> 0.756\nlibrary(rethinking)\nHPDI(samples, prob = 0.66)\n#> |0.66 0.66| \n#> 0.509 0.774\nPI(samples, prob = 0.66)\n#>   17%   83% \n#> 0.503 0.770\np_grid <- seq(from = 0, to = 1, length.out = 1000)\nprior <- rep(1, 1000)\nlikelihood <- dbinom(8, size = 15, prob = p_grid)\nposterior <- likelihood * prior\nposterior <- posterior / sum(posterior)\n\ntibble(p = p_grid, posterior = posterior) %>%\n  ggplot(aes(x = p, y = posterior)) +\n  geom_point() +\n  geom_line() +\n  labs(x = \"Proportion Water (p)\", y = \"Posterior Density\")\nset.seed(101)\nsamples <- sample(p_grid, prob = posterior, size = 1e4, replace = TRUE)\n\nHPDI(samples, prob = 0.9)\n#>  |0.9  0.9| \n#> 0.334 0.722\nw <- rbinom(1e4, size = 15, prob = samples)\nmean(w == 8)\n#> [1] 0.15\nw <- rbinom(1e4, size = 9, prob = samples)\nmean(w == 6)\n#> [1] 0.171\n# 3M5.1\np_grid <- seq(from = 0, to = 1, length.out = 1000)\nprior <- case_when(p_grid < 0.5 ~ 0L,\n                   TRUE ~ 1L)\nlikelihood <- dbinom(8, size = 15, prob = p_grid)\nposterior <- likelihood * prior\nposterior <- posterior / sum(posterior)\n\ntibble(p = p_grid, posterior = posterior) %>%\n  ggplot(aes(x = p, y = posterior)) +\n  geom_point() +\n  geom_line() +\n  labs(x = \"Proportion Water (p)\", y = \"Posterior Density\")\n# 3M5.2\nset.seed(101)\nsamples <- sample(p_grid, prob = posterior, size = 1e4, replace = TRUE)\nHPDI(samples, prob = 0.9)\n#>  |0.9  0.9| \n#> 0.501 0.711\n\n# 3M5.3\nw <- rbinom(1e4, size = 15, prob = samples)\nmean(w == 8)\n#> [1] 0.161\n\n# 3M5.4\nw <- rbinom(1e4, size = 9, prob = samples)\nmean(w == 6)\n#> [1] 0.236\nsingle_sim <- function(tosses, prior_type = c(\"uniform\", \"step\")) {\n  prior_type <- match.arg(prior_type)\n  obs <- rbinom(1, size = tosses, prob = 0.7)\n  \n  p_grid <- seq(from = 0, to = 1, length.out = 1000)\n  prior <- rep(1, 1000)\n  if (prior_type == \"step\") prior[1:500] <- 0\n  \n  likelihood <- dbinom(obs, size = tosses, prob = p_grid)\n  posterior <- likelihood * prior\n  posterior <- posterior / sum(posterior)\n  \n  samples <- sample(p_grid, prob = posterior, size = 1e4, replace = TRUE)\n  interval <- PI(samples, prob = 0.99)\n  width <- interval[2] - interval[1]\n}\nsingle_cond <- function(tosses, prior_type, reps = 100) {\n  tibble(tosses = tosses,\n         prior_type = prior_type,\n         width = map_dbl(seq_len(reps), ~single_sim(tosses = tosses,\n                                                    prior_type = prior_type)))\n}\n\nsimulation <- crossing(tosses = seq(1000, 5000, by = 100),\n                       prior_type = c(\"uniform\", \"step\")) %>%\n  pmap_dfr(single_cond, reps = 100) %>%\n  group_by(tosses, prior_type) %>%\n  summarize(avg_width = mean(width), .groups = \"drop\") %>%\n  mutate(prior_type = case_when(prior_type == \"uniform\" ~ \"Uniform Prior\",\n                                prior_type == \"step\" ~ \"Step Prior\"),\n         prior_type = factor(prior_type, levels = c(\"Uniform Prior\",\n                                                    \"Step Prior\")))\n\nggplot(simulation, aes(x = tosses, y = avg_width)) +\n  facet_wrap(~prior_type, nrow = 1) +\n  geom_point() +\n  geom_line() +\n  scale_x_comma() +\n  labs(x = \"Tosses\", y = \"Average Interval Width\") +\n  theme(panel.spacing.x = unit(2, \"lines\"))\ndata(homeworkch3)\nbirth1\n#>   [1] 1 0 0 0 1 1 0 1 0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1\n#>  [38] 1 0 1 0 1 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 1 0 0 1 1 1\n#>  [75] 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1 0 1 1 1 0 1 1 1 1\nbirth2\n#>   [1] 0 1 0 1 0 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 0 1 0 0\n#>  [38] 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 0 0\n#>  [75] 0 0 0 1 0 0 0 1 1 0 0 1 0 0 1 1 0 0 0 1 1 1 0 0 0 0\nsum(birth1) + sum(birth2)\n#> [1] 111\np_grid <- seq(from = 0, to = 1, length.out = 1000)\nprior <- rep(1, 1000)\n\nboys <- sum(birth1) + sum(birth2)\ntotal <- length(birth1) + length(birth2)\nlikelihood <- dbinom(boys, size = total, prob = p_grid)\nposterior <- likelihood * prior\nposterior <- posterior / sum(posterior)\n\ntibble(p = p_grid, posterior = posterior) %>%\n  ggplot(aes(x = p, y = posterior)) +\n  geom_point() +\n  geom_line() +\n  labs(x = \"Proportion Boys (p)\", y = \"Posterior Density\")\n\np_grid[which.max(posterior)]\n#> [1] 0.555\nsamples <- sample(p_grid, prob = posterior, size = 1e4, replace = TRUE)\nHPDI(samples, prob = c(0.50, 0.89, 0.97))\n#> |0.97 |0.89  |0.5  0.5| 0.89| 0.97| \n#> 0.474 0.496 0.531 0.578 0.609 0.628\nlibrary(tidybayes)\nbreak_func <- function(x) {\n  length(seq(min(x), max(x), by = 1)) + 1\n}\n\nset.seed(300)\nb <- rbinom(1e4, size = 200, prob = samples)\n\nggplot() +\n  stat_histinterval(aes(x = b), .width = c(0.66, 0.89), breaks = break_func) +\n  geom_vline(aes(xintercept = boys), linetype = \"dashed\", color = \"red\") +\n  labs(x = \"Number of Boys\", y = \"Density\")\nset.seed(301)\nb <- rbinom(1e4, size = 100, prob = samples)\n\n\nggplot() +\n  stat_histinterval(aes(x = b), .width = c(0.66, 0.89), breaks = break_func) +\n  geom_vline(aes(xintercept = sum(birth1)), linetype = \"dashed\",\n             color = \"red\") +\n  labs(x = \"Number of Boys\", y = \"Density\")\nfb_girls <- length(birth1) - sum(birth1)\n\nset.seed(302)\nb <- rbinom(1e4, size = fb_girls, prob = samples)\n\nobs_bfg <- sum(birth2[which(birth1 == 0)])\n\nggplot() +\n  stat_histinterval(aes(x = b), .width = c(0.66, 0.89), breaks = break_func) +\n  geom_vline(aes(xintercept = obs_bfg), linetype = \"dashed\",\n             color = \"red\") +\n  labs(x = \"Number of Boys\", y = \"Density\")"},{"path":"bayesian-inference.html","id":"homework","chapter":"Week 1: Bayesian Inference","heading":"1.3 Homework","text":"1. Suppose globe tossing data (Chapter 2) turned 4 water 11 land. Construct posterior distribution, using grid approximation. Use flat prior book.First, create grid create prior, constant values grid.Next, calculate likelihood 4 water 11 land value grid normalize values sum 1.Finally, can sample visualize posterior distribution. majority posterior 0.5, mean 0.30. surprising, given data indicates (.e., land observed water).2. Now suppose data 4 water 2 land. Compute posterior , time use prior zero p = 0.5 constant p = 0.5. corresponds prior information majority Earth’s surface water.follow process, now define prior 0 p < .5 1 p ≥ .5.now see posterior distribution truncated .5. mean around 0.69, expected given 4 6 trials (two-thirds) water.3. posterior distribution 2, compute 89% percentile HPDI intervals. Compare widths intervals. wider? ? information interval, might misunderstand shape posterior distribution?First, take 10,000 samples posterior calculated previous question. summarize PI() HPDI().89% percentile interval [0.525, 0.882], highest posterior density interval [0.503, 0.848]. percentile interval 0.357 wide, highest posterior density interval 0.345 wide. Thus, percentile interval wider. HPDI finds narrowest interval contains 89% data. Therefore, unless posterior perfectly symmetrical, central 89% , definition, wider HDPI.intervals, boundary information conveyed. information actual shape posterior conveyed. Without visualizing posterior, interval boundaries might tempt us (incorrectly) assume values interval equally likely values middle range plausible. However, know previous problem posterior asymmetrical, values closer low end interval plausible values high end interval.4. OPTIONAL CHALLENGE. Suppose bias sampling Land likely Water recorded. Specifically, assume 1--5 (20%) Water samples accidentally recorded instead “Land.” First, write generative simulation sampling process. Assuming true proportion Water 0.70, proportion simulation tend produce instead? Second, using simulated sample 20 tosses, compute unbiased posterior distribution true proportion water.’ll start writing function generate biased data. First, generate specified number tosses true_prop. Normally, use rbinom(n = 1, size = tosses), provide total number successes (tosses “water” result). want results individual toss. , example, rather 1 trial 100 tosses, 100 trials 1 toss.Next, generate random uniform numbers 0 1. indicate trials biased. every element bias_sim less bias, corresponding element true_trials changed 0 new vector called bias_trials. original results 0 (“land”), bias effect (.e., 0 changed 0). original result 1 (“water”), bias chance result changed 0.Finally, sum total number 1s (“water”) implementing bias return results.bias mean estimated proportion water? explore, ’ll run short simulation. ’ll use biased_globe() function 1,000 simulations 100 tosses. simulations, can see proportion tosses water, bias included.previous figure, true proportion, 0.7, indicated dashed red line. However, can see biased tosses greatly reducing number “waters” actually observe. average, observe 56 waters, estimated proportion 0.56.final step compute unbiased posterior distribution true proportion water, using 20 tosses biased data generation process. ’ll start generating 20 tosses.data, observed 11 waters. final step estimate unbiased posterior. can accomplish using biased sampling rate 0.8. , true water observation 80% chance actually recorded water observation. shown crtd_likelihood line . dbinom() function, rather setting prob = p_grid, set prob = p_grid * 0.8, reflect bias sampling. see biased posterior peaks around 0.55, whereas correcting bias results posterior peaks right around 0.70.","code":"\ndist <- tibble(p_grid = seq(from = 0, to = 1, length.out = 1000),\n               prior = rep(1, times = 1000))\ndist\n#> # A tibble: 1,000 × 2\n#>     p_grid prior\n#>      <dbl> <dbl>\n#>  1 0           1\n#>  2 0.00100     1\n#>  3 0.00200     1\n#>  4 0.00300     1\n#>  5 0.00400     1\n#>  6 0.00501     1\n#>  7 0.00601     1\n#>  8 0.00701     1\n#>  9 0.00801     1\n#> 10 0.00901     1\n#> # … with 990 more rows\ndist <- dist %>% \n  mutate(likelihood = dbinom(4, size = 15, prob = p_grid),\n         posterior = likelihood * prior,\n         posterior = posterior / sum(posterior))\ndist\n#> # A tibble: 1,000 × 4\n#>     p_grid prior    likelihood posterior\n#>      <dbl> <dbl>         <dbl>     <dbl>\n#>  1 0           1 0              0       \n#>  2 0.00100     1 0.00000000136  2.17e-11\n#>  3 0.00200     1 0.0000000214   3.44e-10\n#>  4 0.00300     1 0.000000107    1.72e- 9\n#>  5 0.00400     1 0.000000336    5.38e- 9\n#>  6 0.00501     1 0.000000811    1.30e- 8\n#>  7 0.00601     1 0.00000166     2.66e- 8\n#>  8 0.00701     1 0.00000305     4.88e- 8\n#>  9 0.00801     1 0.00000514     8.23e- 8\n#> 10 0.00901     1 0.00000814     1.30e- 7\n#> # … with 990 more rows\nset.seed(123)\n\ndist %>% \n  slice_sample(n = 10000, weight_by = posterior, replace = TRUE) %>% \n  ggplot(aes(x = p_grid)) +\n  stat_histinterval(.width = c(0.67, 0.89, 0.97), breaks = seq(0, 1, 0.02),\n                    point_interval = mean_hdci) +\n  labs(x = \"Proportion Water (p)\", y = \"Posterior Density\")\ndist <- tibble(p_grid = seq(from = 0, to = 1, length.out = 1000),\n               prior = rep(c(0, 1), each = 500)) %>% \n  mutate(likelihood = dbinom(4, size = 6, prob = p_grid),\n         posterior = likelihood * prior,\n         posterior = posterior / sum(posterior))\ndist\n#> # A tibble: 1,000 × 4\n#>     p_grid prior likelihood posterior\n#>      <dbl> <dbl>      <dbl>     <dbl>\n#>  1 0           0   0                0\n#>  2 0.00100     0   1.50e-11         0\n#>  3 0.00200     0   2.40e-10         0\n#>  4 0.00300     0   1.21e- 9         0\n#>  5 0.00400     0   3.82e- 9         0\n#>  6 0.00501     0   9.32e- 9         0\n#>  7 0.00601     0   1.93e- 8         0\n#>  8 0.00701     0   3.57e- 8         0\n#>  9 0.00801     0   6.07e- 8         0\n#> 10 0.00901     0   9.70e- 8         0\n#> # … with 990 more rows\nset.seed(123)\n\ndist %>% \n  slice_sample(n = 10000, weight_by = posterior, replace = TRUE) %>% \n  ggplot(aes(x = p_grid)) +\n  stat_histinterval(.width = c(0.67, 0.89, 0.97), breaks = seq(0, 1, 0.02),\n                    point_interval = mean_hdci) +\n  labs(x = \"Proportion Water (p)\", y = \"Posterior Density\")\nset.seed(123)\n\nintervals <- dist %>% \n  slice_sample(n = 10000, weight_by = posterior, replace = TRUE) %>% \n  summarize(bound = c(\"lower\", \"upper\"),\n            pi = PI(p_grid, prob = 0.89),\n            hpdi = HPDI(p_grid, prob = 0.89))\nintervals\n#> # A tibble: 2 × 3\n#>   bound    pi  hpdi\n#>   <chr> <dbl> <dbl>\n#> 1 lower 0.525 0.503\n#> 2 upper 0.882 0.848\nbiased_globe <- function(tosses = 100, true_prop = 0.7, bias = 0.2) {\n  true_trials <- rbinom(n = tosses, size = 1, prob = true_prop)\n  bias_sim <- runif(n = tosses, min = 0, max = 1)\n\n  bias_trials <- true_trials\n  bias_trials[which(bias_sim < bias)] <- 0L\n  sum(bias_trials)\n}\nbias_prop <- map_int(seq_len(1000),\n                     ~biased_globe(tosses = 100, true_prop = 0.7, bias = 0.2))\n\nggplot() +\n  stat_histinterval(aes(x = bias_prop / 100), .width = c(0.67, 0.89, 0.97),\n                    breaks = seq(0, 1, by = 0.01)) +\n  geom_vline(aes(xintercept = 0.7), linetype = \"dashed\", color = \"red\") +\n  expand_limits(x = c(0, 1)) +\n  labs(x = \"Proportion Water (p)\", y = \"Simulations\")\nset.seed(123)\nbiased_dat <- biased_globe(tosses = 20)\nbiased_dat\n#> [1] 11\nlibrary(geomtextpath)\n\nposterior <- tibble(p_grid = seq(0, 1, length.out = 1000)) %>% \n  mutate(prior = dbeta(p_grid, shape1 = 1, shape2 = 1),\n         bias_likelihood = dbinom(biased_dat, size = 20, prob = p_grid),\n         crtd_likelihood = dbinom(biased_dat, size = 20, prob = p_grid * 0.8),\n         bias_posterior = bias_likelihood * prior,\n         crtd_posterior = crtd_likelihood * prior,\n         bias_posterior = bias_posterior / sum(bias_posterior),\n         crtd_posterior = crtd_posterior / sum(crtd_posterior))\n\nggplot(posterior, aes(x = p_grid)) +\n  geom_textline(aes(y = bias_posterior), linetype = \"dashed\", color = \"grey70\",\n                size = 6, linewidth = 1, label = \"Biased\", hjust = 0.45,\n                family = \"Source Sans Pro\") +\n  geom_textline(aes(y = crtd_posterior), linetype = \"solid\", color = \"#009FB7\",\n                size = 6, linewidth = 1, label = \"Corrected\", hjust = 0.4,\n                family = \"Source Sans Pro\") +\n  scale_x_continuous(breaks = seq(0, 1, 0.1)) +\n  labs(x = \"Proportion Water (p)\", y = \"Posterior Density\")"},{"path":"linear-models-causal-inference.html","id":"linear-models-causal-inference","chapter":"Week 2: Linear Models & Causal Inference","heading":"Week 2: Linear Models & Causal Inference","text":"second week covers Chapter 4 (Geocentric Models).","code":""},{"path":"linear-models-causal-inference.html","id":"lectures-1","chapter":"Week 2: Linear Models & Causal Inference","heading":"2.1 Lectures","text":"Lecture 3:Lecture 4:","code":""},{"path":"linear-models-causal-inference.html","id":"exercises-1","chapter":"Week 2: Linear Models & Causal Inference","heading":"2.2 Exercises","text":"","code":""},{"path":"linear-models-causal-inference.html","id":"chapter-4","chapter":"Week 2: Linear Models & Causal Inference","heading":"2.2.1 Chapter 4","text":"4E1. model definition , line likelihood?\n\\[\\begin{align}\ny_i &\\sim \\text{Normal}(\\mu,\\sigma) \\\\\n\\mu &\\sim \\text{Normal}(0,10) \\\\\n\\sigma &\\sim \\text{Exponential}(1)\n\\end{align}\\]likelihood given first line, \\(y_i \\sim \\text{Normal}(\\mu,\\sigma)\\). lines represent prior distributions \\(\\mu\\) \\(\\sigma\\).4E2. model definition just , many parameters posterior distribution?two parameters, \\(\\mu\\) \\(\\sigma\\).4E3. Using model definition , write appropriate form Bayes’ theorem includes proper likelihood priors.\\[\n\\text{Pr}(\\mu,\\sigma|y) = \\frac{\\text{Normal}(y|\\mu,\\sigma)\\text{Normal}(\\mu|0,10)\\text{Exponential}(\\sigma|1)}{\\int\\int\\text{Normal}(y|\\mu,\\sigma)\\text{Normal}(\\mu|0,10)\\text{Exponential}(\\sigma|1)d \\mu d \\sigma}\n\\]4E4. model definition , line linear model?\n\\[\\begin{align}\ny_i &\\sim \\text{Normal}(\\mu,\\sigma) \\\\\n\\mu_i &= \\alpha + \\beta x_i \\\\\n\\alpha &\\sim \\text{Normal}(0,10) \\\\\n\\beta &\\sim \\text{Normal}(0,1) \\\\\n\\sigma &\\sim \\text{Exponential}(2)\n\\end{align}\\]linear model second line, \\(\\mu_i = \\alpha + \\beta x_i\\).4E5. model definition just , many parameters posterior distribution?now three model parameters: \\(\\alpha\\), \\(\\beta\\), \\(\\sigma\\). mean, \\(\\mu\\) longer parameter, defined deterministically, function parameters model.4M1. model definition , simulate observed y values prior (posterior).\n\\[\\begin{align}\ny_i &\\sim \\text{Normal}(\\mu,\\sigma) \\\\\n\\mu &\\sim \\text{Normal}(0,10) \\\\\n\\sigma &\\sim \\text{Exponential}(1)\n\\end{align}\\]4M2. Trasnlate model just quap formula.4M3. Translate quap model formula mathematical model definition.\\[\\begin{align}\n  y_i &\\sim \\text{Normal}(\\mu_i,\\sigma) \\\\\n  \\mu_i &= \\alpha + \\beta x_i \\\\\n  \\alpha &\\sim \\text{Normal}(0, 10) \\\\\n  \\beta &\\sim \\text{Uniform}(0, 1) \\\\\n  \\sigma &\\sim \\text{Exponential}(1)\n\\end{align}\\]4M4. sample students measured height year 3 years. third year, want fit linear regression predicting height using year predictor. Write mathematical model definition regression, using variable names priors choose. prepared defend choice priors.\\[\\begin{align}\n  h_{ij} &\\sim \\text{Normal}(\\mu_{ij}, \\sigma) \\\\\n  \\mu_{ij} &= \\alpha + \\beta(y_j - \\bar{y}) \\\\\n  \\alpha &\\sim \\text{Normal}(100, 10) \\\\\n  \\beta &\\sim \\text{Normal}(0, 10) \\\\\n  \\sigma &\\sim \\text{Exponential}(1)\n\\end{align}\\]height centered, \\(\\alpha\\) represents average height average year (.e., year 2). prior \\(\\text{Normal}(100, 10)\\) chosen assuming height measured centimeters sample children still growing.slope extremely vague. prior centered zero, standard deviation prior 10 represents wide range possible growth (shrinkage). growth spurts, height growth averages 6–13 cm/year. standard deviation 10 encompasses range might expect see growth occurring high rate.Finally, exponential prior \\(\\sigma\\) assumes average deviation 1.Prior predictive simulations also appear give reasonably plausible regression lines, given current assumptions.4M5. Now suppose remind every student got taller year. information lead change choice priors? ?Yes. know increase year always lead increased height, know \\(\\beta\\) positive. Therefore, prior reflect using, example, log-normal distribution.\\[\n\\beta \\sim \\text{Log-Normal}(1,0.5)\n\\]prior gives expectation 3cm per year, 89% highest density interval 0.87cm 5.18cm per year.Prior predictive simulations plausible lines using new log-normal prior indicate priors still represent plausible values. lines positive, due prior constraint. However, variation around mean, lines show decrease height. truly impossible students shrink, data like might arise measurement error.4M6. Now suppose tell variance among heights students age never 64cm. lead revise priors?variance 64cm corresponds standard deviation 8cm. current prior \\(\\sigma \\sim \\text{Exponential}(1)\\) gives little probability mass values greater 8. However, still theoretically possible. want truly constrain variance way, use \\(\\text{Uniform}(0,8)\\) prior. eliminate values result variance greater 64cm.4M7. Refit model m4.3 chapter, omit mean weight xbar time. Compare new model’s posterior original model. particular, look covariance among parameters. different? compare posterior predictions models.First, ’ll reproduce m4.3 using quap(), using brm(). covariance matrix , expect.Now, let’s using non-centered parameterization. time, ’ll use brm().now see non-zero covariances parameters. Lets compare posterior predictions. ’ll generate hypothetical outcome plots animated show uncertainty estimates (see Hullman et al., 2015; Kale et al., 2019). ’ll just animate estimated regression line using {gganimate} (Pedersen & Robinson, 2020). can see predictions two models nearly identical.4M8. chapter, used 15 knots cherry blossom spline. Increase number knots observe happens resulting spline. adjust also width prior weights—change standard deviation prior watch happens. think combination know number prior weights controls?First lets duplicate 15-knot spline model chapter. ’ll double number knots play prior.Visualizing model, see looks similar fitted model chapter.Now ’ll fit two additional models. first uses 30 knots, second uses tighter prior.expected, visualize models see increasing number knots increases “wiggly-ness” spline. can also see tightening prior weights takes away “wiggly-ness”.4H1. weights listed recored !Kung census, heights recorded individuals. Provide predicted heights 89% intervals individuals. , fill table, , using model-based predictions.key function tidybayes::add_predicted_draws(), samples posterior predictive distribution. use model b4.3 make predictions, estimated back question 4M7.4H2. Select rows Howell1 data ages 18 years age. right, end new data frame 192 rows .Fit linear regression data, using quap. Present interpret estimates. every 10 units increase weight, much taller model predict child gets?’ll use brms::brm() fitting model. ’ll use priors model adults, except weight \\(\\beta\\). children shorter adults, ’ll use prior \\(\\text{Normal}(138,20)\\), based data reported Fryar et al. (2016). Based estimates, increase 10 units weights corresponds average increase height 27.2 centimeters.Plot raw data, height vertical axis weight horizontal axis. Superimpose MAP regression line 89% interval mean. Also superimpose 89% interval predicted heights.aspects model fit concern ? Describe kinds assumptions change, , improve model. don’t write new code. Just explain model appears bad job , hypothesize better model.model consistently -estimates height individuals weight less ~13 great ~35. model also consistently underestimating height individuals weight ~13-35. Thus, data appears curve assumption straight line violating. wanted improve model, relax assumption straight line.4H3. Suppose colleauge , works allometry, glances practice problems just . colleague exclaims, “’s silly. Everyone knows ’s logarithm body weight scales height!” Let’s take colleague’s advice see happens.Model relationship height (cm) natural logarithm weight (log-kg). Use entire Howell1 data frame, 544 rows, adults non-adults. Can interpret resulting estimates?Conditional data model, intercept estimate sprintf(\"%0.1f\", summary(b4h3)[[\"fixed\"]][\"Intercept\", \"Estimate\"]) represents predicted average height individual average log-weight (log-kg). \\(\\beta\\) estimate sprintf(\"%0.1f\", summary(b4h3)[[\"fixed\"]][\"log_weight_c\", \"Estimate\"]) represents average expected increase height associated one-unit increase weight (log-kg).Begin plot: plot( height ~ weight , data = Howell1 ). use samples quadratic approximate posterior model () superimpose plot: (1) predicted mean height function weight, (2) 97% interval mean, (3) 97% interval predicted heights.4H4. Plot prior predictive distribution parabolic polynomial regression model chapter. can modify code plots linear regression prior predictive distribution. Can modify prior distributions \\(\\alpha\\), \\(\\beta_1\\), \\(\\beta_2\\) prior predictions stay within biologically reasonable outcome space? say: try fit data hand. try keep curves consistent know height weight, seeing exact data.polynomial model chapter defined :\\[\\begin{align}\n  h_i &\\sim \\text{Normal}(\\mu_i,\\sigma) \\\\\n  \\mu_i &= \\alpha + \\beta_1x_i + \\beta_2x_i^2 \\\\\n  \\alpha &\\sim \\text{Normal}(178,20) \\\\\n  \\beta_1 &\\sim \\text{Log-Normal}(0,1) \\\\\n  \\beta_2 &\\sim \\text{Normal}(0,1) \\\\\n  \\sigma &\\sim \\text{Uniform}(0,50)\n\\end{align}\\]First, let’s generate prior predictive checks original priors.Clearly room improvement . However, ’s intuitive exactly parameter effects parabolic curve, finding good prior distribution really hard! much trial error playing parabola calculators online, ended :\\[\\begin{align}\n  h_i &\\sim \\text{Normal}(\\mu_i,\\sigma) \\\\\n  \\mu_i &= \\alpha + \\beta_1x_i + \\beta_2x_i^2 \\\\\n  \\alpha &\\sim \\text{Normal}(-190,5) \\\\\n  \\beta_1 &\\sim \\text{Normal}(13,0.2) \\\\\n  \\beta_2 &\\sim \\text{Uniform}(-0.13,-0.10) \\\\\n  \\sigma &\\sim \\text{Uniform}(0,50)\n\\end{align}\\]following prior predictive distribution.4H5. Return data(cherry_blossoms) model association blossom date (doy) March temperature (temp). Note many missing values variables. may consider linear model, polynomial, spline temperature. well temperature trend predict blossom trend?’ll try type model: linear, polynomial, spline. , ’ll fit model, visualize predictions observed data.Now let’s visualize predictions model. Overall predictions model remarkably similar. Therefore, go linear model, simplest models.4H6. Simulate prior predictive distribution cherry blossom spline chapter. Adjust prior weights observe happens. think prior weights ?reminder, cherry blossom spline model chapter:\\[\\begin{align}\n  D_i &\\sim \\text{Normal}(\\mu_i,\\sigma) \\\\\n  \\mu_i &= \\alpha + \\sum_{k=1}^Kw_kB_{k,} \\\\\n  \\alpha &\\sim \\text{Normal}(100, 10) \\\\\n  w_k &\\sim \\text{Normal}(0,10) \\\\\n  \\sigma &\\sim \\text{Exponential}(1)\n\\end{align}\\]’ll also need recreate basis functions model uses:Finally, can generate data priors, combine parameters basis functions get prior predictive distributions.Now let’s tighten prior w \\(\\text{Normal}(0,2)\\), used exercise 4M8. Now lines much less wiggly, consistent found previous exercise, used observed data.4H8. (sic; 4H7 text, ’ve kept labeled 4H8 consistent book) cherry blossom spline chapter used intercept \\(\\alpha\\), technically doesn’t require one. first basis functions substitute intercept. Try refitting cherry blossom spline without intercept. else model need change make work?can remove intercept removing parameter model. {brms} formula, means replace doy ~ 1 + B question 4M8 doy ~ 0 + B. 0 means “don’t estimate intercept.”looks lot like original model, except left hand side spline pulled . likely due prior w. prior centered 0, assumes intercept present (.e., curves spline average deviation 0 mean). However, without intercept, prior drags line actual zero first basis function non-zero. changing prior w prior originally used intercept, get almost original model back.","code":"\nlibrary(tidyverse)\n\nsim <- tibble(mu = rnorm(n = 10000, mean = 0, sd = 10),\n              sigma = rexp(n = 10000, rate = 1)) %>%\n  mutate(y = rnorm(n = 10000, mean = mu, sd = sigma))\n\nggplot(sim, aes(x = y)) +\n  geom_density() +\n  labs(x = \"y\", y = \"Density\")\nflist <- alist(\n  y ~ dnorm(mu, sigma),\n  mu ~ dnorm(0, 10),\n  sigma ~ dexp(1)\n)y ~ dnorm( mu , sigma ),\nmu <- a + b*x,\na ~ dnorm( 0 , 10 ),\nb ~ dunif( 0 , 1 ),\nsigma ~ dexp( 1 )\nn <- 50\ntibble(group = seq_len(n),\n       alpha = rnorm(n, 100, 10),\n       beta = rnorm(n, 0, 10),\n       sigma = rexp(n, 1)) %>%\n  expand(nesting(group, alpha, beta, sigma), year = c(1, 2, 3)) %>%\n  mutate(height = rnorm(n(), alpha + beta * (year - mean(year)), sigma)) %>%\n  ggplot(aes(x = year, y = height, group = group)) +\n  geom_line() +\n  labs(x = \"Year\", y = \"Height\")\nlibrary(tidybayes)\n\nset.seed(123)\nsamples <- rlnorm(1e8, 1, 0.5)\nbounds <- mean_hdi(samples, .width = 0.89)\n\nggplot() +\n  stat_function(data = tibble(x = c(0, 10)), mapping = aes(x = x),\n                geom = \"line\", fun = dlnorm,\n                args = list(meanlog = 1, sdlog = 0.5)) +\n  geom_ribbon(data = tibble(x = seq(bounds$ymin, bounds$ymax, 0.01)),\n              aes(x = x, ymin = 0, ymax = dlnorm(x, 1, 0.5)),\n              alpha = 0.8) +\n  scale_x_continuous(breaks = seq(0, 10, 2)) +\n  labs(x = expression(beta), y = \"Density\")\nn <- 50\ntibble(group = seq_len(n),\n       alpha = rnorm(n, 100, 10),\n       beta = rlnorm(n, 1, 0.5),\n       sigma = rexp(n, 1)) %>%\n  expand(nesting(group, alpha, beta, sigma), year = c(1, 2, 3)) %>%\n  mutate(height = rnorm(n(), alpha + beta * (year - mean(year)), sigma)) %>% \n  ggplot(aes(x = year, y = height, group = group)) +\n  geom_line() +\n  labs(x = \"Year\", y = \"Height\")\nlibrary(rethinking)\nlibrary(brms)\n\ndata(Howell1)\nhow_dat <- Howell1 %>%\n  filter(age >= 18) %>%\n  mutate(weight_c = weight - mean(weight))\n\n# first, duplicate model with `quap`\nm4.3 <- quap(alist(height ~ dnorm(mu, sigma),\n                   mu <- a + b * (weight_c),\n                   a ~ dnorm(178, 20),\n                   b ~ dlnorm(0, 1),\n                   sigma ~ dunif(0, 50)),\n             data = how_dat)\n\nround(vcov(m4.3), 3)\n#>           a     b sigma\n#> a     0.073 0.000 0.000\n#> b     0.000 0.002 0.000\n#> sigma 0.000 0.000 0.037\n\n# and then with brms\nb4.3 <- brm(height ~ 1 + weight_c, data = how_dat, family = gaussian,\n            prior = c(prior(normal(178, 20), class = Intercept),\n                      prior(lognormal(0, 1), class = b, lb = 0),\n                      prior(uniform(0, 50), class = sigma)),\n            iter = 28000, warmup = 27000, chains = 4, cores = 4, seed = 1234,\n            file = here(\"fits\", \"chp4\", \"b4.3-0\"))\n#> Warning: It appears as if you have specified an upper bounded prior on a parameter that has no natural upper bound.\n#> If this is really what you want, please specify argument 'ub' of 'set_prior' appropriately.\n#> Warning occurred for prior \n#> sigma ~ uniform(0, 50)\n\nas_draws_df(b4.3) %>%\n  as_tibble() %>% \n  select(b_Intercept, b_weight_c, sigma) %>%\n  cov() %>%\n  round(digits = 3)\n#>             b_Intercept b_weight_c sigma\n#> b_Intercept       0.074      0.000 0.000\n#> b_weight_c        0.000      0.002 0.000\n#> sigma             0.000      0.000 0.038\nb4.3_nc <- brm(height ~ 1 + weight, data = how_dat, family = gaussian,\n               prior = c(prior(normal(178, 20), class = Intercept),\n                         prior(lognormal(0, 1), class = b, lb = 0),\n                         prior(uniform(0, 50), class = sigma)),\n               iter = 28000, warmup = 27000, chains = 4, cores = 4, seed = 1234,\n               file = here(\"fits\", \"chp4\", \"b4.3_nc\"))\n#> Warning: It appears as if you have specified an upper bounded prior on a parameter that has no natural upper bound.\n#> If this is really what you want, please specify argument 'ub' of 'set_prior' appropriately.\n#> Warning occurred for prior \n#> sigma ~ uniform(0, 50)\n\nas_draws_df(b4.3_nc) %>%\n  as_tibble() %>% \n  select(b_Intercept, b_weight, sigma) %>%\n  cov() %>%\n  round(digits = 3)\n#>             b_Intercept b_weight sigma\n#> b_Intercept       3.653   -0.079 0.010\n#> b_weight         -0.079    0.002 0.000\n#> sigma             0.010    0.000 0.035\nlibrary(gganimate)\n\nweight_seq <- tibble(weight = seq(25, 70, length.out = 100)) %>%\n  mutate(weight_c = weight - mean(how_dat$weight))\n\npredictions <- bind_rows(\n  predict(b4.3, newdata = weight_seq) %>%\n    as_tibble() %>%\n    bind_cols(weight_seq) %>%\n    mutate(type = \"Centered\"),\n  predict(b4.3_nc, newdata = weight_seq) %>%\n    as_tibble() %>%\n    bind_cols(weight_seq) %>%\n    mutate(type = \"Non-centered\")\n)\n\nfits <- bind_rows(\n  weight_seq %>%\n    add_epred_draws(b4.3) %>%\n    mutate(type = \"Centered\"),\n  weight_seq %>%\n    add_epred_draws(b4.3_nc) %>%\n    mutate(type = \"Non-centered\")\n) %>%\n  ungroup()\n\nbands <- fits %>%\n  group_by(type, weight) %>%\n  median_qi(.epred, .width = c(.67, .89, .97))\n\nlines <- fits %>%\n  filter(.draw %in% sample(unique(.data$.draw), size = 50))\n\nggplot(lines, aes(x = weight)) +\n  facet_wrap(~type, nrow = 1) +\n  geom_ribbon(data = predictions, aes(ymin = Q2.5, ymax = Q97.5), alpha = 0.3) +\n  geom_lineribbon(data = bands, aes(y = .epred, ymin = .lower, ymax = .upper),\n                  color = NA) +\n  scale_fill_brewer(palette = \"Blues\", breaks = c(.67, .89, .97)) +\n  geom_line(aes(y = .epred, group = .draw)) +\n  geom_point(data = how_dat, aes(y = height), shape = 1, alpha = 0.7) +\n  labs(x = \"Weight\", y = \"Height\", fill = \"Interval\") +\n  transition_states(.draw, 0, 1)\nlibrary(splines)\n\ndata(cherry_blossoms)\ncb_dat <- cherry_blossoms %>%\n  drop_na(doy)\n\n# original m4.7 model\nknots_15 <- quantile(cb_dat$year, probs = seq(0, 1, length.out = 15))\nB_15 <- bs(cb_dat$year, knots = knots_15[-c(1, 15)],\n           degree = 3, intercept = TRUE)\n\ncb_dat_15 <- cb_dat %>% \n  mutate(B = B_15)\n\nb4.7 <- brm(doy ~ 1 + B, data = cb_dat_15, family = gaussian,\n            prior = c(prior(normal(100, 10), class = Intercept),\n                      prior(normal(0, 10), class = b),\n                      prior(exponential(1), class = sigma)),\n            iter = 2000, warmup = 1000, chains = 4, cores = 4, seed = 1234,\n            file = here(\"fits\", \"chp4\", \"b4.7\"))\noriginal_draws <- cb_dat_15 %>% \n  add_epred_draws(b4.7) %>% \n  summarize(mean_hdi(.epred, .width = 0.89),\n            .groups = \"drop\")\n\nggplot(original_draws, aes(x = year, y = doy)) +\n  geom_vline(xintercept = knots_15, alpha = 0.5) +\n  geom_hline(yintercept = fixef(b4.7)[1, 1], linetype = \"dashed\") +\n  geom_point(alpha = 0.5) +\n  geom_ribbon(aes(ymin = ymin, ymax = ymax), fill = \"#009FB7\", alpha = 0.8) +\n  labs(x = \"Year\", y = \"Day in Year\")\n# double the number of knots\nknots_30 <- quantile(cb_dat$year, probs = seq(0, 1, length.out = 30))\nB_30 <- bs(cb_dat$year, knots = knots_30[-c(1, 30)],\n           degree = 3, intercept = TRUE)\n\ncb_dat_30 <- cb_dat %>% \n  mutate(B = B_30)\n\nb4.7_30 <- brm(doy ~ 1 + B, data = cb_dat_30, family = gaussian,\n               prior = c(prior(normal(100, 10), class = Intercept),\n                         prior(normal(0, 10), class = b),\n                         prior(exponential(1), class = sigma)),\n               iter = 2000, warmup = 1000, chains = 4, cores = 4, seed = 1234,\n               file = here(\"fits\", \"chp4\", \"b4.7_30\"))\n\n# and modify the prior\nb4.7_30p <- brm(doy ~ 1 + B, data = cb_dat_30, family = gaussian,\n                prior = c(prior(normal(100, 10), class = Intercept),\n                          prior(normal(0, 2), class = b),\n                          prior(exponential(1), class = sigma)),\n                iter = 2000, warmup = 1000, chains = 4, cores = 4, seed = 1234,\n                file = here(\"fits\", \"chp4\", \"b4.7_30p\"))\n# create plot data\nspline_15 <- original_draws %>%\n  select(-B) %>% \n  mutate(knots = \"15 knots (original model)\")\n\nspline_30 <- cb_dat_30 %>% \n  add_epred_draws(b4.7_30) %>% \n  summarize(mean_hdi(.epred, .width = 0.89),\n            .groups = \"drop\") %>% \n  select(-B) %>% \n  mutate(knots = \"30 knots\")\n\nspline_30p <- cb_dat_30 %>% \n  add_epred_draws(b4.7_30p) %>% \n  summarize(mean_hdi(.epred, .width = 0.89),\n            .groups = \"drop\") %>% \n  select(-B) %>% \n  mutate(knots = \"30 knots; Tight prior\")\n\nall_splines <- bind_rows(spline_15, spline_30, spline_30p)\n\n# make plot\nggplot(all_splines, aes(x = year, y = doy)) +\n  geom_point(alpha = 0.5) +\n  geom_ribbon(aes(ymin = ymin, ymax = ymax), fill = \"#009FB7\", alpha = 0.8) +\n  facet_wrap(~knots, ncol = 1) +\n  labs(x = \"Year\", y = \"Day in Year\")\ntibble(individual = 1:5,\n       weight = c(46.95, 43.72, 64.78, 32.59, 54.63)) %>%\n  mutate(weight_c = weight - mean(how_dat$weight)) %>%\n  add_predicted_draws(b4.3) %>%\n  group_by(individual, weight) %>%\n  mean_qi(.prediction, .width = 0.89) %>%\n  mutate(range = glue(\"[{sprintf('%0.1f', .lower)}--\",\n                      \"{sprintf('%0.1f', .upper)}]\"),\n         .prediction = sprintf(\"%0.1f\", .prediction)) %>%\n  select(individual, weight, exp = .prediction, range) %>%\n  kbl(align = \"c\", booktabs = TRUE,\n      col.names = c(\"Individual\", \"weight\", \"expected height\", \"89% interval\"))\nyoung_how <- Howell1 %>%\n  filter(age < 18) %>%\n  mutate(weight_c = weight - mean(weight))\nnrow(young_how)\n#> [1] 192\nb4h2 <- brm(height ~ 1 + weight_c, data = young_how, family = gaussian,\n            prior = c(prior(normal(138, 20), class = Intercept),\n                      prior(lognormal(0, 1), class = b, lb = 0),\n                      prior(exponential(1), class = sigma)),\n            iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n            file = here(\"fits\", \"chp4\", \"b4h2.rds\"))\n\nsummary(b4h2)\n#>  Family: gaussian \n#>   Links: mu = identity; sigma = identity \n#> Formula: height ~ 1 + weight_c \n#>    Data: young_how (Number of observations: 192) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 0; thin = 1;\n#>          total post-warmup draws = 8000\n#> \n#> Population-Level Effects: \n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept   108.36      0.60   107.17   109.55 1.00     6976     5427\n#> weight_c      2.72      0.07     2.58     2.85 1.00     7770     5680\n#> \n#> Family Specific Parameters: \n#>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sigma     8.36      0.42     7.59     9.22 1.00     7618     5811\n#> \n#> Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\nmod_fits <- tibble(weight = seq_range(young_how$weight, 100)) %>% \n  mutate(weight_c = weight - mean(young_how$weight)) %>%\n  add_epred_draws(b4h2) %>%\n  group_by(weight) %>%\n  mean_qi(.epred, .width = 0.89)\n\nmod_preds <- tibble(weight = seq_range(young_how$weight, 100)) %>% \n  mutate(weight_c = weight - mean(young_how$weight)) %>%\n  add_predicted_draws(b4h2) %>%\n  group_by(weight) %>%\n  mean_qi(.prediction, .width = 0.89)\n\nggplot(young_how, aes(x = weight)) +\n  geom_point(aes(y = height), alpha = 0.4) +\n  geom_ribbon(data = mod_preds, aes(ymin = .lower, ymax = .upper),\n              alpha = 0.2) +\n  geom_lineribbon(data = mod_fits,\n                  aes(y = .epred, ymin = .lower, ymax = .upper),\n                  fill = \"grey60\", size = 1) +\n  labs(x = \"Weight\", y = \"Height\")\nfull_how <- Howell1 %>%\n  mutate(log_weight = log(weight),\n         log_weight_c = log_weight - mean(log_weight))\n\nb4h3 <- brm(height ~ 1 + log_weight_c, data = full_how, family = gaussian,\n            prior = c(prior(normal(158, 20), class = Intercept),\n                      prior(lognormal(0, 1), class = b, lb = 0),\n                      prior(exponential(1), class = sigma)),\n            iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n            file = here(\"fits\", \"chp4\", \"b4h3\"))\nsummary(b4h3)\n#>  Family: gaussian \n#>   Links: mu = identity; sigma = identity \n#> Formula: height ~ 1 + log_weight_c \n#>    Data: full_how (Number of observations: 544) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 0; thin = 1;\n#>          total post-warmup draws = 8000\n#> \n#> Population-Level Effects: \n#>              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept      138.27      0.22   137.83   138.70 1.00     8706     6181\n#> log_weight_c    47.08      0.38    46.33    47.81 1.00     8601     6066\n#> \n#> Family Specific Parameters: \n#>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sigma     5.13      0.15     4.85     5.44 1.00     8332     5723\n#> \n#> Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\nhow_fits <- tibble(weight = seq_range(full_how$weight, 100)) %>% \n  mutate(log_weight = log(weight),\n         log_weight_c = log_weight - mean(full_how$log_weight)) %>%\n  add_epred_draws(b4h3) %>%\n  group_by(weight) %>%\n  mean_qi(.epred, .width = 0.97)\n\nhow_preds <- tibble(weight = seq_range(full_how$weight, 100)) %>% \n  mutate(log_weight = log(weight),\n         log_weight_c = log_weight - mean(full_how$log_weight)) %>%\n  add_predicted_draws(b4h3) %>%\n  group_by(weight) %>%\n  mean_qi(.prediction, .width = 0.97)\n\nggplot(full_how, aes(x = weight)) +\n  geom_point(aes(y = height), alpha = 0.4) +\n  geom_ribbon(data = how_preds, aes(ymin = .lower, ymax = .upper),\n              alpha = 0.2) +\n  geom_lineribbon(data = how_fits,\n                  aes(y = .epred, ymin = .lower, ymax = .upper),\n                  fill = \"grey60\", size = 1) +\n  labs(x = \"Weight\", y = \"Height\")\nn <- 1000\ntibble(group = seq_len(n),\n       alpha = rnorm(n, 178, 20),\n       beta1 = rlnorm(n, 0, 1),\n       beta2 = rnorm(n, 0, 1)) %>%\n  expand(nesting(group, alpha, beta1, beta2),\n         weight = seq(25, 70, length.out = 100)) %>%\n  mutate(height = alpha + (beta1 * weight) + (beta2 * (weight ^ 2))) %>%\n  ggplot(aes(x = weight, y = height, group = group)) +\n  geom_line(alpha = 1 / 10) +\n  geom_hline(yintercept = c(0, 272), linetype = 2:1, color = \"red\") +\n  annotate(geom = \"text\", x = 25, y = 0, hjust = 0, vjust = 1,\n           label = \"Embryo\") +\n  annotate(geom = \"text\", x = 25, y = 272, hjust = 0, vjust = 0,\n           label = \"World's tallest person (272cm)\") +\n  coord_cartesian(ylim = c(-25, 300)) +\n  labs(x = \"Weight\", y = \"Height\")\nn <- 1000\ntibble(group = seq_len(n),\n       alpha = rnorm(n, -190, 5),\n       beta1 = rnorm(n, 13, 0.2),\n       beta2 = runif(n, -0.13, -0.1)) %>%\n  expand(nesting(group, alpha, beta1, beta2),\n         weight = seq(25, 70, length.out = 100)) %>%\n  mutate(height = alpha + (beta1 * weight) + (beta2 * (weight ^ 2))) %>%\n  ggplot(aes(x = weight, y = height, group = group)) +\n  geom_line(alpha = 1 / 10) +\n  geom_hline(yintercept = c(0, 272), linetype = 2:1, color = \"red\") +\n  annotate(geom = \"text\", x = 25, y = -3, hjust = 0, vjust = 1,\n           label = \"Embryo\") +\n  annotate(geom = \"text\", x = 25, y = 275, hjust = 0, vjust = 0,\n           label = \"World's tallest person (272cm)\") +\n  coord_cartesian(ylim = c(-25, 300)) +\n  labs(x = \"Weight\", y = \"Height\")\ndata(cherry_blossoms)\n\ncb_temp <- cherry_blossoms %>%\n  drop_na(doy, temp) %>%\n  mutate(temp_c = temp - mean(temp),\n         temp_s = temp_c / sd(temp),\n         temp_s2 = temp_s ^ 2,\n         temp_s3 = temp_s ^ 3)\n\n# linear model\nlin_mod <- brm(doy ~ 1 + temp_c, data = cb_temp, family = gaussian,\n               prior = c(prior(normal(100, 10), class = Intercept),\n                         prior(normal(0, 10), class = b),\n                         prior(exponential(1), class = sigma)),\n               iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n               file = here(\"fits\", \"chp4\", \"b4h5-linear\"))\n\n# quadratic model\nqad_mod <- brm(doy ~ 1 + temp_s + temp_s2, data = cb_temp, family = gaussian,\n               prior = c(prior(normal(100, 10), class = Intercept),\n                         prior(normal(0, 10), class = b, coef = \"temp_s\"),\n                         prior(normal(0, 1), class = b, coef = \"temp_s2\"),\n                         prior(exponential(1), class = sigma)),\n               iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n               file = here(\"fits\", \"chp4\", \"b4h5-quadratic\"))\n\n# cubic model\ncub_mod <- brm(doy ~ 1 + temp_s + temp_s2 + temp_s3, data = cb_temp,\n               family = gaussian,\n               prior = c(prior(normal(100, 10), class = Intercept),\n                         prior(normal(0, 10), class = b, coef = \"temp_s\"),\n                         prior(normal(0, 1), class = b, coef = \"temp_s2\"),\n                         prior(normal(0, 1), class = b, coef = \"temp_s3\"),\n                         prior(exponential(1), class = sigma)),\n               iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n               file = here(\"fits\", \"chp4\", \"b4h5-cubic\"))\n\n# spline model\nknots_30 <- quantile(cb_temp$temp, probs = seq(0, 1, length.out = 30))\nB_30 <- bs(cb_temp$temp, knots = knots_30[-c(1, 30)],\n           degree = 3, intercept = TRUE)\n\ncb_temp_30 <- cb_temp %>% \n  mutate(B = B_30)\n\nspl_mod <- brm(doy ~ 1 + B, data = cb_temp_30, family = gaussian,\n               prior = c(prior(normal(100, 10), class = Intercept),\n                         prior(normal(0, 10), class = b),\n                         prior(exponential(1), class = sigma)),\n               iter = 2000, warmup = 1000, chains = 4, cores = 4, seed = 1234,\n               file = here(\"fits\", \"chp4\", \"b4h5-spline\"))\ngrid <- tibble(temp = seq_range(cb_temp_30$temp, 100)) %>% \n  mutate(temp_c = temp - mean(cb_temp$temp),\n         temp_s = temp_c / sd(cb_temp$temp),\n         temp_s2 = temp_s ^ 2,\n         temp_s3 = temp_s ^ 3)\n\nknots_30 <- quantile(grid$temp, probs = seq(0, 1, length.out = 30))\nB_30 <- bs(grid$temp, knots = knots_30[-c(1, 30)],\n           degree = 3, intercept = TRUE)\n\ngrid <- grid %>% \n  mutate(B = B_30)\n\n\nfits <- bind_rows(\n  add_epred_draws(grid, lin_mod) %>%\n    summarize(mean_qi(.epred, .width = c(0.67, 0.89, 0.97)),\n              .groups = \"drop\") %>% \n    select(-B) %>% \n    rename(.epred = y, .lower = ymin, .upper = ymax) %>% \n    mutate(model = \"Linear\"),\n  add_epred_draws(grid, qad_mod) %>%\n    summarize(mean_qi(.epred, .width = c(0.67, 0.89, 0.97)),\n              .groups = \"drop\") %>% \n    select(-B) %>% \n    rename(.epred = y, .lower = ymin, .upper = ymax) %>% \n    mutate(model = \"Quadratic\"),\n  add_epred_draws(grid, cub_mod) %>%\n    summarize(mean_qi(.epred, .width = c(0.67, 0.89, 0.97)),\n              .groups = \"drop\") %>% \n    select(-B) %>% \n    rename(.epred = y, .lower = ymin, .upper = ymax) %>% \n    mutate(model = \"Cubic\"),\n  add_epred_draws(grid, spl_mod) %>%\n    summarize(mean_qi(.epred, .width = c(0.67, 0.89, 0.97)),\n              .groups = \"drop\") %>% \n    select(-B) %>% \n    rename(.epred = y, .lower = ymin, .upper = ymax) %>% \n    mutate(model = \"Spline\")\n) %>%\n  ungroup() %>%\n  mutate(model = factor(model, levels = c(\"Linear\", \"Quadratic\", \"Cubic\",\n                                          \"Spline\")))\n\npreds <- bind_rows(\n  add_predicted_draws(grid, lin_mod) %>%\n    summarize(mean_qi(.prediction, .width = 0.89), .groups = \"drop\") %>% \n    select(-B) %>% \n    rename(.prediction = y, .lower = ymin, .upper = ymax) %>% \n    mutate(model = \"Linear\"),\n  add_predicted_draws(grid, qad_mod) %>%\n    summarize(mean_qi(.prediction, .width = 0.89), .groups = \"drop\") %>% \n    select(-B) %>% \n    rename(.prediction = y, .lower = ymin, .upper = ymax) %>% \n    mutate(model = \"Quadratic\"),\n  add_predicted_draws(grid, cub_mod) %>%\n    summarize(mean_qi(.prediction, .width = 0.89), .groups = \"drop\") %>% \n    select(-B) %>% \n    rename(.prediction = y, .lower = ymin, .upper = ymax) %>% \n    mutate(model = \"Cubic\"),\n  add_predicted_draws(grid, spl_mod) %>%\n    summarize(mean_qi(.prediction, .width = 0.89), .groups = \"drop\") %>% \n    select(-B) %>% \n    rename(.prediction = y, .lower = ymin, .upper = ymax) %>% \n    mutate(model = \"Spline\")\n) %>%\n  ungroup() %>%\n  mutate(model = factor(model, levels = c(\"Linear\", \"Quadratic\", \"Cubic\",\n                                          \"Spline\")))\n\nggplot(cb_temp, aes(x = temp)) +\n  facet_wrap(~model, nrow = 2) +\n  geom_point(aes(y = doy), alpha = 0.2) +\n  geom_ribbon(data = preds, aes(ymin = .lower, ymax = .upper),\n              alpha = 0.2) +\n  geom_lineribbon(data = fits, aes(y = .epred, ymin = .lower, ymax = .upper),\n                  size = .6) +\n  scale_fill_brewer(palette = \"Blues\", breaks = c(0.67, 0.89, 0.97)) +\n  labs(x = \"March Temperature\", y = \"Day in Year\")\ncb_dat <- cherry_blossoms %>%\n  drop_na(doy)\n\nknot_list <- quantile(cb_dat$year, probs = seq(0, 1, length.out = 15))\n\nB <- bs(cb_dat$year,\n        knots = knot_list[-c(1, 15)],\n        degree = 3, intercept = TRUE)\nn <- 50\ntibble(.draw = seq_len(n),\n       alpha = rnorm(n, 100, 10),\n       w = purrr::map(seq_len(n),\n                      function(x, knots) {\n                        w <- rnorm(n = knots + 2, 0, 10)\n                        return(w)\n                      },\n                      knots = 15)) %>%\n  mutate(mu = map2(alpha, w,\n                   function(alpha, w, b) {\n                     res <- b %*% w\n                     res <- res + alpha\n                     res <- res %>%\n                       as_tibble(.name_repair = ~\".value\") %>%\n                       mutate(year = cb_dat$year, .before = 1)\n                     return(res)\n                   },\n                   b = B)) %>%\n  unnest(cols = mu) %>%\n  ggplot(aes(x = year, y = .value)) +\n  geom_vline(xintercept = knot_list, alpha = 0.5) +\n  geom_line(aes(group = .draw)) +\n  expand_limits(y = c(60, 140)) +\n  labs(x = \"Year\", y = \"Day in Year\")\nn <- 50\ntibble(.draw = seq_len(n),\n       alpha = rnorm(n, 100, 10),\n       w = purrr::map(seq_len(n),\n                      function(x, knots) {\n                        w <- rnorm(n = knots + 2, 0, 1)\n                        return(w)\n                      },\n                      knots = 15)) %>%\n  mutate(mu = map2(alpha, w,\n                   function(alpha, w, b) {\n                     res <- b %*% w\n                     res <- res + alpha\n                     res <- res %>%\n                       as_tibble(.name_repair = ~\".value\") %>%\n                       mutate(year = cb_dat$year, .before = 1)\n                     return(res)\n                   },\n                   b = B)) %>%\n  unnest(cols = mu) %>%\n  ggplot(aes(x = year, y = .value)) +\n  geom_vline(xintercept = knot_list, alpha = 0.5) +\n  geom_line(aes(group = .draw)) +\n  expand_limits(y = c(60, 140)) +\n  labs(x = \"Year\", y = \"Day in Year\")\ncb_dat <- cherry_blossoms %>%\n  drop_na(doy)\n\nknots_15 <- quantile(cb_dat$year, probs = seq(0, 1, length.out = 15))\nB_15 <- bs(cb_dat$year, knots = knots_15[-c(1, 15)],\n           degree = 3, intercept = TRUE)\n\ncb_dat_15 <- cb_dat %>% \n  mutate(B = B_15)\n\nb4h8 <- brm(doy ~ 0 + B, data = cb_dat_15, family = gaussian,\n            prior = c(prior(normal(0, 10), class = b),\n                      prior(exponential(1), class = sigma)),\n            iter = 2000, warmup = 1000, chains = 4, cores = 4, seed = 1234,\n            file = here(\"fits\", \"chp4\", \"b4h8\"))\n\nepred_draws(b4h8, cb_dat_15) %>%\n  summarize(mean_qi(.epred, .width = 0.89), .groups = \"drop\") %>%\n  ggplot(aes(x = year, y = doy)) +\n  geom_point(alpha = 0.2) +\n  geom_hline(yintercept = mean(cb_dat$doy), linetype = \"dashed\") +\n  geom_lineribbon(aes(y = y, ymin = ymin, ymax = ymax),\n                  alpha = 0.8, fill = \"#009FB7\") +\n  labs(x = \"Year\", y = \"Day in Year\")\nb4h8_2 <- brm(doy ~ 0 + B, data = cb_dat_15, family = gaussian,\n            prior = c(prior(normal(100, 10), class = b),\n                      prior(exponential(1), class = sigma)),\n            iter = 2000, warmup = 1000, chains = 4, cores = 4, seed = 1234,\n            file = here(\"fits\", \"chp4\", \"b4h8-2\"))\n\nepred_draws(b4h8_2, cb_dat_15) %>%\n  summarize(mean_qi(.epred, .width = 0.89), .groups = \"drop\") %>%\n  ggplot(aes(x = year, y = doy)) +\n  geom_point(alpha = 0.2) +\n  geom_hline(yintercept = mean(cb_dat$doy), linetype = \"dashed\") +\n  geom_lineribbon(aes(y = y, ymin = ymin, ymax = ymax),\n                  alpha = 0.8, fill = \"#009FB7\") +\n  labs(x = \"Year\", y = \"Day in Year\")"},{"path":"linear-models-causal-inference.html","id":"homework-1","chapter":"Week 2: Linear Models & Causal Inference","heading":"2.3 Homework","text":"1. Construct linear regression weight predicted height, using adults (age 18 greater) Howell1 dataset. heights listed recorded !Kung census, weights recorded individuals. Provide predicted weights 89% compatibility intervals individuals. , fill table , using model-based predictions.similar question 4H1 . whereas problem knew weight wanted predict height, know height want predict weight. ’ll start estimating linear model.Using model, can use tidybayes::add_predicted_draws() get model based predictions fill table.2. Howell1 dataset, consider people younger 13 years old. Estimate causal association age weight. Assume age influences weight two paths. First, age influences height, height influences weight. Second, age directly influences weight age-related changes muscle growth body proportions. implies causal model (DAG):Use linear regression estimate total (just direct) causal effect year growth weight. sure carefully consider priors. Try using prior predictive simulation assess imply.example, \\(H\\) pipe. Including \\(H\\) model close pipe, removing indirect effect age weight. Therefore, include age predictor weight model.prior distributions, can assume positive relationship age weight, ’ll use lognormal prior slope. intercept represents weight age 0 (.e., birth weight). typically around 3-4 kg, ’ll use normal prior mean 4 standard deviation 1. results wide range plausible regression lines:priors, can now estimate model.Visualizing posterior, see 89% compatibility interval causal effect age weight (b_age) 1.25 1.42 kg/year.3. Now suppose causal association age weight might different boys girls. Use single linear regression, categorical variable sex, estimate total causal effect age weight separately boys girls. girls boys differ? Provide one posterior contrasts summary.can create separate regression lines sex sex (factor) model formula. ’re now estimating intercept sex, use ~ 0 code indicate estimating global intercept, treating sex variable index variable. also use non-linear syntax {brms}. details approach, see Solomon Kurz’s section indicator variables.comparing two intercepts, see posterior distribution girls (b_a_sex1) slightly lower average distribution boys (b_a_sex2); however, lot overlap distributions. Similarly, posterior distributions slopes also show boys (b_b_sex2) slightly higher slope average girls (b_b_sex1).Let visualize regression lines look like. Overall, boys slightly higher intercept appear increase slightly higher rate. , distributions pretty similar overall.However, interested mean difference boys girls, difference means. estimate contrast need calculate posterior simulations sex. represents distribution expected weights individuals sex. can take difference two distributions. posterior distribution difference, shown figure . Overall, difference relatively small, appear increase age.4 - OPTIONAL CHALLENGE. data data(Oxboys) (rethinking package) growth records 26 boys measured 9 periods. want model growth. Specifically, model increments growth one period (Occasion data table) next. increment simply difference height one occasion height previous occasion. Since none boys shrunk study, growth increments greater zero. Estimate posterior distribution increments. Constrain distribution always positive—possible model think boys can shrink year year. Finally compute posterior distribution total growth 9 occasions.Let’s start looking data.first thing need convert individual height measures increments height. straightforward using dplyr::lag().Now want model increments always positive. easy setting prior, increments outcome, parameter model. can {brms} using lognormal family instead gaussian family used point. tell {brms} outcome normally distributed (.e., gaussian), rather lognormally distributed (.e., constrained positive). Specifically, model defined :\\[\\begin{align}\n  y_i &\\sim \\text{Lognormal}(\\alpha,\\sigma) \\\\\n  \\alpha &\\sim \\text{Normal}(0,0.3) \\\\\n  \\sigma &\\sim \\text{Exponential}(4)\n\\end{align}\\]priors? lot trial error prior predictive simulations. lognormal distribution super intuitive , played different priors found looked reasonable . code prior predictive simulation. prior expects growth increments around 1cm. 89% interval .41cm 1.7cm per occasion. seems reasonable, ’ll move forward.estimate model {brms} specifying family = lognormal.Using model, can examine posterior distribution incremental growth. average, expect boys grow 1.5cm per occasion.cumulative growth across occasions, need simulation 8 incremental changes sum . 9 occasions, expect boys grow 13cm, 89% highest density compatibility interval 8.6cm 18.5cm.","code":"\ndata(Howell1)\nhow_dat <- Howell1 %>%\n  filter(age >= 18) %>%\n  mutate(height_c = height - mean(height))\n\nw2h1 <- brm(weight ~ 1 + height_c, data = how_dat, family = gaussian,\n            prior = c(prior(normal(178, 20), class = Intercept),\n                      prior(normal(0, 10), class = b),\n                      prior(exponential(1), class = sigma)),\n            iter = 2000, warmup = 1000, chains = 4, cores = 4, seed = 1234,\n            file = here(\"fits\", \"hw2\", \"w2h1\"))\ntibble(individual = 1:3,\n       height = c(140, 160, 175)) %>%\n  mutate(height_c = height - mean(how_dat$height)) %>%\n  add_predicted_draws(w2h1) %>%\n  mean_qi(.prediction, .width = 0.89) %>%\n  mutate(range = glue(\"[{sprintf('%0.1f', .lower)}--\",\n                      \"{sprintf('%0.1f', .upper)}]\"),\n         .prediction = sprintf(\"%0.1f\", .prediction)) %>%\n  select(individual, height, exp = .prediction, range) %>%\n  kbl(align = \"c\", booktabs = TRUE,\n      col.names = c(\"Individual\", \"height\", \"expected weight\", \"89% interval\"))\nset.seed(123)\nn <- 50\ntibble(group = seq_len(n),\n       alpha = rnorm(n, 4, 1),\n       beta = rlnorm(n, 0, 1)) %>%\n  expand(nesting(group, alpha, beta), age = 0:12) %>%\n  mutate(weight = alpha + beta * age) %>%\n  ggplot(aes(x = age, y = weight, group = group)) +\n  geom_line() +\n  scale_x_continuous(breaks = seq(0, 12, 2)) +\n  coord_cartesian(xlim = c(0, 12), ylim = c(0, 30)) +\n  labs(x = \"Age\", y = \"Weight\")\ndata(Howell1)\nkid_dat <- Howell1 %>%\n  filter(age < 13)\n\nw2h2 <- brm(weight ~ 1 + age, data = kid_dat, family = gaussian,\n            prior = c(prior(normal(4, 1), class = Intercept),\n                      prior(normal(0, 1), class = b),\n                      prior(exponential(1), class = sigma)),\n            iter = 2000, warmup = 1000, chains = 4, cores = 4, seed = 1234,\n            file = here(\"fits\", \"hw2\", \"w2h2\"))\ndraws <- gather_draws(w2h2, b_Intercept, b_age, sigma)\n\nmean_qi(draws, .width = 0.89)\n#> # A tibble: 3 × 7\n#>   .variable   .value .lower .upper .width .point .interval\n#>   <chr>        <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n#> 1 b_age         1.34   1.25   1.42   0.89 mean   qi       \n#> 2 b_Intercept   7.00   6.42   7.59   0.89 mean   qi       \n#> 3 sigma         2.58   2.34   2.85   0.89 mean   qi\n\nggplot(draws, aes(x = .value, y = .variable)) +\n  stat_halfeye(.width = 0.89) +\n  labs(x = \"Parameter value\", y = \"Parameter\")\nkid_dat <- kid_dat %>% \n  mutate(sex = male + 1,\n         sex = factor(sex))\n\nw2h3 <- brm(\n  bf(weight ~ 0 + a + b * age,\n     a ~ 0 + sex,\n     b ~ 0 + sex,\n     nl = TRUE),\n  data = kid_dat, family = gaussian,\n  prior = c(prior(normal(4, 1), class = b, coef = sex1, nlpar = a),\n            prior(normal(4, 1), class = b, coef = sex2, nlpar = a),\n            prior(normal(0, 1), class = b, coef = sex1, nlpar = b),\n            prior(normal(0, 1), class = b, coef = sex2, nlpar = b),\n            prior(exponential(1), class = sigma)),\n  iter = 2000, warmup = 1000, chains = 4, cores = 4, seed = 1234,\n  file = here(\"fits\", \"hw2\", \"w2h3\")\n)\ndraws <- gather_draws(w2h3, b_a_sex1, b_a_sex2, b_b_sex1, b_b_sex2, sigma)\n\nmean_qi(draws, .width = 0.89)\n#> # A tibble: 5 × 7\n#>   .variable .value .lower .upper .width .point .interval\n#>   <chr>      <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n#> 1 b_a_sex1    6.50   5.79   7.21   0.89 mean   qi       \n#> 2 b_a_sex2    7.11   6.34   7.86   0.89 mean   qi       \n#> 3 b_b_sex1    1.36   1.25   1.47   0.89 mean   qi       \n#> 4 b_b_sex2    1.48   1.37   1.60   0.89 mean   qi       \n#> 5 sigma       2.49   2.26   2.74   0.89 mean   qi\n\nggplot(draws, aes(x = .value, y = .variable)) +\n  stat_halfeye(.width = 0.89) +\n  labs(x = \"Parameter value\", y = \"Parameter\")\nnew_age <- expand_grid(age = 0:12, sex = factor(c(1, 2)))\n\nall_lines <- new_age %>% \n  add_epred_draws(w2h3) %>% \n  ungroup() %>% \n  mutate(group = paste0(sex, \"_\", .draw))\n\nplot_lines <- all_lines %>%\n  filter(.draw %in% sample(unique(.data$.draw), size = 1000)) %>% \n  select(-.draw)\n\nanimate_lines <- all_lines %>%\n  filter(.draw %in% sample(unique(.data$.draw), size = 50))\n\nggplot(animate_lines, aes(x = age, y = .epred, color = sex, group = group)) +\n  geom_line(data = plot_lines, alpha = 0.01, show.legend = FALSE) + \n  geom_point(data = kid_dat, aes(x = age, y = weight, color = sex),\n             inherit.aes = FALSE) +\n  geom_line(alpha = 1, show.legend = FALSE, color = \"black\") +\n  scale_color_okabeito(labels = c(\"Girls\", \"Boys\")) +\n  scale_x_continuous(breaks = seq(0, 12, 2)) +\n  labs(x = \"Age\", y = \"Weight (kg)\", color = NULL) +\n  guides(color = guide_legend(override.aes = list(size = 3))) +\n  transition_states(.draw, 0, 1)\ncontrast <- new_age %>% \n  add_predicted_draws(w2h3) %>% \n  ungroup() %>% \n  select(age, sex, .draw, .prediction) %>% \n  mutate(sex = fct_recode(sex,\n                          \"Girls\" = \"1\",\n                          \"Boys\" = \"2\")) %>% \n  pivot_wider(names_from = sex, values_from = .prediction) %>% \n  mutate(diff = Boys - Girls)\n\nggplot(contrast, aes(x = age, y = diff)) +\n  stat_lineribbon(aes(fill_ramp = stat(.width)), .width = ppoints(50),\n                  fill = \"#009FB7\", show.legend = FALSE) +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  scale_fill_ramp_continuous(from = \"transparent\", range = c(1, 0)) +\n  scale_x_continuous(breaks = seq(0, 12, 2)) +\n  labs(x = \"Age\", y = \"Weight difference (kg; Boys-Girls)\")\ndata(Oxboys)\nhead(Oxboys)\n#>   Subject     age height Occasion\n#> 1       1 -1.0000    140        1\n#> 2       1 -0.7479    143        2\n#> 3       1 -0.4630    145        3\n#> 4       1 -0.1643    147        4\n#> 5       1 -0.0027    148        5\n#> 6       1  0.2466    150        6\nincrements <- Oxboys %>% \n  group_by(Subject) %>% \n  mutate(previous_height = lag(height),\n         change = height - previous_height) %>% \n  filter(!is.na(change)) %>% \n  ungroup()\n\nincrements\n#> # A tibble: 208 × 6\n#>    Subject     age height Occasion previous_height change\n#>      <int>   <dbl>  <dbl>    <int>           <dbl>  <dbl>\n#>  1       1 -0.748    143.        2            140.  2.90 \n#>  2       1 -0.463    145.        3            143.  1.40 \n#>  3       1 -0.164    147.        4            145.  2.30 \n#>  4       1 -0.0027   148.        5            147.  0.600\n#>  5       1  0.247    150.        6            148.  2.5  \n#>  6       1  0.556    152.        7            150.  1.5  \n#>  7       1  0.778    153.        8            152.  1.60 \n#>  8       1  0.994    156.        9            153.  2.5  \n#>  9       2 -0.748    139.        2            137.  2.20 \n#> 10       2 -0.463    140.        3            139.  1    \n#> # … with 198 more rows\nset.seed(123)\n\nn <- 1000\ntibble(alpha = rnorm(n, mean = 0, sd = 0.3),\n       sigma = rexp(n, rate = 4)) %>% \n  mutate(sim_change = rlnorm(n, meanlog = alpha, sdlog = sigma)) %>% \n  ggplot(aes(x = sim_change)) +\n  geom_density() +\n  labs(x = \"Prior Expectation for Incremental Growth (cm)\", y = \"Density\")\nw2h4 <- brm(change ~ 1, data = increments, family = lognormal,\n            prior = c(prior(normal(0, 0.3), class = Intercept),\n                      prior(exponential(4), class = sigma)),\n            iter = 2000, warmup = 1000, chains = 4, cores = 4, seed = 1234,\n            file = here(\"fits\", \"hw2\", \"w2h4\"))\nset.seed(234)\n\nas_draws_df(w2h4) %>% \n  mutate(post_change = rlnorm(n(), meanlog = b_Intercept, sdlog = sigma)) %>% \n  ggplot(aes(x = post_change)) +\n  geom_density() +\n  labs(x = \"Posterior Distribution for Incremental Growth (cm)\",\n       y = \"Density\")\nset.seed(345)\n\nas_draws_df(w2h4) %>% \n  mutate(all_change = map2_dbl(b_Intercept, sigma, ~sum(rlnorm(8, .x, .y)))) %>% \n  ggplot(aes(x = all_change)) +\n  stat_halfeye(aes(fill = stat(between(x, 8.6, 18.5))), color = NA) +\n  scale_fill_manual(values = c(\"#009FB7\", NA),\n                    labels = \"89% Compatibility Interval\",\n                    breaks = \"TRUE\", na.value = \"#F0F0F0\") +\n  labs(x = \"Posterior Distribution for Cumulative Growth (cm)\",\n       y = \"Density\", fill = NULL)"},{"path":"causes-confounds-colliders.html","id":"causes-confounds-colliders","chapter":"Week 3: Causes, Confounds & Colliders","heading":"Week 3: Causes, Confounds & Colliders","text":"third week covers Chapter 5 (Many Variables & Spurious Waffles) Chapter 6 (Haunted DAG & Causal Terror).","code":""},{"path":"causes-confounds-colliders.html","id":"lectures-2","chapter":"Week 3: Causes, Confounds & Colliders","heading":"3.1 Lectures","text":"Lecture 5:Lecture 6:","code":""},{"path":"causes-confounds-colliders.html","id":"exercises-2","chapter":"Week 3: Causes, Confounds & Colliders","heading":"3.2 Exercises","text":"","code":""},{"path":"causes-confounds-colliders.html","id":"chapter-5","chapter":"Week 3: Causes, Confounds & Colliders","heading":"3.2.1 Chapter 5","text":"5E1. linear models multiple linear regressions?\n\\[\\begin{align}\n(1)\\ \\ \\mu_i &= \\alpha + \\beta x_i \\\\\n(2)\\ \\ \\mu_i &= \\beta_x x_i + \\beta_z z_i \\\\\n(3)\\ \\ \\mu_i &= \\alpha + \\beta(x_i - z_i) \\\\\n(4)\\ \\ \\mu_i &= \\alpha + \\beta_x x_i + \\beta_z z_i\n\\end{align}\\]Numbers 2 4 multiple regressions. Number 1 contains one predictor variable. Number 3, although two variables appear model, also uses difference \\(x\\) \\(z\\) single predictor. numbers 2 4 contain multiple predictor variables.5E2. Write multiple regression evaluate claim: Animal diversity linearly related latitude, controlling plant diversity. just need write model definition.denote animal diversity \\(\\), latitude \\(L\\), plant diversity \\(P\\). linear model can defined follows:\\[\\begin{align}\n  A_i &\\sim \\text{Normal}(\\mu, \\sigma) \\\\\n  \\mu_i &= \\alpha + \\beta_L L_i + \\beta_P P_i\n\\end{align}\\]5E3. Write multiple regression evaluate claim: Neither amount funding size laboratory good predictor time PhD degree; together variables positively associated time degree. Write model definition indicate side zero slope parameter .denote time PhD degree \\(T\\), amount funding \\(F\\), size laboratory \\(L\\). model defined :\\[\\begin{align}\n  T_i &\\sim \\text{Normal}(\\mu_i, \\sigma) \\\\\n  \\mu_i &= \\alpha + \\beta_F F_i + \\beta_L L_i\n\\end{align}\\]\\(\\beta_F\\) \\(\\beta_L\\) positive. order funding lab size show positive relationship together relationship separately, two variables need negatively correlated (.e., large labs less funding per student small labs funding per student). positively associated outcome, negatively associated real world. Thus, analyzing variables isolation may mask positive relationship.5E4. Suppose single categorical predictor 4 levels (unique values), labeled , B, C D. Let \\(A_i\\) indicator variable 1 case \\(\\) category \\(\\). Also suppose \\(B_i\\), \\(C_i\\), \\(D_i\\) categories. Now following linear models inferentially equivalent ways include categorical variable regression? Model inferentially equivalent ’s possible compute one posterior distribution posterior distribution another model.\n\\[\\begin{align}\n(1)\\ \\ \\mu_i &= \\alpha + \\beta_A A_i + \\beta_B B_i + \\beta_D D_i \\\\\n(2)\\ \\ \\mu_i &= \\alpha + \\beta_A A_i + \\beta_B B_i + \\beta_C C_i + \\beta_D D_i \\\\\n(3)\\ \\ \\mu_i &= \\alpha + \\beta_B B_i + \\beta_C C_i + \\beta_D D_i \\\\\n(4)\\ \\ \\mu_i &= \\alpha_A A_i + \\alpha_B B_i + \\alpha_C C_i + \\alpha_D D_i \\\\\n(5)\\ \\ \\mu_i &= \\alpha_A (1 - B_i - C_i - D_i) + \\alpha_B B_i + \\alpha_C C_i + \\alpha_D D_i\n\\end{align}\\]Numbers 1, 3, 4, 5 inferentially equivalent. Numbers 1 3 use 3 4 indicator variables, meaning can always calculate 4th three estimated intercept. Number 4 equivalent index variable approach, inferentially equivalent indicator variable approach. Finally, Number 5 mathematically equivalent Number 4, assuming observation can belong 1 4 groups.Number 2 valid model representation, model contain \\(k-1\\) indicator variables intercept (using indicator variable approach). 4 included definition Number 2, expect estimation problems (model estimate ).5M1. Invent example spurious correlation. outcome variable correlated predictor variables. predictors entered model, correlation outcome one predictors mostly vanish (least greatly reduced).(simulated) example, ’ll predict ice cream sales temperature number shark attacks. First, ’ll fit two bivariate regressions, mod_t mod_s, include temperature shark attacks predictors, respectively. ’ll estimate multivariate regression, mod_all, includes predictors.plot shows posterior distributions \\(\\beta\\) coefficients temperature shark attacks. expected, positive relationship ice cream sales bivariate models. However, predictors included mod_all, posterior distribution b_shark moves zero, whereas distribution b_temp remains basically . Thus, relationship ice cream sales shark attacks spurious correlation, informed temperature.5M2. Invent example masked relationship. outcome variable correlated predictor variables, opposite directions. two predictor variables correlated one another.(also simulated) example, ’ll predict academic test score amount instruction student received number days missed class. First, ’ll fit two bivariate regressions, mod_i mod_d, include instruction days away predictors, respectively. ’ll estimate multivariate regression, mod_test, includes predictors.figure shows posterior distributions \\(\\beta\\) parameters models. can see full model, mod_test, b_instruction gets positive b_days_away gets negative.5M3. sometimes observed best predictor fire risk presence firefighters—State localities many firefighters also fires. Presumably firefighters cause fires. Nevertheless, spurious correlation. Instead fires cause firefighters. Consider reversal causal inference context divorce marriage data. might high divorce rate cause higher marriage rate? Can think way evaluate relationship, using multiple regression?high divorce rate means people available population single-people available marry. Additionally, people may getting divorced specific purpose marrying someone else. evaluate , add marriage number, “re-marry” indicator. expect coefficient marriage rate get closer zero predictor added model.5M4. divorce data, States high numbers members Church Jesus Christ Latter-day Saints (LDS) much lower divorce rates regression models expected. Find list LDS population State use numbers predictor variable, predicting divorce rate using marriage rate, median age marriage, percent LDS population (possibly standardized). may want consider transformations raw percent LDS variable.can pull LDS membership official LDS website, state populations United States census website. Conveniently, pulled together World Population Review (copied January 4, 2022). data saved data/lds-data-2021.csv. can combine existing divorce data data(\"WaffleDivorce\"). analysis, ’ll use LDS membership per capita. Specifically, number LDS members per 100,000 state’s population. standardized, along predictor variables, done chapter examples.’re now ready estimate model.Finally, can visualize estimates. intercept coefficients Marriage MedianAgeMarriage nearly identical model m5.3 text. Thus, appears new predictor, LDS per capita, contributing unique information. expected, higher population LDS members state associated lower divorce rate.5M5. One way reason multiple causation hypotheses imagine detailed mechanisms predictor variables may influence outcomes. example, sometimes argued price gasoline (predictor variable) positively associated lower obesity rates (outcome variable). However, least two important mechanisms price gas reduce obesity. First, lead less driving therefore exercise. Second, lead less driving, leads less eating , leds less consumption huge restaurant meals. Can outline one multiple regressions address two mechanisms? Assume can predictor data need.Let’s assume four variables: rate obesity (\\(O\\)), price gasoline (\\(G\\)), amount driving (\\(D\\)), amount exercise (\\(E\\)), rate eating restaurants (\\(R\\)). Given variables, can outline first proposed mechanism implies:\\(D\\) negatively associated \\(P\\)\\(E\\) negatively associated \\(D\\)\\(O\\) negatively associated \\(E\\)chain causality, outcome input next chain. second mechanism similar:\\(D\\) negatively associated \\(P\\)\\(R\\) positively associated \\(D\\)\\(O\\) positively associated \\(R\\)5H1. divorce example, suppose DAG : \\(M \\rightarrow \\rightarrow D\\). implied conditional independencies graph? data consistent ?can use {dagitty} (Textor et al., 2021) see implied conditional independencies. code see DAG implies divorce rate independent marriage rate conditional median age marriage.shown model m5.3, data consistent implied conditional independency. Thus data consistent multiple DAGs. Specifically, support Markov Equivalent DAGs. second DAG list, D <- -> M, DAG investigated text.5H2. Assuming DAG divorce example indeed \\(M \\rightarrow \\rightarrow D\\), fit new model use estimate counterfactual effect halving State’s marriage rate \\(M\\). Using counterfactual example chapter (starting page 140) template.First, ’ll estimate model consistent DAG. two regressions , ’ll use {brms}’s multivariate syntax (.e., bf(); see ).can simulate counterfactuals plot {ggplot2}. see negative relationship marriage rate age. , marriage rate increases, age marriage decreases average. Specifically, \\(\\) moves -0.7 units every 1 unit increase \\(M\\), reflected estimate A_M model summary . counterfactual \\(M\\) \\(D\\), see positive relationship. relationship \\(M\\) \\(\\) \\(\\) \\(D\\) negative. words, \\(M\\) increases \\(\\) decreases, \\(\\) decreases \\(D\\) increases. every one unit increase \\(M\\), expect 0.4 unit increase \\(D\\). can also derived multiplying slope coefficients model summary (.e., −0.56 × −0.69 ≈ 0.4).question specifically asks counterfactual effect halving state’s marriage rate. dependent original marriage rate . problem, ’ll use average marriage rate across states, 20. Half 10, standardized units used fit model -2.66. Looking counterfactual plot, moving \\(M\\) 0 \\(M\\) -2.66 result decrease divorce rate 1 standard deviation. can calculate directly using code well. also see estimated difference -1.03 standard deviations, 89% posterior interval -3.14 1.08.5H3. Return milk energy model, m5.7. Suppose true causal relationship among variables :Now compute counterfactual effect \\(K\\) doubling \\(M\\). need account direct indirect paths causation. Use counterfactual example chapter (starting page 140) template.First, need estimate model.Now can calculate counterfactual. \\(M\\) represents mass, ’ll use evenly spaced values 0.5 80, captures range observed mass data. ’ll predict new values \\(K\\) masses.can see plot, mass log-transformed model, non-linear relationship manipulated mass counterfactual. Thus, impact doubling mass depends original mass. previous example, ’ll use average mass (≈15kg) baseline. Thus standardized log units used estimate model, ’re comparing \\(M\\) value 0.746 1.154. code shows doubling mass small effect \\(K\\) quick wide compatibility interval.5H4. open practice problem engage imagination. divorce data, States southern United States many highest divorce rates. Add South indicator variable analysis. First, draw one DAGs represent ideas Southern American culture might influence three variables (\\(D\\), \\(M\\), \\(\\)). list testable implications DAGs, , fit one models evaluate implications. think influence “Southerness” ?First, let’s draw DAG using {ggdag} (Barrett, 2021).proposed model, hypothesizing southerness influences median age marriage marriage rate. can use {dagitty} view testable implications:Given DAG, divorce rate independent southerness condition median age marriage marriage rate. Let’s estimate model test . ’ll include median age marriage (\\(\\)), marriage rate (\\(M\\)), southerness (\\(S\\)) model. \\(\\) \\(M\\) included, expect coefficient \\(S\\) zero, implied conditional independency holds.Now can look posterior distribution \\(\\beta\\) coefficient southerness.effect southerness close zero, slightly larger might expected. Thus, preliminary evidence DAG drawn may accurate. However, evidence strong enough refute proposed DAG either.","code":"\nset.seed(2022)\nn <- 100\ntemp <- rnorm(n)\nshark <- rnorm(n, temp)\nice_cream <- rnorm(n, temp)\n\nspur_exp <- tibble(ice_cream, temp, shark) %>%\n  mutate(across(everything(), standardize))\n\nmod_t <- brm(ice_cream ~ 1 + temp, data = spur_exp, family = gaussian,\n             prior = c(prior(normal(0, 0.2), class = Intercept),\n                       prior(normal(0, 0.5), class = b),\n                       prior(exponential(1), class = sigma)),\n             iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n             file = here(\"fits\", \"chp5\", \"b5m1-t\"))\n\nmod_s <- brm(ice_cream ~ 1 + shark, data = spur_exp, family = gaussian,\n             prior = c(prior(normal(0, 0.2), class = Intercept),\n                       prior(normal(0, 0.5), class = b),\n                       prior(exponential(1), class = sigma)),\n             iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n             file = here(\"fits\", \"chp5\", \"b5m1-s\"))\n\nmod_all <- brm(ice_cream ~ 1 + temp + shark, data = spur_exp, family = gaussian,\n               prior = c(prior(normal(0, 0.2), class = Intercept),\n                         prior(normal(0, 0.5), class = b),\n                         prior(exponential(1), class = sigma)),\n               iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n               file = here(\"fits\", \"chp5\", \"b5m1-all\"))\nbind_rows(\n  spread_draws(mod_t, b_temp) %>%\n    mutate(model = \"mod_t\"),\n  spread_draws(mod_s, b_shark) %>%\n    mutate(model = \"mod_s\"),\n  spread_draws(mod_all, b_temp, b_shark) %>%\n    mutate(model = \"mod_all\")\n) %>%\n  pivot_longer(cols = starts_with(\"b_\"), names_to = \"parameter\",\n               values_to = \"value\") %>%\n  drop_na(value) %>%\n  mutate(model = factor(model, levels = c(\"mod_t\", \"mod_s\", \"mod_all\")),\n         parameter = factor(parameter, levels = c(\"b_temp\", \"b_shark\"))) %>%\n  ggplot(aes(x = value, y = fct_rev(model))) +\n  facet_wrap(~parameter, nrow = 1) +\n  stat_halfeye(.width = 0.89) +\n  labs(x = \"Parameter Value\", y = \"Model\")\nset.seed(2020)\nn <- 100\nu <- rnorm(n)\ndays_away <- rnorm(n, u)\ninstruction <- rnorm(n, u)\ntest_score <- rnorm(n, instruction - days_away)\n\nmask_exp <- tibble(test_score, instruction, days_away) %>%\n  mutate(across(everything(), standardize))\n\nmod_i <- brm(test_score ~ 1 + instruction, data = mask_exp, family = gaussian,\n             prior = c(prior(normal(0, 0.2), class = Intercept),\n                       prior(normal(0, 0.5), class = b),\n                       prior(exponential(1), class = sigma)),\n             iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n             file = here(\"fits\", \"chp5\", \"b5m2-i\"))\n\nmod_d <- brm(test_score ~ 1 + days_away, data = mask_exp, family = gaussian,\n             prior = c(prior(normal(0, 0.2), class = Intercept),\n                       prior(normal(0, 0.5), class = b),\n                       prior(exponential(1), class = sigma)),\n             iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n             file = here(\"fits\", \"chp5\", \"b5m2-d\"))\n\nmod_test <- brm(test_score ~ 1 + instruction + days_away, data = mask_exp,\n                family = gaussian,\n                prior = c(prior(normal(0, 0.2), class = Intercept),\n                          prior(normal(0, 0.5), class = b),\n                          prior(exponential(1), class = sigma)),\n                iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n                file = here(\"fits\", \"chp5\", \"b5m2-test\"))\nbind_rows(\n  spread_draws(mod_i, b_instruction) %>%\n    mutate(model = \"mod_i\"),\n  spread_draws(mod_d, b_days_away) %>%\n    mutate(model = \"mod_d\"),\n  spread_draws(mod_test, b_instruction, b_days_away) %>%\n    mutate(model = \"mod_test\")\n) %>%\n  pivot_longer(cols = starts_with(\"b_\"), names_to = \"parameter\",\n               values_to = \"value\") %>%\n  drop_na(value) %>%\n  mutate(model = factor(model, levels = c(\"mod_i\", \"mod_d\", \"mod_test\")),\n         parameter = factor(parameter, levels = c(\"b_instruction\",\n                                                  \"b_days_away\"))) %>%\n  ggplot(aes(x = value, y = fct_rev(model))) +\n  facet_wrap(~parameter, nrow = 1) +\n  stat_halfeye(.width = 0.89) +\n  labs(x = \"Parameter Value\", y = \"Model\")\nlds <- read_csv(here(\"data\", \"lds-data-2021.csv\"),\n                col_types = cols(.default = col_integer(),\n                                 state = col_character())) %>%\n  mutate(lds_prop = members / population,\n         lds_per_capita = lds_prop * 100000)\n\ndata(\"WaffleDivorce\")\nlds_divorce <- WaffleDivorce %>%\n  as_tibble() %>%\n  select(Location, Divorce, Marriage, MedianAgeMarriage) %>%\n  left_join(select(lds, state, lds_per_capita),\n            by = c(\"Location\" = \"state\")) %>%\n  mutate(lds_per_capita = log(lds_per_capita)) %>%\n  mutate(across(where(is.numeric), standardize)) %>% \n  filter(!is.na(lds_per_capita))\n\nlds_divorce\n#> # A tibble: 49 × 5\n#>    Location    Divorce Marriage MedianAgeMarriage lds_per_capita\n#>    <chr>         <dbl>    <dbl>             <dbl>          <dbl>\n#>  1 Alabama       1.65    0.0226            -0.606         -0.423\n#>  2 Alaska        1.54    1.55              -0.687          1.21 \n#>  3 Arizona       0.611   0.0490            -0.204          1.42 \n#>  4 Arkansas      2.09    1.66              -1.41          -0.123\n#>  5 California   -0.927  -0.267              0.600          0.409\n#>  6 Colorado      1.05    0.892             -0.285          0.671\n#>  7 Connecticut  -1.64   -0.794              1.24          -0.909\n#>  8 Delaware     -0.433   0.786              0.439         -0.693\n#>  9 Florida      -0.652  -0.820              0.278         -0.466\n#> 10 Georgia       0.995   0.523             -0.124         -0.375\n#> # … with 39 more rows\nlds_mod <- brm(Divorce ~ 1 + Marriage + MedianAgeMarriage + lds_per_capita,\n               data = lds_divorce, family = gaussian,\n               prior = c(prior(normal(0, 0.2), class = Intercept),\n                         prior(normal(0, 0.5), class = b, coef = Marriage),\n                         prior(normal(0, 0.5), class = b, coef = MedianAgeMarriage),\n                         prior(normal(0, 0.5), class = b, coef = lds_per_capita),\n                         prior(exponential(1), class = sigma)),\n               iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n               file = here(\"fits\", \"chp5\", \"b5m4\"))\nspread_draws(lds_mod, `b_.*`, regex = TRUE) %>%\n  pivot_longer(starts_with(\"b_\"), names_to = \"parameter\",\n               values_to = \"value\") %>%\n  ggplot(aes(x = value, y = parameter)) +\n  stat_halfeye(.width = c(0.67, 0.89, 0.97)) +\n  labs(x = \"Parameter Value\", y = \"Parameter\")\nlibrary(dagitty)\n\nmad_dag <- dagitty(\"dag{M -> A -> D}\")\nimpliedConditionalIndependencies(mad_dag)\n#> D _||_ M | A\nequivalentDAGs(mad_dag)\n#> [[1]]\n#> dag {\n#> A\n#> D\n#> M\n#> A -> D\n#> M -> A\n#> }\n#> \n#> [[2]]\n#> dag {\n#> A\n#> D\n#> M\n#> A -> D\n#> A -> M\n#> }\n#> \n#> [[3]]\n#> dag {\n#> A\n#> D\n#> M\n#> A -> M\n#> D -> A\n#> }\ndat <- WaffleDivorce %>%\n  select(A = MedianAgeMarriage,\n         D = Divorce,\n         M = Marriage) %>%\n  mutate(across(everything(), standardize))\n\nd_model <- bf(D ~ 1 + A)\na_model <- bf(A ~ 1 + M)\n\nb5h2 <- brm(d_model + a_model + set_rescor(FALSE),\n            data = dat, family = gaussian,\n            prior = c(prior(normal(0, 0.2), class = Intercept, resp = D),\n                      prior(normal(0, 0.5), class = b, resp = D),\n                      prior(exponential(1), class = sigma, resp = D),\n                      \n                      prior(normal(0, 0.2), class = Intercept, resp = A),\n                      prior(normal(0, 0.5), class = b, resp = A),\n                      prior(exponential(1), class = sigma, resp = A)),\n            iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n            file = here(\"fits\", \"chp5\", \"b5h2\"))\n\nsummary(b5h2)\n#>  Family: MV(gaussian, gaussian) \n#>   Links: mu = identity; sigma = identity\n#>          mu = identity; sigma = identity \n#> Formula: D ~ 1 + A \n#>          A ~ 1 + M \n#>    Data: dat (Number of observations: 50) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 0; thin = 1;\n#>          total post-warmup draws = 8000\n#> \n#> Population-Level Effects: \n#>             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> D_Intercept     0.00      0.10    -0.20     0.20 1.00    10726     6132\n#> A_Intercept    -0.00      0.09    -0.17     0.18 1.00    10190     6073\n#> D_A            -0.56      0.11    -0.78    -0.34 1.00     9422     6605\n#> A_M            -0.69      0.10    -0.89    -0.49 1.00     8993     5538\n#> \n#> Family Specific Parameters: \n#>         Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sigma_D     0.82      0.09     0.67     1.01 1.00    10660     5820\n#> sigma_A     0.71      0.07     0.58     0.88 1.00    10351     6034\n#> \n#> Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\nas_draws_df(b5h2) %>%\n  as_tibble() %>%\n  select(.draw, b_D_Intercept:sigma_A) %>% \n  expand(nesting(.draw, b_D_Intercept, b_A_Intercept, b_D_A, b_A_M,\n                 sigma_D, sigma_A),\n         m = seq(from = -2, to = 2, length.out = 30)) %>%\n  mutate(a_sim = rnorm(n(), mean = b_A_Intercept + b_A_M * m, sd = sigma_A),\n         d_sim = rnorm(n(), mean = b_D_Intercept + b_D_A * a_sim, sd = sigma_D)) %>%\n  pivot_longer(ends_with(\"_sim\"), names_to = \"name\", values_to = \"value\") %>%\n  group_by(m, name) %>%\n  mean_qi(value, .width = c(0.89)) %>%\n  ungroup() %>%\n  mutate(name = case_when(name == \"a_sim\" ~ \"Counterfactual M &rarr; A\",\n                          TRUE ~ \"Counterfactual M &rarr; A &rarr; D\")) %>%\n  ggplot(aes(x = m, y = value, ymin = .lower, ymax = .upper)) +\n  facet_wrap(~name, nrow = 1) +\n  geom_smooth(stat = \"identity\") +\n  labs(x = \"Manipulated M\", y = \"Counterfactual\")\nas_draws_df(b5h2) %>% \n  mutate(a_avg = rnorm(n(), b_A_Intercept + b_A_M * 0, sigma_A),\n         a_hlf = rnorm(n(), b_A_Intercept + b_A_M * -2.66, sigma_A),\n         d_avg = rnorm(n(), b_D_Intercept + b_D_A * a_avg, sigma_D),\n         d_hlf = rnorm(n(), b_D_Intercept + b_D_A * a_hlf, sigma_D),\n         diff = d_hlf - d_avg) %>% \n  mean_hdi(diff, .width = 0.89)\n#> # A tibble: 1 × 6\n#>    diff .lower .upper .width .point .interval\n#>   <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n#> 1 -1.03  -3.11   1.09   0.89 mean   hdi\ndata(milk)\n\nnew_milk <- milk %>%\n  select(kcal.per.g,\n         neocortex.perc,\n         mass) %>%\n  drop_na(everything()) %>%\n  mutate(log_mass = log(mass),\n         K = standardize(kcal.per.g),\n         N = standardize(neocortex.perc),\n         M = standardize(log_mass))\n\nK_model <- bf(K ~ 1 + M + N)\nN_model <- bf(N ~ 1 + M)\n\nb5h3 <- brm(K_model + N_model + set_rescor(FALSE),\n            data = new_milk, family = gaussian,\n            prior = c(prior(normal(0, 0.2), class = Intercept, resp = K),\n                      prior(normal(0, 0.5), class = b, resp = K),\n                      prior(exponential(1), class = sigma, resp = K),\n                      \n                      prior(normal(0, 0.2), class = Intercept, resp = N),\n                      prior(normal(0, 0.5), class = b, resp = N),\n                      prior(exponential(1), class = sigma, resp = N)),\n            iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n            file = here(\"fits\", \"chp5\", \"b5h3\"))\n\nsummary(b5h3)\n#>  Family: MV(gaussian, gaussian) \n#>   Links: mu = identity; sigma = identity\n#>          mu = identity; sigma = identity \n#> Formula: K ~ 1 + M + N \n#>          N ~ 1 + M \n#>    Data: new_milk (Number of observations: 17) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 0; thin = 1;\n#>          total post-warmup draws = 8000\n#> \n#> Population-Level Effects: \n#>             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> K_Intercept     0.00      0.14    -0.27     0.28 1.00     8841     5684\n#> N_Intercept     0.00      0.13    -0.25     0.26 1.00     9335     5242\n#> K_M            -0.68      0.27    -1.17    -0.11 1.00     5097     5278\n#> K_N             0.57      0.26     0.02     1.05 1.00     4924     5189\n#> N_M             0.66      0.17     0.32     0.98 1.00     8326     5454\n#> \n#> Family Specific Parameters: \n#>         Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sigma_K     0.81      0.17     0.56     1.21 1.00     6085     5711\n#> sigma_N     0.72      0.14     0.50     1.05 1.00     8236     5409\n#> \n#> Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\nmilk_cf <- as_draws_df(b5h3) %>%\n  as_tibble() %>% \n  select(.draw, b_K_Intercept:sigma_N) %>% \n  expand(nesting(.draw, b_K_Intercept, b_N_Intercept, b_K_M, b_K_N, b_N_M,\n                 sigma_K, sigma_N),\n         mass = seq(from = 0.5, to = 80, by = 0.5)) %>%\n  mutate(log_mass = log(mass),\n         M = (log_mass - mean(new_milk$log_mass)) / sd(new_milk$log_mass),\n         n_sim = rnorm(n(), mean = b_N_Intercept + b_N_M * M, sd = sigma_N),\n         k_sim = rnorm(n(), mean = b_K_Intercept + b_K_N * n_sim + b_K_M * M,\n                       sd = sigma_K)) %>%\n  pivot_longer(ends_with(\"_sim\"), names_to = \"name\", values_to = \"value\") %>%\n  group_by(mass, name) %>%\n  mean_qi(value, .width = c(0.89)) %>%\n  ungroup() %>%\n  filter(name == \"k_sim\") %>%\n  mutate(name = case_when(name == \"n_sim\" ~ \"Counterfactual effect M on N\",\n                          TRUE ~ \"Total Counterfactual effect of M on K\"))\n\nggplot(milk_cf, aes(x = mass, y = value, ymin = .lower, ymax = .upper)) +\n  geom_smooth(stat = \"identity\") +\n  labs(x = \"Manipulated Mass\", y = \"Counterfactual K\")\n(log(c(15, 30)) - mean(log(milk$mass))) / sd(log(milk$mass)) \n#> [1] 0.746 1.154\n\nas_draws_df(b5h3) %>% \n  mutate(n_avg = rnorm(n(), b_N_Intercept + b_N_M * 0.746, sigma_N),\n         n_dbl = rnorm(n(), b_N_Intercept + b_N_M * 1.154, sigma_N),\n         k_avg = rnorm(n(), b_K_Intercept + b_K_M * 0.746 + b_K_N * n_avg,\n                       sigma_K),\n         k_dbl = rnorm(n(), b_K_Intercept + b_K_M * 1.154 + b_K_N * n_dbl,\n                       sigma_K),\n         diff = k_dbl - k_avg) %>% \n  median_hdi(diff, .width = 0.89)\n#> # A tibble: 1 × 6\n#>     diff .lower .upper .width .point .interval\n#>    <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n#> 1 -0.151  -2.45   1.82   0.89 median hdi\ndag_coords <-\n  tibble(name = c(\"S\", \"A\", \"M\", \"D\"),\n         x = c(1, 1, 2, 3),\n         y = c(3, 1, 2, 1))\n\ndagify(D ~ A + M,\n       M ~ A + S,\n       A ~ S,\n       coords = dag_coords) %>%\n  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_text(color = \"black\", size = 10) +\n  geom_dag_edges(edge_color = \"black\", edge_width = 2,\n                 arrow_directed = grid::arrow(length = grid::unit(15, \"pt\"),\n                                              type = \"closed\")) +\n  theme_void()\ndiv_dag <- dagitty(\"dag{S -> M -> D; S -> A -> D; A -> M}\")\nimpliedConditionalIndependencies(div_dag)\n#> D _||_ S | A, M\ndata(\"WaffleDivorce\")\n\nsouth_divorce <- WaffleDivorce %>%\n  as_tibble() %>%\n  select(D = Divorce,\n         A = MedianAgeMarriage,\n         M = Marriage,\n         S = South) %>%\n  drop_na(everything()) %>%\n  mutate(across(where(is.double), standardize))\n\nb5h4 <- brm(D ~ A + M + S, data = south_divorce, family = gaussian,\n            prior = c(prior(normal(0, 0.2), class = Intercept),\n                      prior(normal(0, 0.5), class = b),\n                      prior(exponential(1), class = sigma)),\n            iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n            file = here(\"fits\", \"chp5\", \"b5h4\"))\nspread_draws(b5h4, b_S) %>%\n  ggplot(aes(x = b_S)) +\n  stat_halfeye(.width = c(0.67, 0.89, 0.97)) +\n  labs(x = expression(beta[S]), y = \"Density\")"},{"path":"causes-confounds-colliders.html","id":"chapter-6","chapter":"Week 3: Causes, Confounds & Colliders","heading":"3.2.2 Chapter 6","text":"6E1. List three mechanisms multiple regression can produce false inferences causal effects.Three mechanisms :Multicollinearity. occurs two variables strongly assocaited, conditional variables model.Post-treatment Bias. occurs inclusion variable “blocks” effect another.Collider Bias. occurs two variables unrelated , related third variable. inclusion third variable creates statistical association model first two.6E2. one mechanisms previous problem, provide example choice, perhaps research.educational research, often interested instructional interventions. example, might provide teacher professional development (\\(D\\)). expect professional development positive impact instruction (\\(\\)) teacher provides, turn improve student performance (\\(P\\)). However, student performance also influenced pre-existing knowledge state (\\(K\\)) teacher’s students. interested estimating effect \\(D\\) \\(\\), inclusion \\(P\\) model example post-treatment bias, quality instruction (influencing performance, \\(P\\)) masks effect professional development shown DAG.6E3. List four elemental confounds. Can explain conditional dependencies ?Fork. classic “confounder” example. variable \\(Z\\) common cause \\(X\\) \\(Y\\), resulting correlation \\(X\\) \\(Y\\). words, \\(X\\) independent \\(Y\\), conditional \\(Z\\), , math notation, \\(X \\!\\perp\\!\\!\\!\\perp Y | Z\\).Pipe. variable \\(X\\) influences, another variable \\(Z\\), turn influences outcome \\(Y\\). good example post-treatment bias described . treatment (\\(X\\)) meant influence outcome (\\(Y\\)), intermediary (\\(Z\\)). Including \\(X\\) \\(Z\\) can make appear though \\(X\\) effect \\(Y\\). Thus, fork, \\(X\\) independent \\(Y\\), conditional \\(Z\\). math : \\(X \\!\\perp\\!\\!\\!\\perp Y | Z\\).Collider. Unlike fork pipe, collider induces correlation otherwise unassociated variables. Thus, \\(X\\) independent \\(Y\\), conditional \\(Z\\). math notation, can written \\(X \\\\!\\perp\\!\\!\\!\\perp Y|Z\\).Descendant. final case, descendant, \\(D\\), influenced another variable DAG, case \\(Z\\). Conditioning descendant impact partially conditioning parent variable. example, \\(Z\\) collider. Thus, kept \\(Z\\) model, included \\(D\\), get partial collider bias, \\(D\\) contains information \\(Z\\). much bias introduced depends strength relationship descendant parent.6E4. biased sample like conditioning collider? Think example open chapter.collider, association introduced two variables third added. biased sample like un-measured collider. example started chapter, association trustworthiness newsworthiness. However, selection status added model, appears negative association. Now imagine data funded proposals. , implicit conditioning selection status, funded proposals. potentially nefarious, collider isn’t explicitly data, variance (.e., proposals data selection score 1).6M1. Modify DAG page 186 include variable \\(V\\), unobserved cause \\(C\\) \\(Y\\): \\(C \\leftarrow V \\rightarrow Y\\). Reanalyze DAG. many paths connect \\(X\\) \\(Y\\)? must closed? variables condition now?new DAG looks like :now 5 paths \\(X\\) \\(Y\\). three paths original DAG, 2 new paths introduced \\(V\\).\\(X \\rightarrow Y\\)\\(X \\leftarrow U \\rightarrow B \\leftarrow C \\rightarrow Y\\)\\(X \\leftarrow U \\rightarrow B \\leftarrow C \\leftarrow V \\rightarrow Y\\)\\(X \\leftarrow U \\leftarrow \\rightarrow C \\rightarrow Y\\)\\(X \\leftarrow U \\leftarrow \\rightarrow C \\leftarrow V \\rightarrow Y\\)want keep path 1 open, causal path interest. Paths 2 3 already closed, \\(B\\) collider. Paths 4 5 open \\(\\) fork. original DAG, close either \\(\\) \\(C\\); however, new DAG, \\(C\\) collider. Therefore, conditioned \\(C\\), ’d opening new path \\(V\\). Therefore, want make inferences causal effect \\(X\\) \\(Y\\), must condition \\(\\) (assuming DAG correct). can confirm using dagitty::adjustmentSets().6M2. Sometimes, order avoid multicollinearity, people inspect pairwise correlations among predictors including model. bad procedure, matters conditional association, association variables included model. highlight , consider DAG \\(X \\rightarrow Z \\rightarrow Y\\). Simulate data DAG correlation \\(X\\) \\(Z\\) large. include model prediction \\(Y\\). observe multicollinearity? ? different legs example chapter?First, ’ll generate data confirm x z highly correlated simulation.generated data prettyNum(nrow(dat), big.mark = \",\") observations, correlation fmt_prop(sim_cor, 3) x z. Now let’s estimate model regressing y x z.model summary, can see x z estimates relatively narrow posterior distributions. contrast example legs chapter, estimated standard deviations \\(beta\\) parameters much larger magnitudes parameters, posterior distributions significant overlap. Thus, appear though observing multicollinearity.due causal model gave rise (simulated) data. legs example chapter, legs predicted height (left DAG ). example, \\(Z\\) predicts outcome. DAG language, \\(Z\\) pipe. Therefore, model estimated, golem looking \\(X\\) tells us, conditional \\(Z\\). answer case “much” \\(X\\) \\(Z\\) highly correlated, posterior \\(X\\) centered zero. leg model condition either predictors, direct paths outcome variable. Thus, whether model multicollinearity depends pairwise relationship, also causal model.\n6M3. Learning analyze DAGs requires practice. four DAGs , state variables, , must adjust (condition ) estimate total causal influence \\(X\\) \\(Y\\).\nUpper Left: two back-door paths \\(X\\) \\(Y\\): \\(X \\leftarrow Z \\rightarrow Y\\) \\(X \\leftarrow Z \\leftarrow \\rightarrow Y\\). first path \\(Z\\) fork, second, \\(Z\\) pipe \\(\\) fork. Thus, cases, conditioning \\(Z\\) close path. can confirm dagitty::adjustmentSets().Upper Right: , two paths \\(X\\) \\(Y\\): \\(X \\rightarrow Z \\rightarrow Y\\) \\(X \\rightarrow Z \\leftarrow \\rightarrow Y\\). first path indirect causal effect \\(X\\) \\(Y\\), included estimating total causal effect \\(X\\) \\(Y\\). second path, \\(Z\\) collider, path already closed therefore action needed. Thus, adjustments needed estimate total effect \\(X\\) \\(Y\\).Lower Left: two paths \\(X\\) \\(Y\\): \\(X \\leftarrow \\rightarrow Z \\leftarrow Y\\) \\(X \\rightarrow Z \\leftarrow Y\\). one causal path \\(X\\) \\(Y\\), direct path. back-door paths, \\(Z\\) collider paths closed unless include , additional variables need added model.Lower Right: Finally, DAG also two causal paths \\(X\\) \\(Y\\). direct effect, indirect effect \\(Z\\). one additional path, \\(X \\leftarrow \\rightarrow Z \\rightarrow Y\\). Conditioning \\(\\) close path.6H1. Use Waffle House data, data(WaffleDivorce), find total causal influence number Waffle Houses divorce rate. Justify model models causal graph.problem, ’ll use DAG given chapter example:order estimate total causal effect Waffle Houses (\\(W\\)) divorce rate (\\(D\\)), condition either \\(S\\) \\(\\) \\(M\\). simplicity, ’ll condition \\(S\\).can use brms::brm() estimate model.Finally, can see causal estimate Waffle Houses divorce rate looking posterior distribution b_W parameter. , can see estimate small, indicating number Waffle Houses little causal impact divorce rate state.6H2. Build series models test implied conditional independencies causal graph used previous problem. tests fail, think graph needs ammended? graph need fewer arrows? Feel free nominate variables aren’t data.First need get conditional independencies implied DAG.three models need estimate evaluate implied conditional independencies. one can estimated brms::brm().Finally, can example posterior distributions implied conditional independencies. implied conditional independency tested first model, \\(\\!\\perp\\!\\!\\!\\perp W | S\\), appears met, \\(beta_W\\) coefficient model centered zero. true third implied conditional independency, \\(M \\!\\perp\\!\\!\\!\\perp W | S\\). second implied conditional independency, \\(D \\!\\perp\\!\\!\\!\\perp S | , M, W\\), less clear, posterior distribution overlaps zero, indicate slightly positive relationship divorce rate state’s “southern” status, even adjusting median age marriage, marriage rate, number waffle houses. likely variables missing model related divorce rate also southerness. example, religiosity, family size, education plausibly impact divorce rates show regional differences United States.three problems based data. data data(foxes) 116 foxes 30 different urban groups England. foxes like street gangs. Group size varies 2 8 individuals. group maintains urban territory. territories larger others. area variable encodes information. territories also avgfood others. want model weight fox. problems , assume following DAG:6H3. Use model infer total causal influence area weight. increasing area available fox make heavier (healthier)? might want standardize variables. Regardless, use prior predictive simulation show model’s prior predictions stay within possible outcome range.First, let’s load data standardize variables.first question, back-door paths area weight. arrows represent indirect effects area weight. Therefore, want condition avgfood groupsize, close one indirect paths needed estimate total causal effect. can confirm dagitty::adjustmentSets().Thus, model question can written :\\[\\begin{align}\n  W_i &\\sim \\text{Normal}(\\mu_i, \\sigma) \\\\\n  \\mu_i &= \\alpha + \\beta_A \\\\\n  \\alpha &\\sim \\text{Normal}(0, 0.2) \\\\\n  \\beta_A &\\sim \\text{Normal}(0, 0.5) \\\\\n  \\sigma &\\sim \\text{Exponential}(1)\n\\end{align}\\]Now, let’s prior predictive simulations makes sure ’re within bounds might expected. Nearly lines within bounds might expected.Finally, can estimate model. Conditional DAG data, doesn’t appear though area size causal effect weight foxes sample.6H4. Now infer causal impact adding food territory. make foxes heavier? covariates need adjust estimate total causal influence food?estimate total causal impact food, don’t need adjust variables. direct path average food weight indirect path group size. condition group size, path closed left direct effect. However, want total effect, adjustment made.estimate model regressing weight average food available, see effect food weight. Given DAG, expected. impact food weight, expected see impact area weight previous problem, area upstream average food causal model.6H5. Now infer causal impact group size. covariates need adjust ? Looking posterior distribution resulting model, think explains data? , can explain estimates three problems? go together?assessing causal impact group size, one back-door path: \\(G \\leftarrow F \\rightarrow W\\). path, average food, \\(F\\), fork, condition isolate effect group size.estimate model, see negative effect group size controlling food. also now see positive effect average food controlling group size. Thus, causal effect group size decrease weight. Logically makes sense, less food fox. model also indicates direct effect average food increase weight. , group size held constant, food results weight. However, total causal effect food weight, saw last problem, nothing. food also leads larger groups, turn decreases weight. masking effect, also called post-treatment bias.6H6. Consider research question. Draw DAG represent . testable implications DAG? variables condition close backdoor paths? unobserved variables omitted? reasonable colleague imagine additional threats causal inference ignored?question, ’ll use instructional intervention described question 6E2. DAG shown . DAG, ’re interested effect new professional development intervention (\\(D\\)) student performance (\\(P\\)). However, professional development works improving teacher’s instruction (\\(\\)), student performance also affected students’ pre-existing knowledge (\\(K\\)).Based DAG, three testable implications:\\(D \\!\\perp\\!\\!\\!\\perp K\\)\\(D \\!\\perp\\!\\!\\!\\perp P | \\)\\(\\!\\perp\\!\\!\\!\\perp K\\)interested causal impact professional development intervention \\(D\\) student performance \\(P\\), back-door paths close. Conditioning quality instruction introduce post-treatment bias mask effect professional development student performance.many factors included DAG known impact quality instruction student performance. include socioeconomic socioemotional state student, student motivation, school funding, class size, -home educational support, name just . Students also grouped classes schools, likely group-level effects accounted .6H7. DAG made previous problem, can write data generating simulation ? Can design one statistical models produce causal estimates? , try calculate interesting counterfactuals. , use simulation estimate size bias might expect. conditions , example, infer opposite true causal effect?Given DAG, can generate data estimate causal models test . First, let’s generate data. sake example, ’ll assume group level effects teachers equally effective. assumptions wouldn’t hold real data, suffice exercise.Now let’s estimate model find causal effect professional development student performance.\\[\\begin{align}\n  P_i &\\sim \\text{Normal}(\\mu_i, \\sigma) \\\\\n  \\mu_i &= \\alpha + \\beta_D \\\\\n  \\alpha &\\sim \\text{Normal}(0,0.2) \\\\\n  \\beta_D &\\sim \\text{Normal}(0,0.5) \\\\\n  \\sigma &\\sim \\text{Exponential}(1)\n\\end{align}\\]can see , expected given data simulated, strong effect professional development student performance. students whose teachers received professional development showing 0.88 standard deviation increase performance compared students whose teachers receive professional development.","code":"\ned_dag <- dagitty(\"dag { D -> I -> P <- K }\")\ncoordinates(ed_dag) <- list(x = c(D = 1, I = 1.5, P = 2, K = 2.5),\n                            y = c(D = 3, I = 2, P = 1, K = 2))\n\nggplot(ed_dag, aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_text(color = \"black\", size = 10) +\n  geom_dag_edges(edge_color = \"black\", edge_width = 2,\n                 arrow_directed = grid::arrow(length = grid::unit(15, \"pt\"),\n                                              type = \"closed\")) +\n  theme_void()\ndag_coords <- tibble(name = c(\"X\", \"U\", \"A\", \"B\", \"C\", \"Y\", \"V\"),\n                     x = c(1, 1, 2, 2, 3, 3, 3.5),\n                     y = c(1, 2, 2.5, 1.5, 2, 1, 1.5))\n\ndagify(Y ~ X + C + V,\n       X ~ U,\n       U ~ A,\n       B ~ U + C,\n       C ~ A + V,\n       coords = dag_coords) %>%\n  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_point(data = . %>% filter(name %in% c(\"U\", \"V\")),\n                 shape = 1, stroke = 2, color = \"black\") +\n  geom_dag_text(color = \"black\", size = 10) +\n  geom_dag_edges(edge_color = \"black\", edge_width = 2,\n                 arrow_directed = grid::arrow(length = grid::unit(15, \"pt\"),\n                                              type = \"closed\")) +\n  theme_void()\nnew_dag <- dagitty(\"dag { U [unobserved]\n                          V [unobserved]\n                          X -> Y\n                          X <- U <- A -> C -> Y\n                          U -> B <- C\n                          C <- V -> Y }\")\n\nadjustmentSets(new_dag, exposure = \"X\", outcome = \"Y\")\n#> { A }\nset.seed(1984)\n\nn <- 1000\ndat <- tibble(x = rnorm(n)) %>%\n  mutate(z = rnorm(n, mean = x, sd = 0.1),\n         y = rnorm(n, mean = z),\n         across(everything(), standardize))\n\nsim_cor <- cor(dat$x, dat$z)\nsim_cor\n#> [1] 0.995\nb6m2 <- brm(y ~ 1 + x + z, data = dat, family = gaussian,\n            prior = c(prior(normal(0, 0.2), class = Intercept),\n                      prior(normal(0, 0.5), class = b),\n                      prior(exponential(1), class = sigma)),\n            iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n            file = here(\"fits\", \"chp6\", \"b6m2\"))\n\nas_draws_df(b6m2) %>%\n  as_tibble() %>% \n  select(b_Intercept, b_x, b_z, sigma) %>%\n  pivot_longer(everything()) %>%\n  ggplot(aes(x = value, y = name)) +\n  stat_halfeye(.width = c(0.67, 0.89, 0.97))\ndag1 <- dagitty(\"dag{ X <- Z <- A -> Y <- X; Y <- Z }\")\nadjustmentSets(dag1, exposure = \"X\", outcome = \"Y\")\n#> { Z }\ndag2 <- dagitty(\"dag{ X -> Z <- A -> Y <- X; Y <- Z }\")\nadjustmentSets(dag2, exposure = \"X\", outcome = \"Y\")\n#>  {}\ndag3 <- dagitty(\"dag{ Y -> Z <- A -> X -> Y; X -> Z }\")\nadjustmentSets(dag3, exposure = \"X\", outcome = \"Y\")\n#>  {}\ndag4 <- dagitty(\"dag{ Y <- Z <- A -> X -> Y; X -> Z }\")\nadjustmentSets(dag4, exposure = \"X\", outcome = \"Y\")\n#> { A }\nwaffle_dag <- dagitty(\"dag { S -> W -> D <- A <- S -> M -> D; A -> M }\")\ncoordinates(waffle_dag) <- list(x = c(A = 1, S = 1, M = 2, W = 3, D = 3),\n                                y = c(A = 1, S = 3, M = 2, W = 3, D = 1))\n\nggplot(waffle_dag, aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_text(color = \"black\", size = 10) +\n  geom_dag_edges(edge_color = \"black\", edge_width = 2,\n                 arrow_directed = grid::arrow(length = grid::unit(15, \"pt\"),\n                                              type = \"closed\")) +\n  theme_void()\nadjustmentSets(waffle_dag, exposure = \"W\", outcome = \"D\")\n#> { A, M }\n#> { S }\ndata(\"WaffleDivorce\")\nwaffle <- WaffleDivorce %>%\n  as_tibble() %>%\n  select(D = Divorce,\n         A = MedianAgeMarriage,\n         M = Marriage,\n         S = South,\n         W = WaffleHouses) %>%\n  mutate(across(-S, standardize),\n         S = factor(S))\n\nwaff_mod <- brm(D ~ 1 + W + S, data = waffle, family = gaussian,\n                prior = c(prior(normal(0, 0.2), class = Intercept),\n                          prior(normal(0, 0.5), class = b),\n                          prior(exponential(1), class = sigma)),\n                iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n                file = here(\"fits\", \"chp6\", \"b6h1\"))\nspread_draws(waff_mod, b_W) %>%\n  ggplot(aes(x = b_W)) +\n  stat_halfeye(.width = c(0.67, 0.89, 0.97)) +\n  labs(x = expression(beta[W]), y = \"Density\")\nimpliedConditionalIndependencies(waffle_dag)\n#> A _||_ W | S\n#> D _||_ S | A, M, W\n#> M _||_ W | S\nwaff_ci1 <- brm(A ~ 1 + W + S, data = waffle, family = gaussian,\n                prior = c(prior(normal(0, 0.2), class = Intercept),\n                          prior(normal(0, 0.5), class = b),\n                          prior(exponential(1), class = sigma)),\n                iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n                file = here(\"fits\", \"chp6\", \"b6h2-1\"))\n\nwaff_ci2 <- brm(D ~ 1 + S + A + M + W, data = waffle, family = gaussian,\n                prior = c(prior(normal(0, 0.2), class = Intercept),\n                          prior(normal(0, 0.5), class = b),\n                          prior(exponential(1), class = sigma)),\n                iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n                file = here(\"fits\", \"chp6\", \"b6h2-2\"))\n\nwaff_ci3 <- brm(M ~ 1 + W + S, data = waffle, family = gaussian,\n                prior = c(prior(normal(0, 0.2), class = Intercept),\n                          prior(normal(0, 0.5), class = b),\n                          prior(exponential(1), class = sigma)),\n                iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n                file = here(\"fits\", \"chp6\", \"b6h2-3\"))\nlbls <- c(expression(\"Model 1:\"~beta[W]),\n          expression(\"Model 2:\"~beta[S]),\n          expression(\"Model 3:\"~beta[W]))\n\nbind_rows(\n  gather_draws(waff_ci1, b_W) %>%\n    ungroup() %>%\n    mutate(model = \"ICI 1\"),\n  gather_draws(waff_ci2, b_S1) %>%\n    ungroup() %>%\n    mutate(model = \"ICI 2\"),\n  gather_draws(waff_ci3, b_W) %>%\n    ungroup() %>%\n    mutate(model = \"ICI 3\")\n) %>%\n  ggplot(aes(x = .value, y= model)) +\n  stat_halfeye(.width = c(0.67, 0.89, 0.97)) +\n  scale_y_discrete(labels = lbls) +\n  labs(x = \"Parameter Estimate\", y = \"Implied Conditional Independency\")\ndata(foxes)\n\nfox_dat <- foxes %>%\n  as_tibble() %>%\n  select(area, avgfood, weight, groupsize) %>%\n  mutate(across(everything(), standardize))\n\nfox_dat\n#> # A tibble: 116 × 4\n#>      area avgfood    weight groupsize\n#>     <dbl>   <dbl>     <dbl>     <dbl>\n#>  1 -2.24  -1.92    0.414       -1.52 \n#>  2 -2.24  -1.92   -1.43        -1.52 \n#>  3 -1.21  -1.12    0.676       -1.52 \n#>  4 -1.21  -1.12    1.30        -1.52 \n#>  5 -1.13  -1.32    1.12        -1.52 \n#>  6 -1.13  -1.32   -1.08        -1.52 \n#>  7 -2.02  -1.52    0.000291    -1.52 \n#>  8 -2.02  -1.52   -0.371       -1.52 \n#>  9  0.658 -0.0591  1.35        -0.874\n#> 10  0.658 -0.0591  0.896       -0.874\n#> # … with 106 more rows\nfox_dag <- dagitty(\"dag{ area -> avgfood -> groupsize -> weight <- avgfood }\")\nadjustmentSets(fox_dag, exposure = \"area\", outcome = \"weight\")\n#>  {}\nset.seed(2020)\n\nn <- 1000\ntibble(group = seq_len(n),\n       alpha = rnorm(n, 0, 0.2),\n       beta = rnorm(n, 0, 0.5)) %>%\n  expand(nesting(group, alpha, beta),\n         area = seq(from = -2, to = 2, length.out = 100)) %>%\n  mutate(weight = alpha + beta * area) %>%\n  ggplot(aes(x = area, y = weight, group = group)) +\n  geom_line(alpha = 1 / 10) +\n  geom_hline(yintercept = c((0 - mean(foxes$weight)) / sd(foxes$weight),\n                            (max(foxes$weight) - mean(foxes$weight)) /\n                              sd(foxes$weight)),\n             linetype = c(\"dashed\", \"solid\"), color = \"red\") +\n  annotate(geom = \"text\", x = -2, y = -3.83, hjust = 0, vjust = 1,\n           label = \"No weight\") +\n  annotate(geom = \"text\", x = -2, y = 2.55, hjust = 0, vjust = 0,\n           label = \"Maximum weight\") +\n  expand_limits(y = c(-4, 4)) +\n  labs(x = \"Standardized Area\", y = \"Standardized Weight\")\narea_mod <- brm(weight ~ 1 + area, data = fox_dat, family = gaussian,\n                prior = c(prior(normal(0, 0.2), class = Intercept),\n                          prior(normal(0, 0.5), class = b,),\n                          prior(exponential(1), class = sigma)),\n                iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n                file = here(\"fits\", \"chp6\", \"b6h3\"))\n\nas_draws_df(area_mod) %>%\n  as_tibble() %>%\n  select(b_Intercept, b_area, sigma) %>%\n  pivot_longer(everything()) %>%\n  mutate(name = factor(name, levels = c(\"b_Intercept\", \"b_area\", \"sigma\"))) %>%\n  ggplot(aes(x = value, y = fct_rev(name))) +\n  stat_halfeye(.width = c(0.67, 0.89, 0.97)) +\n  labs(x = \"Parameter Estimate\", y = \"Parameter\")\nadjustmentSets(fox_dag, exposure = \"avgfood\", outcome = \"weight\")\n#>  {}\nfood_mod <- brm(weight ~ 1 + avgfood, data = fox_dat, family = gaussian,\n                prior = c(prior(normal(0, 0.2), class = Intercept),\n                          prior(normal(0, 0.5), class = b,),\n                          prior(exponential(1), class = sigma)),\n                iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n                file = here(\"fits\", \"chp6\", \"b6h4\"))\n\nas_draws_df(food_mod) %>%\n  as_tibble() %>%\n  select(b_Intercept, b_avgfood, sigma) %>%\n  pivot_longer(everything()) %>%\n  mutate(name = factor(name, levels = c(\"b_Intercept\", \"b_avgfood\", \"sigma\"))) %>%\n  ggplot(aes(x = value, y = fct_rev(name))) +\n  stat_halfeye(.width = c(0.67, 0.89, 0.97)) +\n  labs(x = \"Parameter Estimate\", y = \"Parameter\")\nadjustmentSets(fox_dag, exposure = \"groupsize\", outcome = \"weight\")\n#> { avgfood }\ngrp_mod <- brm(weight ~ 1 + avgfood + groupsize, data = fox_dat,\n               family = gaussian,\n               prior = c(prior(normal(0, 0.2), class = Intercept),\n                         prior(normal(0, 0.5), class = b,),\n                         prior(exponential(1), class = sigma)),\n               iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n               file = here(\"fits\", \"chp6\", \"b6h5\"))\n\nas_draws_df(grp_mod) %>%\n  as_tibble() %>%\n  select(b_Intercept, b_avgfood, b_groupsize, sigma) %>%\n  pivot_longer(everything()) %>%\n  mutate(name = factor(name, levels = c(\"b_Intercept\", \"b_avgfood\",\n                                        \"b_groupsize\", \"sigma\"))) %>%\n  ggplot(aes(x = value, y = fct_rev(name))) +\n  stat_halfeye(.width = c(0.67, 0.89, 0.97)) +\n  labs(x = \"Parameter Estimate\", y = \"Parameter\")\ned_dag <- dagitty(\"dag { D -> I -> P <- K }\")\ncoordinates(ed_dag) <- list(x = c(D = 1, I = 1.5, P = 2, K = 2.5),\n                            y = c(D = 3, I = 2, P = 1, K = 2))\n\nggplot(ed_dag, aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_text(color = \"black\", size = 10) +\n  geom_dag_edges(edge_color = \"black\", edge_width = 2,\n                 arrow_directed = grid::arrow(length = grid::unit(15, \"pt\"),\n                                              type = \"closed\")) +\n  theme_void()\nimpliedConditionalIndependencies(ed_dag)\n#> D _||_ K\n#> D _||_ P | I\n#> I _||_ K\nadjustmentSets(ed_dag, exposure = \"D\", outcome = \"P\")\n#>  {}\nset.seed(2010)\n\nstudents <- 500\n\ned_dat <- tibble(k = rnorm(students, mean = 0, sd = 2),\n                 d = sample(0L:1L, students, replace = TRUE),\n                 i = rnorm(students, mean = 1 + 3 * d),\n                 p = k + rnorm(students, 0.8 * i)) %>%\n  mutate(across(where(is.double), standardize))\n\ned_dat\n#> # A tibble: 500 × 4\n#>          k     d        i      p\n#>      <dbl> <int>    <dbl>  <dbl>\n#>  1 -0.472      1  1.61     1.05 \n#>  2  0.0678     1  0.986    0.973\n#>  3  1.09       1  1.05     1.42 \n#>  4  0.290      0 -1.60    -0.385\n#>  5 -0.131      1  1.28     0.731\n#>  6  1.54       0 -0.00907  1.11 \n#>  7 -0.474      0 -1.35    -0.794\n#>  8 -1.47       1  0.345   -0.425\n#>  9  0.735      0 -0.559    0.439\n#> 10  0.695      0 -0.372    0.155\n#> # … with 490 more rows\ned_mod <- brm(p ~ 1 + d, data = ed_dat, family = gaussian,\n              prior = c(prior(normal(0, 0.2), class = Intercept),\n                        prior(normal(0, 0.5), class = b),\n                        prior(exponential(1), class = sigma)),\n              iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n              file = here(\"fits\", \"chp6\", \"b6h7-causal\"))\n\nas_draws_df(ed_mod) %>%\n  as_tibble() %>%\n  select(b_Intercept, b_d, sigma) %>%\n  pivot_longer(everything()) %>%\n  ggplot(aes(x = value, y = name)) +\n  stat_halfeye(.width = c(0.67, 0.89, 0.97)) +\n  labs(x = \"Parameter Value\", y = \"Parameter\")"},{"path":"causes-confounds-colliders.html","id":"homework-2","chapter":"Week 3: Causes, Confounds & Colliders","heading":"3.3 Homework","text":"1. first two problems based data. data data(foxes) 116 foxes 30 different urban groups England. fox groups like street gangs. Group size (groupsize) varies 2 8 individuals. group maintains (almost exclusive) urban territory. territories larger tahn others. area variable encodes information. territories also avgfood others. food influences weight fox. Assume DAG:\\(F\\) avgfood, \\(G\\) groupsize, \\(\\) area, \\(W\\) weight.Use backdoor criterion estimate total causal influence \\(\\) \\(F\\). effect increasing area territory amount food inside ?one path \\(\\) \\(F\\), direct path. Thus backdoors, additional variables need included model. can confirm dagitty.Given , can estimate model {brms}. ’ll standardize variables make setting priors easier.see fairly strong effect area average amount food. credible interval area well zero. increase 1 standard deviation area expect see .9 standard deviation increase food. Logically makes sense, greater area means prey available.2. Now infer total direct causal effects adding food \\(F\\) territory weight \\(W\\) foxes. covariates need adjust case? light estimates problem previous one, think going foxes? Feel free speculate—matters justify speculation.backdoor paths \\(F\\) \\(W\\), covariates need added evaluating total effect food weight. want direct effect, need close path \\(F \\rightarrow G \\rightarrow W\\) adding group size covariate. can confirm dagitty.Now estimate models. First total effect. model see basically effect food weight. 95% interval {brms} output -0.21 0.15 mean -0.02. effect just likely positive negative.Next estimate direct effect. see stratify group size, see strong positive effect food weight. indicates within given group size, food associated weight.Altogether, results seem suggest masking effect. , food available, foxes move territory, increasing group size. continues equilibrium reached amount food available equally good (equally bad) within territory. Thus, total effect food negligible food becomes available, group size increases amount food available individual fox remains relatively stable.3. Reconsider Table 2 Fallacy example (Lecture 6), time unobserved confound \\(U\\) influences smoking \\(S\\) stroke \\(Y\\). ’s modified DAG:First use backdoor criterion determine adjustment set allows estimate causal effect \\(X\\) \\(Y\\), .e., \\(P(Y|\\text{}(X))\\). Second explain proper interpretation coefficient implied regression model corresponds adjustment set. coefficients (slopes) causal ? need fit models. Just think implications.5 paths \\(X\\) \\(Y\\):\\(X \\rightarrow Y\\)\\(X \\leftarrow S \\rightarrow Y\\)\\(X \\leftarrow \\rightarrow Y\\)\\(X \\leftarrow \\rightarrow S \\rightarrow Y\\)\\(X \\leftarrow \\rightarrow S \\leftarrow U \\rightarrow Y\\)Path 1 effect \\(X\\) \\(Y\\), want. rest backdoor paths must closed. Conditioning \\(\\) \\(S\\) close paths, can confirm dagitty.However, unobserved variable \\(U\\) important implications interpretation model. three slope coefficients canonical Table 2: \\(\\beta_X\\), \\(\\beta_S\\), \\(\\beta_A\\). focus investigation, \\(\\beta_X\\) represents causal effect \\(X\\) \\(Y\\). However, \\(S\\) collider, \\(\\beta_S\\) \\(\\beta_A\\) confounded \\(U\\). Thus, coefficients interpreted type causal effect.4 - OPTIONAL CHALLENGE. Write synthetic data simulation causal model shown Problem 3. sure include unobserved confound simulation. Choose functional relationships like—don’t get epidemiology correct. just need honor causal structure. design regression model estimate influence \\(X\\) \\(Y\\) use synthetic data. large sample need reliably estimate \\(P(Y|\\text{}(X))\\)? Define “reliably” like, justify definition.Since ’re going simulating bunch data sets, ’ll start writing function generate single data set based DAG. function allows us specify sample size relationship \\(X\\) \\(Y\\). Notice although \\(U\\) used generate data, variable removed return data set, unobserved (select(-U)).’ll test one example data set. use sim_dat() function just created generate data set 10 subjects positive relationship \\(X\\) \\(Y\\) 0.3.worked! got back estimate \\(X\\) close 0.3, equally likely positive negative. sample size 10.question asks us sample size needed reliable estimate \\(\\beta_X\\). two ways (least) think . first “correct” estimate average. , mean difference true value (0.3 example data set) estimated posterior mean (0.37 model summary). Thus, difference 0.07. measure also referred mean absolute difference. , absolute indicates normally take absolute value difference positive negative deviations don’t cancel .measure reliability might consider width chosen credible interval. posterior interval wide, might say unreliable estimate \\(\\beta_X\\), wide range values model views plausible. smaller interval reliable, indicate high degree confidence estimate narrow range values.simulation, ’ll generate 100 data sets sample size, fit model data set, calculate outcome measures. make things easier, ’ll build another function. First generate data, fit model (suppressMessages() capture.output() just suppress model fitting messages since ’ll fitting many models), use mean_hdi() calculate measures reliability.’ll investigate sample sizes 10, 20, 50, 100, 250, 500, 1,000. sample size, ’ll conduct 100 replications (.e., 100 data sets per sample size condition). following code create 100 rows sample size, apply sim_func() sample size row.Looking results can see replication, absolute value difference mean posterior true value (0.3; abs_error), well width 89% compatibility interval.Across replications, see average absolute error similar sample sizes. However, much variability lower sample sizes. , sample size 10, ’s unexpected see estimate 0.5. larger samples, range bias values gets narrower, less likely see estimates far true value.also see small sample sizes result large variable interval widths. sample size gets larger, width 89% compatibility interval decreases becomes consistent (.e., width similar replication).","code":"\nfox_dag <- dagitty(\"dag{ A -> F -> G -> W <- F }\")\n\nadjustmentSets(fox_dag, exposure = \"A\", outcome = \"F\")\n#>  {}\ndata(foxes)\n\nfox_dat <- foxes %>%\n  as_tibble() %>%\n  select(area, avgfood, weight, groupsize) %>%\n  mutate(across(everything(), standardize))\n\nfood_on_area <- brm(avgfood ~ 1 + area, data = fox_dat, family = gaussian,\n                    prior = c(prior(normal(0, 0.2), class = Intercept),\n                              prior(normal(0, 0.5), class = b,),\n                              prior(exponential(1), class = sigma)),\n                    iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n                    file = here(\"fits\", \"hw3\", \"w3h1\"))\n\nsummary(food_on_area)\n#>  Family: gaussian \n#>   Links: mu = identity; sigma = identity \n#> Formula: avgfood ~ 1 + area \n#>    Data: fox_dat (Number of observations: 116) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 0; thin = 1;\n#>          total post-warmup draws = 8000\n#> \n#> Population-Level Effects: \n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept     0.00      0.04    -0.09     0.09 1.00     8076     6131\n#> area          0.88      0.04     0.79     0.96 1.00     8389     5927\n#> \n#> Family Specific Parameters: \n#>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sigma     0.48      0.03     0.42     0.54 1.00     7997     6226\n#> \n#> Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\nadjustmentSets(fox_dag, exposure = \"F\", outcome = \"W\", effect = \"total\")\n#>  {}\n\nadjustmentSets(fox_dag, exposure = \"F\", outcome = \"W\", effect = \"direct\")\n#> { G }\nfood_total <- brm(weight ~ 1 + avgfood, data = fox_dat, family = gaussian,\n                  prior = c(prior(normal(0, 0.2), class = Intercept),\n                            prior(normal(0, 0.5), class = b,),\n                            prior(exponential(1), class = sigma)),\n                  iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n                  file = here(\"fits\", \"hw3\", \"w3h2-total\"))\n\nsummary(food_total)\n#>  Family: gaussian \n#>   Links: mu = identity; sigma = identity \n#> Formula: weight ~ 1 + avgfood \n#>    Data: fox_dat (Number of observations: 116) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 0; thin = 1;\n#>          total post-warmup draws = 8000\n#> \n#> Population-Level Effects: \n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept    -0.00      0.08    -0.17     0.16 1.00     7369     5854\n#> avgfood      -0.02      0.09    -0.21     0.15 1.00     7826     6205\n#> \n#> Family Specific Parameters: \n#>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sigma     1.01      0.07     0.89     1.15 1.00     7839     6107\n#> \n#> Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\nfood_direct <- brm(weight ~ 1 + avgfood + groupsize, data = fox_dat,\n                   family = gaussian,\n                   prior = c(prior(normal(0, 0.2), class = Intercept),\n                             prior(normal(0, 0.5), class = b,),\n                             prior(exponential(1), class = sigma)),\n                   iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n                   file = here(\"fits\", \"hw3\", \"w3h2-direct\"))\n\nsummary(food_direct)\n#>  Family: gaussian \n#>   Links: mu = identity; sigma = identity \n#> Formula: weight ~ 1 + avgfood + groupsize \n#>    Data: fox_dat (Number of observations: 116) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 0; thin = 1;\n#>          total post-warmup draws = 8000\n#> \n#> Population-Level Effects: \n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept    -0.00      0.08    -0.16     0.16 1.00     5680     4403\n#> avgfood       0.47      0.18     0.11     0.84 1.00     4022     3986\n#> groupsize    -0.57      0.19    -0.93    -0.21 1.00     4021     4085\n#> \n#> Family Specific Parameters: \n#>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sigma     0.96      0.06     0.85     1.09 1.00     5544     5204\n#> \n#> Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\nstroke_dag <- dagitty(\"dag{\n  A -> S -> X -> Y;\n  A -> X; A -> Y; S -> Y;\n  S <- U -> Y \n  X [exposure]\n  Y [outcome]\n  U [unobserved]\n}\")\n\nadjustmentSets(stroke_dag)\n#> { A, S }\nsim_dat <- function(n = 100, bx = 0) {\n  tibble(U = rnorm(n, 0, 1),\n         A = rnorm(n, 0, 1)) %>% \n    mutate(S = rnorm(n, A + U, 1),\n           X = rnorm(n, A + S, 1),\n           Y = rnorm(n, A + S + (bx * X) + U, 1)) %>% \n    select(-U) %>% \n    mutate(across(everything(), standardize))\n}\nset.seed(208)\n\ndat1 <- sim_dat(n = 10, bx = 0.3)\n\nmod1 <- brm(Y ~ 1 + X + S + A, data = dat1, family = gaussian,\n            prior = c(prior(normal(0, 0.2), class = Intercept),\n                      prior(normal(0, 0.5), class = b,),\n                      prior(exponential(1), class = sigma)),\n            iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n            file = here(\"fits\", \"hw3\", \"w3h4\"))\n\nsummary(mod1, prob = 0.89)\n#>  Family: gaussian \n#>   Links: mu = identity; sigma = identity \n#> Formula: Y ~ 1 + X + S + A \n#>    Data: dat1 (Number of observations: 10) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 0; thin = 1;\n#>          total post-warmup draws = 8000\n#> \n#> Population-Level Effects: \n#>           Estimate Est.Error l-89% CI u-89% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept     0.00      0.09    -0.14     0.14 1.00     5459     4269\n#> X             0.31      0.28    -0.13     0.75 1.00     4000     3847\n#> S             0.61      0.22     0.24     0.96 1.00     4549     4029\n#> A             0.05      0.22    -0.29     0.42 1.00     4558     4417\n#> \n#> Family Specific Parameters: \n#>       Estimate Est.Error l-89% CI u-89% CI Rhat Bulk_ESS Tail_ESS\n#> sigma     0.31      0.10     0.19     0.48 1.00     3566     4676\n#> \n#> Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\nsim_func <- function(n, bx = 0) {\n  dat <- sim_dat(n = n, bx = bx)\n  \n  suppressMessages(output <- capture.output(\n    mod <- brm(Y ~ 1 + X + S + A, data = dat, family = gaussian,\n               prior = c(prior(normal(0, 0.2), class = Intercept),\n                         prior(normal(0, 0.5), class = b,),\n                         prior(exponential(1), class = sigma)),\n               refresh = 0,\n               iter = 4000, warmup = 2000, chains = 4, cores = 4)\n  ))\n  \n  as_draws_df(mod, \"b_X\") %>% \n    mean_hdi(.width = 0.89) %>% \n    mutate(abs_error = abs(b_X - bx),\n           int_width = .upper - .lower) %>% \n    select(abs_error, int_width)\n}\nsim_results <- expand_grid(sample_size = c(10, 20, 50, 100, 250, 500, 1000),\n                           replication = seq_len(100)) %>% \n  mutate(results = map(sample_size, sim_func, bx = 0.3)) %>% \n  unnest(results) %>% \n  write_rds(here(\"fits\", \"hw3\", \"w3h4-sim.rds\"))\nsim_results\n#> # A tibble: 700 × 4\n#>    sample_size replication abs_error int_width\n#>          <dbl>       <int>     <dbl>     <dbl>\n#>  1          10           1    0.206      0.774\n#>  2          10           2    0.265      1.08 \n#>  3          10           3    0.0771     0.907\n#>  4          10           4    0.378      0.954\n#>  5          10           5    0.109      0.991\n#>  6          10           6    0.0423     0.970\n#>  7          10           7    0.460      0.764\n#>  8          10           8    0.0568     0.999\n#>  9          10           9    0.0854     0.706\n#> 10          10          10    0.0566     1.01 \n#> # … with 690 more rows\nsim_results %>% \n  select(-replication) %>% \n  pivot_longer(-sample_size, names_to = \"measure\", values_to = \"value\") %>% \n  mutate(measure = factor(measure, levels = c(\"abs_error\", \"int_width\"),\n                          labels = c(\"Absolute Error\", \"89% Interval Width\"))) %>% \n  ggplot(aes(x = factor(sample_size), y = value)) +\n  facet_wrap(~measure, nrow = 1) +\n  stat_interval(.width = c(0.67, 0.89, 0.97)) +\n  scale_color_manual(values = ramp_blue(seq(0.9, 0.1, length.out = 3)),\n                     breaks = c(0.67, 0.89, 0.97)) +\n  labs(x = \"Sample Size\", y = \"Value\", color = \"Interval\")"},{"path":"overfitting-mcmc.html","id":"overfitting-mcmc","chapter":"Week 4: Overfitting / MCMC","heading":"Week 4: Overfitting / MCMC","text":"fourth week covers Chapter 7 (Ulysses’ Compass), Chapter 8 (Conditional Manatees), Chapter 9 (Markov Chain Monte Carlo).","code":""},{"path":"overfitting-mcmc.html","id":"lectures-3","chapter":"Week 4: Overfitting / MCMC","heading":"4.1 Lectures","text":"Lecture 7:Lecture 8:","code":""},{"path":"overfitting-mcmc.html","id":"exercises-3","chapter":"Week 4: Overfitting / MCMC","heading":"4.2 Exercises","text":"","code":""},{"path":"overfitting-mcmc.html","id":"chapter-7","chapter":"Week 4: Overfitting / MCMC","heading":"4.2.1 Chapter 7","text":"7E1. State three motivating criteria define information entropy. Try express words.Information defined reduction uncertainty learn outcome. motivating criteria defining information entropy revolve around measure uncertainty used derive information.first measure uncertainty must continuous. prevents large changes uncertainty measure resulting relatively small changes probabilities. phenomenon often occurs researchers use p-value cutoff .05 claim “significance.” Often, difference “significant” “non-significant” results non-significant 🤯.second measure uncertainty increase number possible events increases. potential outcomes, predictions made, therefore uncertainty outcome observed. example, friend asks guess number 1 100, much less likely guess correctly guessing number 1 2.third final criteria measure uncertainty additive. means calculate uncertainty two sets outcomes (e.g., heads tail coin flip results thrown die), uncertainty combinations events (e.g., heads “3”) equal sum uncertainties two separate events.Information entropy function satisfies three criteria.7E2. Suppose coin weighted , tossed lands table, comes heads 70% time. entropy coin?Entropy average log-probability event. formula given \\[\\begin{equation}\n  H(p) = -\\text{E}\\log(p_i) = -\\sum_{=1}^np_i\\log(p_i)\n\\end{equation}\\]Thus, probability \\(p_i\\), multiply \\(p_i\\) \\(\\log(p_i)\\), sum values, multiply sum negative one. implement , ’ll first write couple functions calculations. without functions, functions allow us handle cases \\(p_i = 0\\), case couple problems. first function, p_logp(), returns 0 p 0, returns p * log(p) otherwise. calc_entropy() function wrapper around p_logp(), applying p_logp() element vector probabilities, summing results, multiplying sum -1.Applying functions probabilities problem results entropy 0.61. Note weather example text, cases two events probabilities 0.3 0.7.7E3. Suppose four-sided die loaded , tossed onto table, shows “1” 20%, “2” 25%, “3” 25%, “4” 30% time. entropy die?Now four outcomes. can reuse code , substituting new probabilities vector probs. results entropy 1.38. expected, now outcomes, entropy higher observed previous problem.7E4. Suppose another four-sided die loaded never shows “4.” three sides show equally often. entropy die?, can copy code , replace probabilities. Even though four outcomes specified, effectively three outcomes, outcome “4” probability 0. Thus, expect entropy decrease, fewer possible outcomes previous problem. indeed find, die’s entropy 1.1.7M1. Write compare definitions AIC WAIC. criteria general? assumptions required transform general criterion less general one?AIC defined follows, \\(\\text{lppd}\\) log-pointwise-predictive density, \\(p\\) number free parameters posterior distribution.\\[\n\\text{AIC} = -2\\text{lppd} + 2p\n\\]contrast, WAIC defined :\\[\n\\text{WAIC}(y,\\Theta) = -2\\Big(\\text{lppd} - \\sum_i \\text{var}_{\\theta}\\log p(y_i | \\theta)\\Big)\n\\]distribute \\(-2\\) , looks remarkably similar AIC formula, exception final \\(p\\) term. Whereas AIC uses 2 times number free parameters, WAIC uses 2 times sum log-probability variances observation.WAIC general AIC, AIC assumes priors flat overwhelmed likelihood, posterior distribution approximately multivariate Gaussian, sample size much greater number parameters. assumptions met, expect AIC WAIC .7M2. Explain difference model selection model comparison. information lost model selection?Model selection refers just picking model lowest (.e., best) criterion value discarding models. take approach, lose information relative model accuracy can seen across criterion values candidate models. information can inform confident models. Additionally, model selection paradigm cares predictive accuracy ignores causal inference. Thus, model may selected confounds correctly inform intervention.contrast, model comparison uses multiple models understand variables included influence prediction affect implied conditional independencies causal model. Thus, preserve information can make holistic judgments data models.7M3. comparing models information criterion, must models fit exactly observations? happen information criterion values, models fit different numbers observations? Perform experiments, sure.information criteria defined based log-pointwise-predictive density, defined follows, \\(y\\) data, \\(\\Theta\\) posterior distribution, \\(S\\) number samples, \\(\\) number samples.\\[\n\\text{lppd}(y,\\Theta) = \\sum_i\\log\\frac{1}{S}\\sum_sp(y_i|\\Theta_s)\n\\]words, means take log average probability across samples observation \\(\\) sum together. Thus, larger sample size necessarily lead smaller log-pointwise-predictive-density, even data generating process models exactly equivalent (.e., LPPD values negative, sum get negative sample size increases). observations entered sum, leading smaller final lppd, turn increase information criteria. can run quick simulation demonstrate. three different sample sizes, ’ll simulate 100 data sets exact data generation process, estimate exact linear model, calculate LPPD, WAIC, PSIS .Visualizing distribution LPPD, WAIC, PSIS across simulated data sets sample size, see LPPD gets negative sample size increases, even though data generation process estimated model identical. Accordingly, WAIC PSIS increase. Note WAIC PSIS values approximately \\(-2 \\times \\text{lppd}\\). Thus, fit one model 100 observations second model 1,000 observations, might conclude WAIC PSIS first model 100 observations much better predictive accuracy, WAIC PSIS values lower. However, artifact different sample sizes, may actually represent true differences models.7M4. happens effective number parameters, measured PSIS WAIC, prior becomes concentrated? ? Perform experiments, sure.penalty term WAIC, \\(p_{\\Tiny\\text{WAIC}}\\) defined shown WAIC formula. Specifically, penalty term sum variances log probabilities observation.\\[\n\\text{WAIC}(y,\\Theta) = -2\\Big(\\text{lppd} - \\underbrace{\\sum_i \\text{var}_{\\theta}\\log p(y_i | \\theta)}_{\\text{penalty term}}\\Big)\n\\]Smaller variances log probabilities results lower penalty. restrict prior become concentrated, restrict plausible range parameters. words, restrict variability posterior distribution. parameters become consistent, log probability observation necessarily become consistent also. Thus, penalty term, effective number parameters, becomes smaller. can confirm small simulation.simulation keep everything constant (.e., data generation, model), exception prior slope coefficients. ’ll try three different priors: \\(\\text{Normal}(0, 0.1)\\), \\(\\text{Normal}(0, 1)\\), \\(\\text{Normal}(0, 10)\\). Visualizing results, can see constricted prior indeed result smaller penalty effective number parameters.7M5. Provide informal explanation informative priors reduce overfitting.Informative priors restrict plausible values parameters. using informative priors, can limit values parameters values reasonable, given scientific knowledge. Thus, can keep model learning much specific sample.7M6. Provide informal explanation overly informative priors result underfitting.contrast previous question, making prior informative can restrictive parameter space. prevents model learning enough sample. basically just get prior distributions back, without learning anything data help make future predictions.7H1. 2007, Wall Street Journal published editorial (“’re Number One, Alas”) graph corportate tax rates 29 countries plotted tax revenue. badly fit curve drawn (reconstructed right), seemingly hand, make argument relationship tax rate tax revenue increases declines, higher tax rates can actually produce less tax revenue. want actually fit curve data, found data(Laffer). Consider models use tax rate predict tax revenue. Compare, using WAIC PSIS, straight-line model curved models like. conclude relationship tax rate tax revenue.First, let’s standardize data fit straight line, quadratic line, spline model.Let’s visualize models:look pretty similar, quadratic spline models show slight curve. Next, can look PSIS (called LOO {brms} {rstan}) WAIC comparisons. Neither PSIS WAIC really able differentiate models meaningful way. However, noted PSIS WAIC Pareto penalty values exceptionally large, make criteria unreliable.7H2. Laffer data, one country high tax revenue outlier. Use PSIS WAIC measure importance outlier models fit previous problem. use robust regression Student’s t distribution revist curve fitting problem. much curved relationship depend upon outlier point.used brms::brm() estimate models, can’t use convenience functions get pointwise values PSIS WAIC available {rethinking} package. ’ll write , called criteria_influence(). plot Pareto k \\(p_{\\Tiny\\text{WAIC}}\\) values, see observation 12 problematic three models.Let’s refit model using Student’s t distribution put larger tails outcome distribution, visualize new models.prediction intervals little bit narrower, makes sense predictions longer influenced outlier. look new PSIS WAIC estimates, longer getting warning messages large Pareto k values; however, still see warnings large \\(p_{\\Tiny\\text{WAIC}}\\) values. comparisons also tell story , distinguishable differences models.7H3. Consider three fictional Polynesian islands. Royal Ornithologist charged king surveying bird population. found following proportions 5 important bird species:Notice row sums 1, birds. problem two parts. computationally complicated. conceptually tricky. First, compute entropy island’s bird distribution. Interpret entropy values. Second, use island’s bird distribution predict two. means compute KL divergence island others, treating island statistical model islands. end 6 different KL divergence values. island predicts others best? ?First, lets compute entropy island.first island highest entropy. expected, even distribution bird species. species equally likely, observation one species surprising. contrast, Island 2 lowest entropy. vast majority birds island Species . Therefore, observing bird Species surprising.second part question, need compute KL divergence pair islands. KL divergence defined :\\[\nD_{KL} = \\sum_i p_i(\\log(p_i) - \\log(q_i))\n\\]’ll write function calculation.Now, let’s calculate \\(D_{KL}\\) set islands.results show us using Island 1 predict Island 2, KL divergence 0.87. use Island 1 predict Island 3, KL divergence 0.63, . Overall, distances shorter used Island 1 model. Island 1 highest entropy. Thus, less surprised islands, ’s shorter distance. contrast, Island 2 Island 3 concentrated distributions, predicting islands leads surprises, therefore greater distances.7H4. Recall marriage, age, happiness collider bias example Chapter 6. Run models m6.9 m6.10 (page 178). Compare two models using WAIC (PSIS, produce identical results). model expected make better predictions? model provides correct causal inference influence age happiness? Can explain answers two questions disagree?reminder, DAG example, \\(H\\) happiness, \\(M\\) marriage, \\(\\) age.First, let’s regenerate data estimate models.model comparison ’ll use PSIS.PSIS shows strong preference b6.9, model includes age marriage status. However, b6.10 provides correct causal inference, additional conditioning needed.reason model, marital status collider. Adding variable model add real statistical association happiness age, improves predictions made. However, association causal, intervening age (possible), actually change happiness. Therefore ’s important consider causal implications model selecting one based PSIS WAIC alone.7H5. Revisit urban fox data, data(foxes), previous chapter’s practice problems. Use WAIC PSIS based model comparison five different models, using weight outcome, containing sets predictor variables:avgfood + groupsize + areaavgfood + groupsizegroupsize + areaavgfoodareaCan explain relative differences WAIC scores, using fox DAG previous chapter? sure pay attention standard error score differences (dSE).First, let’s estimate five models.can calculate WAIC model model comparisons.general, models don’t appear different . However, seem two groups models: b7h5_1, b7h5_2, b7h5_3 nearly identical; b7h5_4 b7h5_5 nearly identical.understand , can return DAG example.first three models (b7h5_1, b7h5_2, b7h5_3) contain groupsize one area avgfood. reason models back-door path area avgfood weight. words, effect area adjusting groupsize effect avgfood adjusting groupsize, effect area routed entirely avgfood.Similarly, last two models (b7h5_4 b7h5_5) also nearly identical relationship area avgfood. effect area routed entirely avgfood, including avgfood area result inferences.","code":"\np_logp <- function(p) {\n  if (p == 0) return(0)\n  p * log(p)\n}\ncalc_entropy <- function(x) {\n  avg_logprob <- sum(map_dbl(x, p_logp))\n  -1 * avg_logprob\n}\nprobs <- c(0.7, 0.3)\ncalc_entropy(probs)\n#> [1] 0.611\nprobs <- c(0.20, 0.25, 0.25, 0.30)\ncalc_entropy(probs)\n#> [1] 1.38\nprobs <- c(1, 1, 1, 0)\nprobs <- probs / sum(probs)\nprobs\n#> [1] 0.333 0.333 0.333 0.000\n\ncalc_entropy(probs)\n#> [1] 1.1\ngen_data <- function(n) {\n  tibble(x1 = rnorm(n = n)) %>%\n    mutate(y = rnorm(n = n, mean = 0.3 + 0.8 * x1),\n           across(everything(), standardize))\n}\nfit_model <- function(dat) {\n  suppressMessages(output <- capture.output(\n    mod <- brm(y ~ 1 + x1, data = dat, family = gaussian,\n               prior = c(prior(normal(0, 0.2), class = Intercept),\n                         prior(normal(0, 0.5), class = \"b\"),\n                         prior(exponential(1), class = sigma)),\n               iter = 4000, warmup = 3000, chains = 4, cores = 4, seed = 1234)\n  ))\n  \n  return(mod)\n}\ncalc_info <- function(model) {\n  mod_lppd <- log_lik(model) %>% \n    as_tibble(.name_repair = \"minimal\") %>% \n    set_names(paste0(\"obs_\", 1:ncol(.))) %>% \n    rowid_to_column(var = \"iter\") %>% \n    pivot_longer(-iter, names_to = \"obs\", values_to = \"logprob\") %>% \n    mutate(prob = exp(logprob)) %>% \n    group_by(obs) %>% \n    summarize(log_prob_score = log(mean(prob))) %>% \n    pull(log_prob_score) %>% \n    sum()\n  \n  mod_waic <- suppressWarnings(waic(model)$estimates[\"waic\", \"Estimate\"])\n  mod_psis <- suppressWarnings(loo(model)$estimates[\"looic\", \"Estimate\"])\n  \n  tibble(lppd = mod_lppd, waic = mod_waic, psis = mod_psis)\n}\n\nsample_sim <- tibble(sample_size = rep(c(100, 500, 1000), each = 100)) %>%\n  mutate(sample_data = map(sample_size, gen_data),\n         model = map(sample_data, fit_model),\n         infc = map(model, calc_info)) %>%\n  select(-sample_data, -model) %>% \n  unnest(infc) %>% \n  write_rds(here(\"fits\", \"chp7\", \"b7m3-sim.rds\"), compress = \"gz\")\nlibrary(ggridges)\n\nsample_sim %>%\n  pivot_longer(cols = c(lppd, waic, psis)) %>%\n  mutate(sample_size = fct_inorder(as.character(sample_size)),\n         name = str_to_upper(name),\n         name = fct_inorder(name)) %>%\n  ggplot(aes(x = value, y = sample_size)) +\n  facet_wrap(~name, nrow = 1, scales = \"free_x\") +\n  geom_density_ridges(bandwidth = 4) +\n  scale_y_discrete(expand = c(0, .1)) +\n  scale_x_continuous(breaks = seq(-2000, 3000, by = 750)) +\n  coord_cartesian(clip = \"off\") +\n  labs(x = \"Value\", y = \"Sample Size\")\ngen_data <- function(n) {\n  tibble(x1 = rnorm(n = n),\n         x2 = rnorm(n = n),\n         x3 = rnorm(n = n)) %>%\n    mutate(y = rnorm(n = n, mean = 0.3 + 0.8 * x1 +\n                       0.6 * x2 + 1.2 * x3),\n           across(everything(), standardize))\n}\nfit_model <- function(dat, p_sd) {\n  suppressMessages(output <- capture.output(\n    mod <- brm(y ~ 1 + x1 + x2 + x3, data = dat,\n               family = gaussian,\n               prior = c(prior(normal(0, 0.2), class = Intercept),\n                         prior_string(glue(\"normal(0, {p_sd})\"), class = \"b\"),\n                         prior(exponential(1), class = sigma)),\n               iter = 4000, warmup = 3000, chains = 4, cores = 4, seed = 1234)\n  ))\n  \n  return(mod)\n}\ncalc_info <- function(model) {\n  w <- suppressWarnings(brms::waic(model))\n  p <- suppressWarnings(brms::loo(model))\n  \n  tibble(p_waic = w$estimates[\"p_waic\", \"Estimate\"],\n         p_loo = p$estimates[\"p_loo\", \"Estimate\"])\n}\n\nprior_sim <- tibble(sample_size = 20,\n                    prior_sd = rep(c(0.1, 1, 10), each = 100)) %>%\n  mutate(sample_data = map(sample_size, gen_data),\n         model = map2(sample_data, prior_sd, fit_model),\n         infc = map(model, calc_info)) %>%\n  select(-sample_data, -model) %>% \n  unnest(infc) %>% \n  write_rds(here(\"fits\", \"chp7\", \"b7m4-sim.rds\"), compress = \"gz\")\nprior_sim %>%\n  pivot_longer(cols = c(p_waic, p_loo)) %>%\n  mutate(prior_sd = glue(\"&sigma; = {prior_sd}\"),\n         prior_sd = fct_inorder(prior_sd),\n         name = factor(name, levels = c(\"p_waic\", \"p_loo\"),\n                       labels = c(\"p<sub>WAIC<\/sub>\", \"p<sub>PSIS<\/sub>\"))) %>%\n  ggplot(aes(x = value, y = prior_sd, height = stat(density))) +\n  facet_wrap(~name, nrow = 1) +\n  geom_density_ridges(stat = \"binline\", bins = 20) +\n  labs(x = \"Effective Parameters\", y = \"Prior\") +\n  theme(axis.text.y = element_markdown())\ndata(Laffer)\n\nlaf_dat <- Laffer %>%\n  mutate(across(everything(), standardize),\n         tax_rate2 = tax_rate ^ 2)\n\nlaf_line <- brm(tax_revenue ~ 1 + tax_rate, data = laf_dat, family = gaussian,\n                prior = c(prior(normal(0, 0.2), class = Intercept),\n                          prior(normal(0, 0.5), class = b),\n                          prior(exponential(1), class = sigma)),\n                iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n                file = here(\"fits\", \"chp7\", \"b7h1-line.rds\"))\n\nlaf_quad <- brm(tax_revenue ~ 1 + tax_rate + tax_rate2, data = laf_dat,\n                family = gaussian,\n                prior = c(prior(normal(0, 0.2), class = Intercept),\n                          prior(normal(0, 0.5), class = b),\n                          prior(exponential(1), class = sigma)),\n                iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n                file = here(\"fits\", \"chp7\", \"b7h1-quad.rds\"))\n\nlaf_spln <- brm(tax_revenue ~ 1 + s(tax_rate, bs = \"bs\"), data = laf_dat,\n                family = gaussian,\n                prior = c(prior(normal(0, 0.2), class = Intercept),\n                          prior(normal(0, 0.5), class = b),\n                          prior(normal(0, 0.5), class = sds),\n                          prior(exponential(1), class = sigma)),\n                iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n                control = list(adapt_delta = 0.95),\n                file = here(\"fits\", \"chp7\", \"bh71-spln.rds\"))\ntr_seq <- tibble(tax_rate = seq(0, 40, length.out = 100)) %>%\n  mutate(tax_rate = (tax_rate - mean(Laffer$tax_rate)) / sd(Laffer$tax_rate),\n         tax_rate2 = tax_rate ^ 2)\n\npredictions <- bind_rows(\n  predicted_draws(laf_line, newdata = tr_seq) %>%\n    median_qi(.width = 0.89) %>%\n    mutate(type = \"Linear\"),\n  predicted_draws(laf_quad, newdata = tr_seq) %>%\n    median_qi(.width = 0.89) %>%\n    mutate(type = \"Quadratic\"),\n  predicted_draws(laf_spln, newdata = tr_seq) %>%\n    median_qi(.width = 0.89) %>%\n    mutate(type = \"Spline\")\n)\n\nfits <- bind_rows(\n  epred_draws(laf_line, newdata = tr_seq) %>%\n    median_qi(.width = c(0.67, 0.89, 0.97)) %>%\n    mutate(type = \"Linear\"),\n  epred_draws(laf_quad, newdata = tr_seq) %>%\n    median_qi(.width = c(0.67, 0.89, 0.97)) %>%\n    mutate(type = \"Quadratic\"),\n  epred_draws(laf_spln, newdata = tr_seq) %>%\n    median_qi(.width = c(0.67, 0.89, 0.97)) %>%\n    mutate(type = \"Spline\")\n)\n\nggplot() +\n  facet_wrap(~type, nrow = 1) +\n  geom_ribbon(data = predictions,\n              aes(x = tax_rate, ymin = .lower, ymax = .upper),\n              alpha = 0.2) +\n  geom_lineribbon(data = fits,\n                  aes(x = tax_rate, y = .epred, ymin = .lower, ymax = .upper),\n                  size = 0.6) +\n  geom_point(data = laf_dat, aes(x = tax_rate, y = tax_revenue),\n             alpha = 0.5) +\n  scale_fill_manual(values = ramp_blue(seq(0.9, 0.1, length.out = 3)),\n                    breaks = c(0.67, 0.89, 0.97)) +\n  labs(x = \"Standardized Tax Rate\", y = \"Standardized Tax Revenue\",\n       fill = \"Interval\")\nlibrary(loo)\n\nlaf_line <- add_criterion(laf_line, criterion = c(\"loo\", \"waic\"))\nlaf_quad <- add_criterion(laf_quad, criterion = c(\"loo\", \"waic\"))\nlaf_spln <- add_criterion(laf_spln, criterion = c(\"loo\", \"waic\"))\n\nloo_compare(laf_line, laf_quad, laf_spln, criterion = \"waic\")\n#>          elpd_diff se_diff\n#> laf_quad  0.0       0.0   \n#> laf_spln -0.1       0.6   \n#> laf_line -0.9       0.9\nloo_compare(laf_line, laf_quad, laf_spln, criterion = \"loo\")\n#>          elpd_diff se_diff\n#> laf_spln  0.0       0.0   \n#> laf_quad  0.0       0.7   \n#> laf_line -0.8       0.9\nlibrary(gghighlight)\n\ncriteria_influence <- function(mod) {\n  tibble(pareto_k = mod$criteria$loo$diagnostics$pareto_k,\n         p_waic = mod$criteria$waic$pointwise[, \"p_waic\"]) %>%\n    rowid_to_column(var = \"obs\")\n}\n\ninflu <- bind_rows(\n  criteria_influence(laf_line) %>%\n    mutate(type = \"Linear\"),\n  criteria_influence(laf_quad) %>%\n    mutate(type = \"Quadratic\"),\n  criteria_influence(laf_spln) %>%\n    mutate(type = \"Spline\")\n)\n\nggplot(influ, aes(x = pareto_k, y = p_waic)) +\n  facet_wrap(~type, nrow = 1) +\n  geom_vline(xintercept = 0.7, linetype = \"dashed\") +\n  geom_hline(yintercept = 0.4, linetype = \"dashed\") +\n  geom_point() +\n  gghighlight(pareto_k > 0.7 | p_waic > 0.4, n = 1, label_key = obs,\n              label_params = list(size = 3)) +\n  labs(x = \"Pareto *k*\", y = \"p<sub>WAIC<\/sub>\")\nlaf_line2 <- brm(bf(tax_revenue ~ 1 + tax_rate, nu = 1),\n                 data = laf_dat, family = student,\n                 prior = c(prior(normal(0, 0.2), class = Intercept),\n                           prior(normal(0, 0.5), class = b),\n                           prior(exponential(1), class = sigma)),\n                 iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n                 file = here(\"fits\", \"chp7\", \"b7h2-line.rds\"))\n\nlaf_quad2 <- brm(bf(tax_revenue ~ 1 + tax_rate + tax_rate2, nu = 1),\n                 data = laf_dat, family = student,\n                 prior = c(prior(normal(0, 0.2), class = Intercept),\n                           prior(normal(0, 0.5), class = b),\n                           prior(exponential(1), class = sigma)),\n                 iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n                 file = here(\"fits\", \"chp7\", \"b7h2-quad.rds\"))\n\nlaf_spln2 <- brm(bf(tax_revenue ~ 1 + s(tax_rate, bs = \"bs\"), nu = 1),\n                 data = laf_dat, family = student,\n                 prior = c(prior(normal(0, 0.2), class = Intercept),\n                           prior(normal(0, 0.5), class = b),\n                           prior(normal(0, 0.5), class = sds),\n                           prior(exponential(1), class = sigma)),\n                 iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n                 control = list(adapt_delta = 0.99),\n                 file = here(\"fits\", \"chp7\", \"bh72-spln.rds\"))\npredictions <- bind_rows(\n  predicted_draws(laf_line2, newdata = tr_seq) %>%\n    median_qi(.width = 0.89) %>%\n    mutate(type = \"Linear\"),\n  predicted_draws(laf_quad2, newdata = tr_seq) %>%\n    median_qi(.width = 0.89) %>%\n    mutate(type = \"Quadratic\"),\n  predicted_draws(laf_spln2, newdata = tr_seq) %>%\n    median_qi(.width = 0.89) %>%\n    mutate(type = \"Spline\")\n)\n\nfits <- bind_rows(\n  epred_draws(laf_line2, newdata = tr_seq) %>%\n    median_qi(.width = c(0.67, 0.89, 0.97)) %>%\n    mutate(type = \"Linear\"),\n  epred_draws(laf_quad2, newdata = tr_seq) %>%\n    median_qi(.width = c(0.67, 0.89, 0.97)) %>%\n    mutate(type = \"Quadratic\"),\n  epred_draws(laf_spln2, newdata = tr_seq) %>%\n    median_qi(.width = c(0.67, 0.89, 0.97)) %>%\n    mutate(type = \"Spline\")\n)\n\nggplot() +\n  facet_wrap(~type, nrow = 1) +\n  geom_ribbon(data = predictions,\n              aes(x = tax_rate, ymin = .lower, ymax = .upper),\n              alpha = 0.2) +\n  geom_lineribbon(data = fits,\n                  aes(x = tax_rate, y = .epred, ymin = .lower, ymax = .upper),\n                  size = 0.6) +\n  geom_point(data = laf_dat, aes(x = tax_rate, y = tax_revenue),\n             alpha = 0.5) +\n  scale_fill_manual(values = ramp_blue(seq(0.9, 0.1, length.out = 3)),\n                    breaks = c(0.67, 0.89, 0.97)) +\n  labs(x = \"Standardized Tax Rate\", y = \"Standardized Tax Revenue\",\n       fill = \"Interval\")\nlaf_line2 <- add_criterion(laf_line2, criterion = c(\"loo\", \"waic\"))\nlaf_quad2 <- add_criterion(laf_quad2, criterion = c(\"loo\", \"waic\"))\nlaf_spln2 <- add_criterion(laf_spln2, criterion = c(\"loo\", \"waic\"))\n\nloo_compare(laf_line2, laf_quad2, laf_spln2, criterion = \"waic\")\n#>           elpd_diff se_diff\n#> laf_quad2  0.0       0.0   \n#> laf_spln2 -0.3       1.3   \n#> laf_line2 -1.1       1.7\nloo_compare(laf_line2, laf_quad2, laf_spln2, criterion = \"loo\")\n#>           elpd_diff se_diff\n#> laf_quad2  0.0       0.0   \n#> laf_spln2 -0.2       1.2   \n#> laf_line2 -1.1       1.7\nislands <- tibble(island = paste(\"Island\", 1:3),\n       a = c(0.2, 0.8, 0.05),\n       b = c(0.2, 0.1, 0.15),\n       c = c(0.2, 0.05, 0.7),\n       d = c(0.2, 0.025, 0.05),\n       e = c(0.2, 0.025, 0.05)) %>%\n  pivot_longer(-island, names_to = \"species\", values_to = \"prop\")\n\nislands %>%\n  group_by(island) %>%\n  summarize(prop = list(prop), .groups = \"drop\") %>%\n  mutate(entropy = map_dbl(prop, calc_entropy))\n#> # A tibble: 3 × 3\n#>   island   prop      entropy\n#>   <chr>    <list>      <dbl>\n#> 1 Island 1 <dbl [5]>   1.61 \n#> 2 Island 2 <dbl [5]>   0.743\n#> 3 Island 3 <dbl [5]>   0.984\nd_kl <- function(p, q) {\n  sum(p * (log(p) - log(q)))\n}\ncrossing(model = paste(\"Island\", 1:3),\n         predicts = paste(\"Island\", 1:3)) %>%\n  filter(model != predicts) %>%\n  left_join(islands, by = c(\"model\" = \"island\")) %>%\n  rename(model_prop = prop) %>%\n  left_join(islands, by = c(\"predicts\" = \"island\", \"species\")) %>%\n  rename(predict_prop = prop) %>%\n  group_by(model, predicts) %>%\n  summarize(q = list(model_prop),\n            p = list(predict_prop),\n            .groups = \"drop\") %>%\n  mutate(kl_distance = map2_dbl(p, q, d_kl))\n#> # A tibble: 6 × 5\n#>   model    predicts q         p         kl_distance\n#>   <chr>    <chr>    <list>    <list>          <dbl>\n#> 1 Island 1 Island 2 <dbl [5]> <dbl [5]>       0.866\n#> 2 Island 1 Island 3 <dbl [5]> <dbl [5]>       0.626\n#> 3 Island 2 Island 1 <dbl [5]> <dbl [5]>       0.970\n#> 4 Island 2 Island 3 <dbl [5]> <dbl [5]>       1.84 \n#> 5 Island 3 Island 1 <dbl [5]> <dbl [5]>       0.639\n#> 6 Island 3 Island 2 <dbl [5]> <dbl [5]>       2.01\nlibrary(dagitty)\nlibrary(ggdag)\n\nhma_dag <- dagitty(\"dag{H -> M <- A}\")\ncoordinates(hma_dag) <- list(x = c(H = 1, M = 2, A = 3),\n                             y = c(H = 1, M = 1, A = 1))\n\nggplot(hma_dag, aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_text(color = \"black\", size = 10) +\n  geom_dag_edges(edge_color = \"black\", edge_width = 2,\n                 arrow_directed = grid::arrow(length = grid::unit(15, \"pt\"),\n                                              type = \"closed\")) +\n  theme_void()\nd <- sim_happiness(seed = 1977, N_years = 1000)\ndat <- d %>%\n  filter(age > 17) %>%\n  mutate(a = (age - 18) / (65 - 18),\n         mid = factor(married + 1, labels = c(\"single\", \"married\")))\n\nb6.9 <- brm(happiness ~ 0 + mid + a, data = dat, family = gaussian,\n            prior = c(prior(normal(0, 1), class = b, coef = midmarried),\n                      prior(normal(0, 1), class = b, coef = midsingle),\n                      prior(normal(0, 2), class = b, coef = a),\n                      prior(exponential(1), class = sigma)),\n            iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n            file = here(\"fits\", \"chp7\", \"b7h4-6.9\"))\n\nb6.10 <- brm(happiness ~ 1 + a, data = dat, family = gaussian,\n             prior = c(prior(normal(0, 1), class = Intercept),\n                       prior(normal(0, 2), class = b, coef = a),\n                       prior(exponential(1), class = sigma)),\n             iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n             file = here(\"fits\", \"chp7\", \"b7h4-6.10\"))\nb6.9 <- add_criterion(b6.9, criterion = \"loo\")\nb6.10 <- add_criterion(b6.10, criterion = \"loo\")\n\nloo_compare(b6.9, b6.10)\n#>       elpd_diff se_diff\n#> b6.9     0.0       0.0 \n#> b6.10 -194.0      17.6\nadjustmentSets(hma_dag, exposure = \"A\", outcome = \"H\")\n#>  {}\ndata(foxes)\n\nfox_dat <- foxes %>%\n  as_tibble() %>%\n  select(area, avgfood, weight, groupsize) %>%\n  mutate(across(everything(), standardize))\n\nb7h5_1 <- brm(weight ~ 1 + avgfood + groupsize + area, data = fox_dat,\n              family = gaussian,\n              prior = c(prior(normal(0, 0.2), class = Intercept),\n                        prior(normal(0, 0.5), class = b),\n                        prior(exponential(1), class = sigma)),\n              iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n              file = here(\"fits\", \"chp7\", \"b7h5_1\"))\n\nb7h5_2 <- brm(weight ~ 1 + avgfood + groupsize, data = fox_dat,\n              family = gaussian,\n              prior = c(prior(normal(0, 0.2), class = Intercept),\n                        prior(normal(0, 0.5), class = b),\n                        prior(exponential(1), class = sigma)),\n              iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n              file = here(\"fits\", \"chp7\", \"b7h5_2\"))\n\nb7h5_3 <- brm(weight ~ 1 + groupsize + area, data = fox_dat,\n              family = gaussian,\n              prior = c(prior(normal(0, 0.2), class = Intercept),\n                        prior(normal(0, 0.5), class = b),\n                        prior(exponential(1), class = sigma)),\n              iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n              file = here(\"fits\", \"chp7\", \"b7h5_3\"))\n\nb7h5_4 <- brm(weight ~ 1 + avgfood, data = fox_dat,\n              family = gaussian,\n              prior = c(prior(normal(0, 0.2), class = Intercept),\n                        prior(normal(0, 0.5), class = b),\n                        prior(exponential(1), class = sigma)),\n              iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n              file = here(\"fits\", \"chp7\", \"b7h5_4\"))\n\nb7h5_5 <- brm(weight ~ 1 + area, data = fox_dat,\n              family = gaussian,\n              prior = c(prior(normal(0, 0.2), class = Intercept),\n                        prior(normal(0, 0.5), class = b),\n                        prior(exponential(1), class = sigma)),\n              iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n              file = here(\"fits\", \"chp7\", \"b7h5_5\"))\nb7h5_1 <- add_criterion(b7h5_1, criterion = \"waic\")\nb7h5_2 <- add_criterion(b7h5_2, criterion = \"waic\")\nb7h5_3 <- add_criterion(b7h5_3, criterion = \"waic\")\nb7h5_4 <- add_criterion(b7h5_4, criterion = \"waic\")\nb7h5_5 <- add_criterion(b7h5_5, criterion = \"waic\")\n\ncomp <- loo_compare(b7h5_1, b7h5_2, b7h5_3, b7h5_4, b7h5_5, criterion = \"waic\")\ncomp\n#>        elpd_diff se_diff\n#> b7h5_1  0.0       0.0   \n#> b7h5_3 -0.4       1.4   \n#> b7h5_2 -0.4       1.7   \n#> b7h5_4 -5.2       3.4   \n#> b7h5_5 -5.3       3.4\nplot_comp <- comp %>%\n  as_tibble(rownames = \"model\") %>%\n  mutate(across(-model, as.numeric),\n         model = fct_inorder(model))\n\nwaic_val <- plot_comp %>%\n  select(model, waic, se = se_waic) %>%\n  mutate(lb = waic - se,\n         ub = waic + se)\n\ndiff_val <- plot_comp %>%\n  select(model, waic, se = se_diff) %>%\n  mutate(se = se * 2) %>%\n  mutate(lb = waic - se,\n         ub = waic + se) %>%\n  filter(se != 0)\n\nggplot() +\n  geom_pointrange(data = waic_val, mapping = aes(x = waic, xmin = lb, xmax = ub,\n                                                 y = fct_rev(model))) +\n  geom_pointrange(data = diff_val, mapping = aes(x = waic, xmin = lb, xmax = ub,\n                                                 y = fct_rev(model)),\n                  position = position_nudge(y = 0.2), shape = 2,\n                  color = \"#009FB7\") +\n  labs(x = \"Deviance\", y = NULL)"},{"path":"overfitting-mcmc.html","id":"chapter-8","chapter":"Week 4: Overfitting / MCMC","heading":"4.2.2 Chapter 8","text":"8E1. causal relationships , name hypothetical third variable lead interaction effect.Bread dough rises yeast.Education leads higher income.Gasoline makes car go.first, amount heat can moderate relationship yeast amount dough rises. second example, ethnicity may give rise interaction, individuals races face systemic challenges (.e., ’s easier white people low education get job people color). Thus, education may effect minorities. Finally, car also requires wheels. Wheels gas gas wheels prevent car moving; car go.8E2. following explanations invokes interaction?Caramelizing onions requires cooking low heat making sure onions dry .car go faster cylinders better fuel injector.people acquire political beliefs parents, unless get instead friends.Intelligent animal species tend either highly social manipulative appendages (hands, tentacles, etc.).first example one , strictly speaking, interaction. , low heat leads camelization, conditional onions drying . second statement, phrased either cylinders better fuel injector result faster speed. number three, phrased “.” People acquire beliefs parents friends. written, nothing indicate influence parents’ beliefs depends influence friends’ beliefs (vice versa). Finally, last statement also phrased “.” indicate influence one factor impacts influence .8E3. explanations 8E2, write linear model expresses stated relationship.onion caramelization, mathematical model :\\[\n\\begin{align}\nC_i &\\sim \\text{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\beta_HH_i + \\beta_MM_i + \\beta_{HM}H_iM_i\n\\end{align}\n\\]mathematical model car speed similar:\\[\n\\begin{align}\nS_i &\\sim \\text{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\beta_CC_i + \\beta_FF_i\n\\end{align}\n\\]similar model political beliefs:\\[\n\\begin{align}\nB_i &\\sim \\text{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\beta_PP_i + \\beta_FF_i\n\\end{align}\n\\]finally model intelligence:\\[\n\\begin{align}\nI_i &\\sim \\text{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\beta_SS_i + \\beta_MM_i\n\\end{align}\n\\]8M1. Recall tulips example chapter. Suppose another set treatments adjusted temperature greenhouse two levels: cold hot. data chapter collected cold temperature. find none plants grown hot temperature developed blooms , regardless water shade levels. Can explain result terms interactions water, shade, temperature?chapter example, saw cool temperatures, blooms best predicted water, shade, interaction. , learn neither water light matter high temperature. implies three-way interaction. Just chapter water effect light, see neither water light effect temperature high.8M2. Can invent regression equation make bloom size zero, whenever temperature hot?model, can use interaction model chapter additional predictor (\\(C\\)) 0 temperature hot 1 temperature cold.\\[\n\\begin{align}\nB_i &\\sim \\text{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i &= C_i \\times (\\alpha + \\beta_WW_i + \\beta_SS_i + \\beta_{WS}W_iS_i)\n\\end{align}\n\\]8M3. parts North America, ravens depend upon wolves food. ravens carnivorous usually kill open carcasses prey. Wolves however can kill tear open animals, tolerate ravens co-feeding kills. species relationship generally described “species interaction.” Can invent hypothetical set data raven population size relationship manifest statistical interaction? think biological interaction linear? ?order predict raven population size based wolf population size, include data territory area wolves, number wolves, amount food available, finally number ravens. similar types data included data(foxes). expect relationship non-linear. wolves, expect ravens. number wolves increases, number ravens also increase. However, eventually number wolves increase point wolves exhaust food supply, leaving food left ravens, point raven population begin shrink. Thus, created counter factual plot wolves x-axis ravens y-axis, expect see linear trend first, raven population level drop large numbers wolves.8M4. Repeat tulips analysis, time use priors constrain effect water positive effect shade negative. Use prior predictive simulation. prior asumptions mean interaction prior, anything?issues constraining different coefficients bounded parameters (especially negative parameters) {brms}. details, see thread Stan discourse. get around , rather constrain shade parameter negative, ’ll create new variable opposite shade, light corresponding light_cent. can constrain parameter positive, just water_cent parameter constrained positive. Finally, new light variable positivity constraints main effects, also want constrain interaction term positive. , water light increase, expect additional additive effect.Looking posterior predicted blooms, results similar saw Figure 8.7 text. indicates prior constraints large effect predicted values.Finally, let’s look prior predictive simulation model. Overall priors might little uninformative, especially interaction. interaction impact far right panel figure, many lines exceed expected boundaries panel.8H1. Return data(tulips) example chapter. Now include bed variable predictor interaction model. Don’t interact bed predictors; just include main effect. Note bed categorical. use properly, need either construct dummy variables, rather index variable, explained Chapter 5.bed variable already factor variable tulips data, can just add formula brm(). use indicator variables instead dummy variable, remove separate intercept (.e., ~ 0 formula ). ’s coming next question, ’ll use light instead shade model also.8H2. Use WAIC compare model 8H1 model omits bed. infer comparison? Can reconcile WAIC results posterior distribution bed coefficients?comparison, ’ll compare b8h1 model b8m4, model chapter, new prior distributions constrain main effect water positive main effect shade negative (.e., main effect light positive).Model b8h1 preferred model; however, standard error difference larger magnitude difference, indicating WAIC able meaningfully differentiate two models. predictive purposes, means inclusion bed variable significantly improve model. also noted models exceptionally large penalty values, analyses may unreliable, consider re-fitting models distribution fatter tails.8H3. Consider data(rugged) data economic development terrain ruggedness, examined chapter. One African countries example Seychelles, far outside cloud nations, rare country relatively high GDP high ruggedness. Seychelles also unusual, group islands far coast mainland Africa, main economic activity tourism.Focus model m8.5 chapter. Use WAIC pointwise penalties PSIS Pareto k values measure relative influence country. criteria, Seychelles influencing results? nations relatively influential? , can explain ?Now use robust regression, described previous chapter. Modify m8.5 se Student-t distribution \\(\\nu = 2\\). change results substantial way?text, model m8.5 uses tulips data, ’m assuming typo looking model m8.3, interaction model terrain ruggedness example chapter. , let’s first create {brms} version model m8.3.Now let’s take look Pareto k \\(p_{\\Tiny\\text{WAIC}}\\) values model. Seychelles appear influential. Pareto \\(k\\) value 0.7 threshold; however, \\(p_{\\Tiny\\text{WAIC}}\\) value 0.4 threshold. countries Pareto k \\(p_{\\Tiny\\text{WAIC}}\\) values thresholds.Now part (b), ’ll use Student-t distribution \\(\\nu = 2\\).much Student’s t distribution affect model? Let’s look posterior distribution difference African Non-African countries. Student’s t model, difference actually increased average. switching distribution affects points, just high leverage points flagged originally. Therefore, ’s unexpected distribution might shift.8H4. values data(nettle) data language diversity 74 nations.1 meaning column given .country: Name countrynum.lang: Number recognized languages spokenarea: Area square kilometersk.pop: Population, thousandsnum.stations: Number weather stations provided data next two columnsmean.growing.season: Average length growing season, monthssd.growing.season: Standard deviation length growing season, monthsUse data evaluate hypothesis language diversity partly product food security. notion , productive ecologies, people don’t need large social networks buffer risk food shortfalls. means cultural groups can smaller self-sufficient, leading languages per capita. Use number languages per capita outcome:Use logarithm new variable regression outcome. (count model better , ’ll learn later, Chapter 11.) problem open ended, allowing decide address hypotheses uncertain advice modeling provides. think need use WAIC anyplace, please . think need certain priors, argue . think need plot predictions certain way, please . Just try honestly evaluate main effects mean.growing.season sd.growing.season, well two-way interaction. three parts help.Evaluate hypothesis language diversity, measured log(lang.per.cap), positively associated average length growing season, mean.growing.season. Consider log(area) regression(s) covariate (interaction). Interpret results.First, let’s calculate new variables ’ll need models. ’ll also go ahead standardize everything make setting priors little bit easier.’ll start fitting two models, one mean_growing_std predictor, one also includes area_std. can compare models using PSIS-LOO.see model without area slightly preferred, PSIS-LOO isn’t really able distinguish models well. purpose exercise, ’ll continue model b8h4a_2, includes predictors. Visualizing model, see , expected given model comparisons, area doesn’t appear much impact. However, appear positive relationship mean growing season number languages.Now evaluate hypothesis language diversity negatively associated standard deviation length growing season, sd.growing.season. hypothesis follows uncertainty harvest favoring social insurance larger social networks therefore fewer languages. , consider log(area) covariate (interaction). Interpret results.second part, replace mean_growing_std sd_growing_std. , ’ll fit two models compare PSIS-LOO.story much . PSIS-LOO can’t really differentiate two models, indicating area doesn’t add much information. reflected visualization. see expected distribution regression lines fairly similar levels area. Additionally, see negative relationship standard deviation growing season number languages, question suggested.Finally, evaluate hypothesis mean.growing.season sd.growing.season interact synergistically reduce language diversity. idea , nations longer average growing seasons, high variance makes storage redistribution even important otherwise. way, people can cooperate preserve protect windfalls used droughts.third part question, asked add interaction term. ’ll drop area since appear effect either previous parts question.see interaction negative. means can seen visualizing interaction directions. shown following image. top row, plot expected effect mean growing season languages. see positive relationship mean growing season languages, except high variance growing. Similarly, bottom row shows expected effect standard deviation growing season languages. mean growing season short, effect variance languages. mean growing season long, negative relationship variance languages.8H5. Consider data(Wines2012) data table. data expert ratings 20 different French American wines 9 different French American judges. goal model score, subjective rating assigned judge wine. recommend standardizing . problem, consider variation among judges wines. Construct index variables judge wine use index variables construct linear regression model. Justify priors. end 9 judge parameters 20 wine parameters. interpret variation among individual judges individual wines? notice patterns, just plotting differences? judges gave highest/lowest ratings? wines rated worst/best average?First, let’s prepare data. ’ll standardize score create index variables judge wine.Next, ’ll fit model, remembering remove overall intercept (.e., ~ 0) index variables estimated correctly. scores standardized, can use normal(0, 0.5) prior ’ve used previously used throughout much text. ’ll also extract posterior draws can explore posterior judge wine individually.Looking distributions judge, can see John Foy tends give highest scores, whereas Robert Hodgson Jean-M Cardebat give lowest scores average.wines, B2, J2, D2, D1, B1 received highest scores average, wine I2 clearly lowest rated wines. However, overall, variability among judges among wines.8H6. Now consider three features wines judges:flight: Whether wine red white.wine.amer: Indicator variable American wines.judge.amer: Indicator variable American judges.Use indicator index variables model influence features scores. Omit individual judge wine index variables Problem 1. include interaction effects yet. justify priors conclude differences among wines judges? Try relate results inferences previous problem.can estimate {brms} model defined . definition, ’re using indicator variables rather index variables, make next question little bit easier. ’ll use standard normal(0, 0.2) prior intercept, since near zero given score standardized. coefficients, ask reasonable difference scores New Jersey French wines, New Jersey French judges, red white wine. One standard deviation seems edge might reasonable, ’ll use normal(0, 0.5), leave sufficient probability tails. priors constrain space plausible values, probably use tighter priors slope parameters wanted get regularization.indicated last problem, basically effect red vs. white wine. appear slight preference French wines; however, ’s good deal posterior density sides 0. confirms found last problem: little variation coming wines. see slightly stronger effect among judges, American judges giving higher scores average.8H7. Now consider two-way interactions among three features. end three different interaction terms model. easier build, use indicator variables. justify priors. Explain interaction means. sure interpret model’s predictions outcome scale (mu, expected score), scale individual parameters. can use link help , just use knowledge linear model instead. conclude features scores? Can relate results model(s) individual judge wine inferences 8H5?’ll start fitting model. ’ve used priors previous problem intercept main effect parameters. interactions, specified normal(0, 0.25) prior. interaction priors little tighter keep subsetting sample, values can’t keep getting larger larger.interpret parameters mean, can visualize predicted score combination judge, wine location, wine type. figure see combinations judge wine white wines. However, appear slight differences red wines. general, French judges really don’t like American reds, American judges really like French reds.","code":"\nlibrary(rethinking)\ndata(\"tulips\")\n\ntulip_dat <- tulips %>%\n  as_tibble() %>%\n  mutate(light = -1 * shade,\n         blooms_std = blooms / max(blooms),\n         water_cent = water - mean(water),\n         shade_cent = shade - mean(shade),\n         light_cent = light - mean(light))\n\nb8m4 <- brm(blooms_std ~ 1 + water_cent + light_cent + water_cent:light_cent,\n            data = tulip_dat, family = gaussian,\n            prior = c(prior(normal(0.5, 0.25), class = Intercept),\n                      prior(normal(0, 0.25), class = b, lb = 0),\n                      prior(exponential(1), class = sigma)),\n            iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n            file = here(\"fits\", \"chp8\", \"b8m4\"))\n\nsummary(b8m4)\n#>  Family: gaussian \n#>   Links: mu = identity; sigma = identity \n#> Formula: blooms_std ~ 1 + water_cent + light_cent + water_cent:light_cent \n#>    Data: tulip_dat (Number of observations: 27) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 0; thin = 1;\n#>          total post-warmup draws = 8000\n#> \n#> Population-Level Effects: \n#>                       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\n#> Intercept                 0.36      0.03     0.30     0.41 1.00     7951\n#> water_cent                0.21      0.03     0.14     0.27 1.00     7826\n#> light_cent                0.11      0.03     0.04     0.18 1.00     5064\n#> water_cent:light_cent     0.14      0.04     0.06     0.22 1.00     7552\n#>                       Tail_ESS\n#> Intercept                 5632\n#> water_cent                4256\n#> light_cent                2627\n#> water_cent:light_cent     3884\n#> \n#> Family Specific Parameters: \n#>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sigma     0.14      0.02     0.11     0.20 1.00     5469     5185\n#> \n#> Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\nnew_tulip <- crossing(water_cent = -1:1, \n                      light_cent = -1:1)\n\npoints <- tulip_dat %>%\n  expand(nesting(water_cent, light_cent, blooms_std)) %>%\n  mutate(light_grid = glue(\"light_cent = {light_cent}\"))\n\nto_string <- as_labeller(c(`-1` = \"Light = -1\", `0` = \"Light = 0\", \n                           `1` = \"Light = 1\"))\n\nnew_tulip %>% \n  add_epred_draws(b8m4, ndraws = 50) %>% \n  ungroup() %>% \n  ggplot(aes(x = water_cent, y = .epred)) +\n  facet_wrap(~light_cent, nrow = 1,\n             labeller = to_string) +\n  geom_line(aes(group = .draw), alpha = 0.4) +\n  geom_point(data = points, aes(y = blooms_std), color = \"#009FB7\") +\n  scale_x_continuous(breaks = -1:1) +\n  labs(x = \"Water (centered)\", y = \"Blooms (standardized)\")\nb8m4p <- update(b8m4, sample_prior = \"only\",\n                iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n                file = here(\"fits\", \"chp8\", \"b8m4p.rds\"))\n#> The desired updates require recompiling the model\n\nnew_tulip %>% \n  add_epred_draws(b8m4p, ndraws = 50) %>% \n  ungroup() %>% \n  ggplot(aes(x = water_cent, y = .epred)) +\n  facet_wrap(~light_cent, nrow = 1,\n             labeller = to_string) +\n  geom_line(aes(group = .draw), alpha = 0.3) +\n  geom_hline(yintercept = c(0, 1), linetype = \"dashed\") +\n  scale_x_continuous(breaks = -1:1) +\n  labs(x = \"Water (centered)\", y = \"Blooms (standardized)\")\nb8h1 <- brm(blooms_std ~ 0 + water_cent + light_cent + bed + \n              water_cent:light_cent,\n            data = tulip_dat, family = gaussian,\n            prior = c(prior(normal(0, 0.25), class = b),\n                      prior(exponential(1), class = sigma)),\n            iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n            file = here(\"fits\", \"chp8\", \"b8h1.rds\"))\n\nsummary(b8h1)\n#>  Family: gaussian \n#>   Links: mu = identity; sigma = identity \n#> Formula: blooms_std ~ 0 + water_cent + light_cent + bed + water_cent:light_cent \n#>    Data: tulip_dat (Number of observations: 27) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 0; thin = 1;\n#>          total post-warmup draws = 8000\n#> \n#> Population-Level Effects: \n#>                       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\n#> water_cent                0.21      0.03     0.14     0.27 1.00    11367\n#> light_cent                0.11      0.03     0.05     0.17 1.00    12221\n#> beda                      0.26      0.04     0.17     0.35 1.00    12912\n#> bedb                      0.38      0.04     0.29     0.47 1.00    12297\n#> bedc                      0.40      0.04     0.31     0.48 1.00    12459\n#> water_cent:light_cent     0.14      0.04     0.07     0.22 1.00    12903\n#>                       Tail_ESS\n#> water_cent                6156\n#> light_cent                6045\n#> beda                      5953\n#> bedb                      5615\n#> bedc                      5556\n#> water_cent:light_cent     6107\n#> \n#> Family Specific Parameters: \n#>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sigma     0.13      0.02     0.10     0.18 1.00     6707     5592\n#> \n#> Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\nb8m4 <- add_criterion(b8m4, criterion = \"waic\")\nb8h1 <- add_criterion(b8h1, criterion = \"waic\")\n\nloo_compare(b8m4, b8h1, criterion = \"waic\") %>%\n  print(simplify = FALSE)\n#>      elpd_diff se_diff elpd_waic se_elpd_waic p_waic se_p_waic waic  se_waic\n#> b8h1   0.0       0.0    13.7       3.3          6.2    1.4     -27.3   6.6  \n#> b8m4  -1.2       3.0    12.5       3.8          4.3    1.1     -24.9   7.6\ndata(\"rugged\")\nrugged_dat <- rugged %>%\n  as_tibble() %>%\n  select(country, rgdppc_2000, rugged, cont_africa) %>%\n  drop_na(rgdppc_2000) %>%\n  mutate(log_gdp = log(rgdppc_2000),\n         log_gdp_std = log_gdp / mean(log_gdp),\n         rugged_std = rugged / max(rugged),\n         rugged_std_cent = rugged_std - mean(rugged_std),\n         cid = factor(cont_africa, levels = c(1, 0),\n                      labels = c(\"African\", \"Not African\")))\n\nb8h3 <- brm(\n  bf(log_gdp_std ~ 0 + a + b * rugged_std_cent,\n     a ~ 0 + cid,\n     b ~ 0 + cid,\n     nl = TRUE),\n  data = rugged_dat, family = gaussian,\n  prior = c(prior(normal(1, 0.1), class = b, coef = cidAfrican, nlpar = a),\n            prior(normal(1, 0.1), class = b, coef = cidNotAfrican, nlpar = a),\n            prior(normal(0, 0.3), class = b, coef = cidAfrican, nlpar = b),\n            prior(normal(0, 0.3), class = b, coef = cidNotAfrican, nlpar = b),\n            prior(exponential(1), class = sigma)),\n  iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n  file = here(\"fits\", \"chp8\", \"b8h3.rds\")\n)\n\nb8h3 <- add_criterion(b8h3, criterion = c(\"loo\", \"waic\"))\n\nsummary(b8h3)\n#>  Family: gaussian \n#>   Links: mu = identity; sigma = identity \n#> Formula: log_gdp_std ~ 0 + a + b * rugged_std_cent \n#>          a ~ 0 + cid\n#>          b ~ 0 + cid\n#>    Data: rugged_dat (Number of observations: 170) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 0; thin = 1;\n#>          total post-warmup draws = 8000\n#> \n#> Population-Level Effects: \n#>                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> a_cidAfrican        0.89      0.02     0.85     0.92 1.00     9876     6334\n#> a_cidNotAfrican     1.05      0.01     1.03     1.07 1.00    10083     6572\n#> b_cidAfrican        0.13      0.08    -0.02     0.28 1.00     9543     6356\n#> b_cidNotAfrican    -0.14      0.05    -0.25    -0.04 1.00     9485     6149\n#> \n#> Family Specific Parameters: \n#>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sigma     0.11      0.01     0.10     0.12 1.00     8960     6057\n#> \n#> Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\nlibrary(gghighlight)\n\ntibble(pareto_k = b8h3$criteria$loo$diagnostics$pareto_k,\n       p_waic = b8h3$criteria$waic$pointwise[, \"p_waic\"]) %>%\n  rowid_to_column(var = \"obs\") %>%\n  left_join(rugged_dat %>%\n              select(country) %>%\n              rowid_to_column(var = \"obs\"),\n            by = \"obs\") %>%\n  ggplot(aes(x = pareto_k, y = p_waic)) +\n  geom_vline(xintercept = 0.7, linetype = \"dashed\") +\n  geom_hline(yintercept = 0.4, linetype = \"dashed\") +\n  geom_point() +\n  gghighlight(pareto_k > 0.7 | p_waic > 0.4, n = 1, label_key = country,\n              label_params = list(size = 3)) +\n  labs(x = \"Pareto *k*\", y = \"p<sub>WAIC<\/sub>\")\nb8h3_t <- brm(\n  bf(log_gdp_std ~ 0 + a + b * rugged_std_cent,\n     a ~ 0 + cid,\n     b ~ 0 + cid,\n     nu = 2,\n     nl = TRUE),\n  data = rugged_dat, family = student,\n  prior = c(prior(normal(1, 0.1), class = b, coef = cidAfrican, nlpar = a),\n            prior(normal(1, 0.1), class = b, coef = cidNotAfrican, nlpar = a),\n            prior(normal(0, 0.3), class = b, coef = cidAfrican, nlpar = b),\n            prior(normal(0, 0.3), class = b, coef = cidNotAfrican, nlpar = b),\n            prior(exponential(1), class = sigma)),\n  iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n  file = here(\"fits\", \"chp8\", \"b8h3_t.rds\")\n)\n\nb8h3_t <- add_criterion(b8h3_t, criterion = c(\"loo\", \"waic\"))\nn_diff <- spread_draws(b8h3, b_b_cidAfrican, b_b_cidNotAfrican) %>% \n  mutate(diff = b_b_cidAfrican - b_b_cidNotAfrican)\n\nt_diff <- spread_draws(b8h3_t, b_b_cidAfrican, b_b_cidNotAfrican) %>% \n  mutate(diff = b_b_cidAfrican - b_b_cidNotAfrican)\n\nggplot() +\n  geom_density(data = n_diff, aes(x = diff, fill = \"Normal\"),\n               color = NA, alpha = 0.6) +\n  geom_density(data = t_diff, aes(x = diff, fill = \"Student's *t*\"),\n               color = NA, alpha = 0.6) +\n  scale_fill_manual(values = c(\"#009FB7\", \"#FED766\")) +\n  labs(x = \"African &minus; Non-African\", y = \"Density\", fill = NULL) +\n  theme(legend.text = element_markdown())\nd$lang.per.cap <- d$num.lang / d$k.pop\ndata(nettle)\n\nnettle <- nettle %>%\n  as_tibble() %>%\n  mutate(lang_per_cap = num.lang / k.pop,\n         log_lang_per_cap = log(lang_per_cap),\n         log_area = log(area),\n         lang_per_cap_std = standardize(log_lang_per_cap),\n         area_std = standardize(log_area),\n         mean_growing_std = standardize(mean.growing.season),\n         sd_growing_std = standardize(sd.growing.season))\n\nnettle\n#> # A tibble: 74 × 14\n#>    country num.lang   area  k.pop num.stations mean.growing.se… sd.growing.seas…\n#>    <fct>      <int>  <int>  <int>        <int>            <dbl>            <dbl>\n#>  1 Algeria       18 2.38e6  25660          102             6.6              2.29\n#>  2 Angola        42 1.25e6  10303           50             6.22             1.87\n#>  3 Austra…      234 7.71e6  17336          134             6                4.17\n#>  4 Bangla…       37 1.44e5 118745           20             7.4              0.73\n#>  5 Benin         52 1.13e5   4889            7             7.14             0.99\n#>  6 Bolivia       38 1.10e6   7612           48             6.92             2.5 \n#>  7 Botswa…       27 5.82e5   1348           10             4.6              1.69\n#>  8 Brazil       209 8.51e6 153322          245             9.71             5.87\n#>  9 Burkin…       75 2.74e5   9242            6             5.17             1.07\n#> 10 CAR           94 6.23e5   3127           13             8.08             1.21\n#> # … with 64 more rows, and 7 more variables: lang_per_cap <dbl>,\n#> #   log_lang_per_cap <dbl>, log_area <dbl>, lang_per_cap_std <dbl>,\n#> #   area_std <dbl>, mean_growing_std <dbl>, sd_growing_std <dbl>\nb8h4a_1 <- brm(lang_per_cap_std ~ mean_growing_std,\n               data = nettle, family = gaussian,\n               prior = c(prior(normal(0, 0.2), class = Intercept),\n                         prior(normal(0, 0.5), class = b),\n                         prior(exponential(1), class = sigma)),\n               iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n               file = here(\"fits\", \"chp8\", \"b8h4a_1.rds\"))\n\nb8h4a_2 <- brm(lang_per_cap_std ~ mean_growing_std + area_std,\n               data = nettle, family = gaussian,\n               prior = c(prior(normal(0, 0.2), class = Intercept),\n                         prior(normal(0, 0.5), class = b),\n                         prior(exponential(1), class = sigma)),\n               iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n               file = here(\"fits\", \"chp8\", \"b8h4a_2.rds\"))\n\nb8h4a_1 <- add_criterion(b8h4a_1, criterion = \"loo\")\nb8h4a_2 <- add_criterion(b8h4a_2, criterion = \"loo\")\n\nloo_compare(b8h4a_1, b8h4a_2)\n#>         elpd_diff se_diff\n#> b8h4a_1  0.0       0.0   \n#> b8h4a_2 -0.1       1.6\nnew_nettle <- crossing(area_std = seq(-4, 4, by = 2),\n                       mean_growing_std = seq(-4, 4, by = 1),\n                       sd_growing_std = seq(-4, 4, by = 1))\n\nto_string <- as_labeller(c(`-4` = \"Area = -4\", `-2` = \"Area = -2\",\n                           `0` = \"Area = 0\", \n                           `2` = \"Area = 2\", `4` = \"Area = 4\"))\n\nnew_nettle %>% \n  add_epred_draws(b8h4a_2, ndraws = 1000) %>% \n  mean_qi(.width = c(0.67, 0.89, 0.97)) %>% \n  ggplot(aes(x = mean_growing_std, y = .epred, ymin = .lower, ymax = .upper)) +\n  facet_wrap(~area_std, nrow = 1, labeller = to_string) +\n  geom_lineribbon(color = NA) +\n  scale_fill_manual(values = ramp_blue(seq(0.9, 0.2, length.out = 3)),\n                    breaks = c(\"0.67\", \"0.89\", \"0.97\")) +\n  labs(x = \"Mean Growing Season (standardized)\",\n       y = \"Log Languages per Capita (standardized)\",\n       fill = \"Interval\")\nb8h4b_1 <- brm(lang_per_cap_std ~ sd_growing_std,\n               data = nettle, family = gaussian,\n               prior = c(prior(normal(0, 0.2), class = Intercept),\n                         prior(normal(0, 0.5), class = b),\n                         prior(exponential(1), class = sigma)),\n               iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n               file = here(\"fits\", \"chp8\", \"b8h4b_1.rds\"))\n\nb8h4b_2 <- brm(lang_per_cap_std ~ sd_growing_std + area_std,\n               data = nettle, family = gaussian,\n               prior = c(prior(normal(0, 0.2), class = Intercept),\n                         prior(normal(0, 0.5), class = b),\n                         prior(exponential(1), class = sigma)),\n               iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n               file = here(\"fits\", \"chp8\", \"b8h4b_2.rds\"))\n\nb8h4b_1 <- add_criterion(b8h4b_1, criterion = \"loo\")\nb8h4b_2 <- add_criterion(b8h4b_2, criterion = \"loo\")\n\nloo_compare(b8h4b_1, b8h4b_2)\n#>         elpd_diff se_diff\n#> b8h4b_1 0.0       0.0    \n#> b8h4b_2 0.0       1.7\nnew_nettle %>% \n  add_epred_draws(b8h4b_2, ndraws = 1000) %>% \n  mean_qi(.width = c(0.67, 0.89, 0.97)) %>% \n  ggplot(aes(x = sd_growing_std, y = .epred, ymin = .lower, ymax = .upper)) +\n  facet_wrap(~area_std, nrow = 1, labeller = to_string) +\n  geom_lineribbon(color = NA) +\n  scale_fill_manual(values = ramp_blue(seq(0.9, 0.2, length.out = 3)),\n                    breaks = c(\"0.67\", \"0.89\", \"0.97\")) +\n  labs(x = \"Standard Deviation of Growing Season (standardized)\",\n       y = \"Log Languages per Capita (standardized)\",\n       fill = \"Interval\")\nb8h4_c <- brm(lang_per_cap_std ~ mean_growing_std * sd_growing_std,\n              data = nettle, family = gaussian,\n              prior = c(prior(normal(0, 0.2), class = Intercept),\n                        prior(normal(0, 0.5), class = b),\n                        prior(exponential(1), class = sigma)),\n              iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n              file = here(\"fits\", \"chp8\", \"b8h4_c.rds\"))\n\nsummary(b8h4_c)\n#>  Family: gaussian \n#>   Links: mu = identity; sigma = identity \n#> Formula: lang_per_cap_std ~ mean_growing_std * sd_growing_std \n#>    Data: nettle (Number of observations: 74) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 0; thin = 1;\n#>          total post-warmup draws = 8000\n#> \n#> Population-Level Effects: \n#>                                 Estimate Est.Error l-95% CI u-95% CI Rhat\n#> Intercept                           0.00      0.09    -0.18     0.19 1.00\n#> mean_growing_std                    0.23      0.11     0.01     0.46 1.00\n#> sd_growing_std                     -0.23      0.10    -0.43    -0.03 1.00\n#> mean_growing_std:sd_growing_std    -0.24      0.11    -0.44    -0.03 1.00\n#>                                 Bulk_ESS Tail_ESS\n#> Intercept                           8427     5784\n#> mean_growing_std                    7513     6080\n#> sd_growing_std                      9774     5790\n#> mean_growing_std:sd_growing_std     8652     6050\n#> \n#> Family Specific Parameters: \n#>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sigma     0.89      0.08     0.75     1.06 1.00     7972     5945\n#> \n#> Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\nlibrary(patchwork)\n\nnew_nettle <- crossing(mean_growing_std = seq(-2, 2, by = 0.5),\n                       sd_growing_std = seq(-2, 4, by = 0.5))\n\nint_preds <- new_nettle %>% \n  add_epred_draws(b8h4_c, ndraws = 1000) %>% \n  mean_qi(.width = 0.97)\n\nfacet_levels <- seq(-2, 2, by = 2)\nsd_facets <- list_along(facet_levels)\nfor (i in seq_along(sd_facets)) {\n  points <- nettle %>% \n    mutate(diff = sd_growing_std - facet_levels[i])\n  \n  p <- int_preds %>% \n    filter(sd_growing_std == facet_levels[i]) %>% \n    ggplot(aes(x = mean_growing_std, y = .epred, ymin = .lower,\n               ymax = .upper)) +\n    geom_lineribbon(fill = \"#99D8E2\", color = \"black\") +\n    geom_point(data = points,\n               aes(x = mean_growing_std, y = lang_per_cap_std,\n                   alpha = -1 * abs(diff)), size = 0.5,\n               inherit.aes = FALSE, show.legend = FALSE) +\n    expand_limits(x = c(-2, 2), y = c(-2.5, 3.5)) +\n    labs(x = \"Mean growing season\", y = \"Languages\",\n         subtitle = glue(\"SD growing season = {facet_levels[i]}\")) +\n    theme(plot.subtitle = element_text(size = 10))\n  \n  if (i == 2) {\n    p <- p +\n      theme(plot.margin = margin(0, 20, 0, 20))\n  } else {\n    p <- p +\n      theme(plot.margin = margin(0, 0, 0, 0))\n  }\n  \n  sd_facets[[i]] <- p\n}\n\nmean_facets <- list_along(facet_levels)\nfor (i in seq_along(mean_facets)) {\n  points <- nettle %>% \n    mutate(diff = mean_growing_std - facet_levels[i])\n  \n  p <- int_preds %>% \n    filter(mean_growing_std == facet_levels[i]) %>% \n    ggplot(aes(x = sd_growing_std, y = .epred, ymin = .lower,\n               ymax = .upper)) +\n    geom_lineribbon(fill = \"#99D8E2\", color = \"black\") +\n    geom_point(data = points,\n               aes(x = sd_growing_std, y = lang_per_cap_std,\n                   alpha = -1 * abs(diff)), size = 0.5,\n               inherit.aes = FALSE, show.legend = FALSE) +\n    expand_limits(x = c(-2, 2), y = c(-2.5, 3.5)) +\n    labs(x = \"SD growing season\", y = \"Languages\",\n         subtitle = glue(\"Mean growing season = {facet_levels[i]}\")) +\n    theme(plot.subtitle = element_text(size = 10))\n  \n  if (i == 2) {\n    p <- p +\n      theme(plot.margin = margin(30, 20, 0, 20))\n  } else {\n    p <- p +\n      theme(plot.margin = margin(30, 0, 0, 0))\n  }\n  \n  mean_facets[[i]] <- p\n}\n\nsd_patch <- (sd_facets[[1]] | sd_facets[[2]] | sd_facets[[3]])\nmean_patch <- (mean_facets[[1]] | mean_facets[[2]] | mean_facets[[3]])\n\nsd_patch / mean_patch\ndata(Wines2012)\n\nwine <- Wines2012 %>%\n  as_tibble() %>%\n  mutate(score_std = standardize(score),\n         judge_ind = factor(as.integer(judge)),\n         wine_ind = factor(as.integer(wine)),\n         red = factor(flight, levels = c(\"white\", \"red\")),\n         wine_amer = factor(wine.amer),\n         judge_amer = factor(judge.amer))\nb8h5 <- brm(bf(score_std ~ 0 + j + w,\n               j ~ 0 + judge_ind,\n               w ~ 0 + wine_ind,\n               nl = TRUE),\n            data = wine, family = gaussian,\n            prior = c(prior(normal(0, 0.5), nlpar = j),\n                      prior(normal(0, 0.5), nlpar = w),\n                      prior(exponential(1), class = sigma)),\n            iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n            file = here(\"fits\", \"chp8\", \"b8h5.rds\"))\n\ndraws <- as_draws_df(b8h5) %>%\n  as_tibble() %>%\n  select(-sigma, -lp__) %>%\n  pivot_longer(-c(.chain, .iteration, .draw), names_to = c(NA, NA, \"type\", \"num\"), names_sep = \"_\",\n               values_to = \"value\", ) %>%\n  mutate(num = str_replace_all(num, \"ind\", \"\"),\n         num = as.integer(num))\ndraws %>%\n  filter(type == \"judge\") %>%\n  mutate(num = factor(num)) %>%\n  left_join(wine %>%\n              distinct(judge, judge_ind),\n            by = c(\"num\" = \"judge_ind\")) %>%\n  select(judge, value) %>%\n  group_by(judge) %>%\n  median_hdci(.width = c(0.67, 0.89, 0.97)) %>%\n  ggplot(aes(y = fct_rev(judge), x = value, xmin = .lower, xmax = .upper)) +\n  geom_interval() +\n  scale_color_manual(values = ramp_blue(seq(0.9, 0.1, length.out = 3)),\n                     limits = as.character(c(0.67, 0.89, 0.97))) +\n  labs(y = NULL, x = \"Parameter Value\", color = \"Interval\")\ndraws %>%\n  filter(type == \"wine\") %>%\n  mutate(num = factor(num)) %>%\n  left_join(wine %>%\n              distinct(wine, wine_ind),\n            by = c(\"num\" = \"wine_ind\")) %>%\n  select(wine, value) %>%\n  group_by(wine) %>%\n  median_hdci(.width = c(0.67, 0.89, 0.97)) %>%\n  ggplot(aes(y = fct_rev(wine), x = value, xmin = .lower, xmax = .upper)) +\n  geom_interval() +\n  scale_color_manual(values = ramp_blue(seq(0.9, 0.1, length.out = 3)),\n                     limits = as.character(c(0.67, 0.89, 0.97))) +\n  labs(y = NULL, x = \"Parameter Value\", color = \"Interval\")\nb8h6 <- brm(score_std ~ wine_amer + judge_amer + red,\n            data = wine, family = gaussian,\n            prior = c(prior(normal(0, 0.2), class = Intercept),\n                      prior(normal(0, 0.5), class = b),\n                      prior(exponential(1), class = sigma)),\n            iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n            file = here(\"fits\", \"chp8\", \"b8h6.rds\"))\n\nfixef(b8h6)\n#>             Estimate Est.Error    Q2.5 Q97.5\n#> Intercept   -0.01641     0.157 -0.3237 0.287\n#> wine_amer1  -0.17688     0.145 -0.4640 0.109\n#> judge_amer1  0.22773     0.143 -0.0534 0.503\n#> redred      -0.00686     0.145 -0.2873 0.277\nb8h7 <- brm(score_std ~ wine_amer + judge_amer + red +\n              wine_amer:judge_amer + wine_amer:red + judge_amer:red,\n            data = wine, family = gaussian,\n            prior = c(prior(normal(0, 0.2), class = Intercept),\n                      prior(normal(0, 0.5), class = b),\n                      prior(normal(0, 0.25), class = b,\n                            coef = judge_amer1:redred),\n                      prior(normal(0, 0.25), class = b,\n                            coef = wine_amer1:judge_amer1),\n                      prior(normal(0, 0.25), class = b,\n                            coef = wine_amer1:redred),\n                      prior(exponential(1), class = sigma)),\n            iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n            file = here(\"fits\", \"chp8\", \"b8h7.rds\"))\n\nfixef(b8h7)\n#>                        Estimate Est.Error   Q2.5 Q97.5\n#> Intercept               -0.0749     0.176 -0.420 0.274\n#> wine_amer1              -0.0553     0.193 -0.419 0.324\n#> judge_amer1              0.2258     0.194 -0.158 0.603\n#> redred                   0.1028     0.198 -0.280 0.494\n#> wine_amer1:judge_amer1  -0.0314     0.186 -0.396 0.325\n#> wine_amer1:redred       -0.2335     0.188 -0.596 0.136\n#> judge_amer1:redred       0.0410     0.188 -0.323 0.410\nwine %>% \n  distinct(wine_amer, judge_amer, red) %>% \n  mutate(combo = glue(\"{ifelse(judge_amer == 0, 'French', 'American')} judge, \",\n                      \"{ifelse(wine_amer == 0, 'French', 'American')} wine\")) %>% \n  add_epred_draws(b8h7) %>% \n  median_hdi(.width = c(0.67, 0.89, 0.97)) %>% \n  ggplot(aes(x = .epred, xmin = .lower, xmax = .upper, y = combo)) +\n  facet_wrap(~red, nrow = 1, labeller = as_labeller(str_to_title)) +\n  geom_interval() +\n  scale_color_manual(values = ramp_blue(seq(0.9, 0.1, length.out = 3)),\n                     breaks = c(\"0.67\", \"0.89\", \"0.97\")) +\n  labs(x = \"Value\", y = NULL, color = \"Interval\")"},{"path":"overfitting-mcmc.html","id":"chapter-9","chapter":"Week 4: Overfitting / MCMC","heading":"4.2.3 Chapter 9","text":"9E1. following requirement simple Metropolis algorithm?parameters must discrete.likelihood must Gaussian.proposal distribution must symmetric.(3) required.9E2. Gibbs sampling efficient Metropolis algorithm. achieve tis extra efficiency? limitations Gibbs sampling strategy?Gibbs sampling efficient makes smarter proposals. accomplished conjugate priors, make possible get analytical solutions posterior parameter model. However, also limiting, constrained prior distributions able select. Additionally, like Metropolis algorithm, Gibbs samplers can get stuck one area posterior parameters highly correlated parameters high-dimensional space.9E3. sort parameters can Hamiltonian Monte Carlo handle? Can explain ?Hamiltonian Monte Carlo handle discrete parameters. method uses physics simulation glide imaginary particle surface posterior. parameters discrete, breaks surface particle glide.9E4. Explain difference effective number samples, n_eff calculated Stan, actual number samples.actual number samples simply number draws make posterior distribution. draws may autocorrelated, effective number samples estimate number completely independent (.e., uncorrelated) draws contain amount information. autocorrelation increases, number effective samples decreases. Usually, n_eff smaller actual number samples. However, times Stan can make better independent draws, result n_eff great actual number samples.9E5. value Rhat approach, chain sampling posterior distribution correctly?Rhat approach 1 . , bad chains result Rhat greater 1.9E6. Sketch good trace plot Markov chain, one effectively sampling posterior distribution. good shape? sketch trace plot malfunctioning Markov chain. shape indicates malfunction?example good Markov chain. ’ve simulated 3 chains. stationary mixing well. Additionally, jumbled together, can’t see patterns different chains sampling different spaces.contrast plot shows bad chain. , one chains gotten stuck different area posterior. three chains fairly stationary, one chain clearly mixing others. rexamine model figure might causing behavior.9E7. Repeat problem , now trace rank plot.one harder, like look McElreath’s trace rank plots. Specifically, uses outline histogram , without lines separate individual bars. wrote function called make_trank() automate work. takes data frame one column per parameter additional column named Chain. returns data frame suitable making trace rank plots {ggplot2} geom_line().Let’s look good trace rank plot. see good mixing, fairly consistent number samples bin chain.Now bad chain. know trace plot one chain sampling values higher two chains. reflected trace rank plot. can see values highest ranks nearly come one chain, chain none low ranks. chains clearly mixed, show consistent number samples across bins.9M1. Re-estimate terrain reggedness model chapter, now using uniform prior standard deviation, sigma. uniform prior dunif(0,1). Use ulam estimate posterior. different prior detectible influence posterior distribution sigma? ?’ll fit two models, first model chapter uses exponential prior sigma. second model use uniform prior.Now let’s compare posterior distributions. nearly identical. enough data get good estimate sigma, regardless prior. However, sigma greater 1, uniform prior give estimate, prior gives 0 probability values outside [0, 1] interval.9M2. Modify terrain ruggedness model . time, change prior b[cid] dexp(0.3). posterior distribution? Can explain ?First ’ll fit model new priors.Now let’s compare posterior distributions beta parameters. first, \\(\\beta_{African}\\), posteriors nearly identical. However, posterior \\(\\beta_{African}\\) quite different. parameter wants negative, original model. new prior constrains parameter positive, see posterior density piled right next 0.9M3. Re-estimate one Stan models chapter, different numbers warmup iterations. sure use number sampling interations case. Compare n_eff values. much warmup enough?simplicity, ’ll use terrain-ruggedness example previous two problems. ’ll investigate 7 different warm-lengths, number post-warmup samples fixed 1,000.{brms}, rather one measure effective sample size (ESS), get two measures, described Vehtari et al. (2021). Bulk ESS describes mean distribution (.e., bulk), Tail ESS describes variance (.e., tails distribution). can see particular model, Bulk ESS Tail ESS level fairly quickly, meaning much warmup needed particular case.9H1. Run model inspect posterior distribution explain accomplishing.Compare samples parameters b. Can explain different trace plots? unfamiliar Cauchy distribution, look . key feature attend expected value. Can connect fact trace plot?model just sampling prior distributions. Let reproduce using {brms}. get prior samples, set sample_prior = \"\". , combination non-linear syntax ’ve seen , lets us duplicate model question.Looking trace plots, see sampling expect, given prior, bouncing around -3 3. b parameter looks little odd. However, normal Cauchy distribution. distribution undefined mean variance, heavy tails. , occasionally jump extreme values.9H2. Recall divorce rate example Chapter 5. Repeat analysis, using ulam time, fitting models m5.1, m5.2, m5.3. Use compare compare models basis WAIC PSIS. use WAIC PSIS ulam, need add argument log_lik=TRUE. Explain model comparison results.First, code reproduce three models. Model bm51 uses median age marriage predict divorce rate, bm52 uses marriage rate, bm53 uses predictors.Now let’s compare. WAIC PSIS-LOO, first model age marriage preferred. However, score bm53 nearly . indicates two models really differentiated well.9H3. Sometimes changing prior one parameter unanticipated effects parameters. parameter highly correlated another parameter posterior, prior influences parameters. ’s example work think .Go back leg length example Chapter 6 use code simulate height leg lengths 100 imagined individuals. model fit , resulting highly correlated posterior two beta parameters. time, fit model using ulam:Compare posterior distribution produced code posterior distribution produced change prior br strictly positive:Note constraints list. constrain prior distribution br positive probability zero. words, prior ensures posterior distribution br probability mass zero. Compare two posterior distributions m5.8s m5.8s2. changed posterior distribution beta parameters? Can explain change induced change prior?Let’s start simulating data used models. reminder, strong correlation lengths two legs.Now let’s fit two models.examine posteriors, ’ll first look correlations parameters. models, strong negative correlation \\(\\beta_L\\) \\(\\beta_R\\). makes sense given data. data strongly correlated, provide basically information. take information left leg (.e., higher values \\(\\beta_L\\)), necessarily must let less right leg. results negative correlation.However, looking actual distributions reveals impact constraining one parameter positive. unconstrained model, distributions similar. constrained model, \\(\\beta_R\\) takes positive values, distributions mirror images . order preserve negative correlation posterior, change prior one parameter cascaded parameter.9H4. two models fit previous problem, use WAIC PSIS compare effective numbers parameters model. need use log_lik=TRUE instruct ulam compute terms WAIC PSIS need. model effective parameters? ?number effective parameters give p_waic p_loo columns, respectively. unconstrained model (bm58s) large number effective parameters, 3.2 compared 2.6. makes sense given priors. second model informative prior, parameters able move around freely posterior smaller variance.9H5. Modify Metropolis algorithm code chapter handle case island populations different distribution island labels. means island’s number population.original example, population island 1 10 order. problem, ’ll pick random population order.Now can repeat simulation chapter. function takes current island position, island, popualtion island, returns next island. guts function loop chapter.can use accumulate() run function 100,000 times, passing previous position island time. summary can see proportion total visits island received (visit_prop) proportion total population lives island (pop_prop). can see two columns nearly identical, fact visiting island proportion populations islands.9H6. Modify Metropolis algorithm code chapter write simple MCMC estimator globe tossing data model Chapter 2.Like previous problem, ’ll start writing function simulation. follows structure previous problem, rather moving based ratio island populations, move based ratio likelihoods parameter estimate.fun, ’ll generate three chains can interesting plots look . Chapter 2 example, 6 waters 9 total trials, values passed n trials arguments function just created. Finally, start chain different value, hope converge posterior.Let’s look trace rank plot chains. see fairly stable distribution within chain, good mixing chains, exactly want see!last step actually look estimate proportion water. ’s expected value 0.63, 95% interval 0.33 0.88.9H7. Can write Hamiltonian Monte Carlo algorithm globe tossing data, using R code chapter? write functions likelihood gradient, can use HMC2 function.two functions need re-write ’re following example book. U_globe() log-probability data, U_globe_gradient() gradient. ’ll start U_globe(), similar created previous problem.gradient U function given \\[\n\\frac{\\partial U(y|n,p)}{\\partial p}\n\\]\nsolve (cheated used Mathematica), get answer gradient:\\[\n\\frac{\\partial \\log U(y|n,p)}{\\partial p} = \\frac{y - np}{p(1-p)}\n\\]function form, define U_globe_gradient() :Finally, plug functions wrapper function can pass accumulate(), run 3 chains., can look trace rank plot. still get good mixing consistency, indicating chains mixing well sampling area posterior.Looking posterior, ahve expected value 0.63, 95% interval 0.35 0.87. similar achieved Metropolis algorithm.","code":"\niters <- 1000\n\ngood_chain <- tibble(.iter = seq_len(iters),\n                     chain1 = rnorm(n = iters, mean = 0, sd = 1),\n                     chain2 = rnorm(n = iters, mean = 0, sd = 1),\n                     chain3 = rnorm(n = iters, mean = 0, sd = 1)) %>% \n  pivot_longer(-.iter, names_to = \"chain\", values_to = \"value\")\n\nggplot(good_chain, aes(x = .iter, y = value, color = chain)) +\n  geom_line(show.legend = FALSE) +\n  scale_color_okabeito() +\n  labs(x = \"Iteration\", y = \"Value\")\nbad_chain <- tibble(.iter = seq_len(iters),\n                    chain1 = rnorm(n = iters, mean = 0, sd = 1),\n                    chain2 = rnorm(n = iters, mean = 0, sd = 1),\n                    chain3 = rnorm(n = iters, mean = 3, sd = .5)) %>% \n  pivot_longer(-.iter, names_to = \"chain\", values_to = \"value\")\n\nggplot(bad_chain, aes(x = .iter, y = value, color = chain)) +\n  geom_line(show.legend = FALSE) +\n  scale_color_okabeito() +\n  labs(x = \"Iteration\", y = \"Value\")\nmake_trank <- function(dat, bins = 20) {\n  dat <- dat %>% \n    group_by(Chain) %>% \n    mutate(iteration = 1:n()) %>% \n    pivot_longer(-c(Chain, iteration),\n                 names_to = \"parameter\", values_to = \"value\") %>% \n    group_by(parameter) %>% \n    mutate(value_rank = row_number(value))\n  \n  bucket_counts <- dat %>% \n    mutate(value_bucket = cut_interval(value_rank, n = bins,\n                                       labels = FALSE)) %>%\n    ungroup() %>% \n    count(Chain, parameter, value_bucket)\n  \n  dat %>% \n    ungroup() %>% \n    select(Chain, iteration) %>% \n    mutate(iter_bucket = cut_interval(iteration, n = bins,\n                                      labels = FALSE)) %>% \n    left_join(bucket_counts, by = c(\"Chain\", \"iter_bucket\" = \"value_bucket\")) %>% \n    mutate(Chain = factor(Chain))\n}\ngood_chain %>% \n  mutate(Chain = str_replace_all(chain, \"chain\", \"\"),\n         Chain = as.integer(Chain)) %>% \n  select(Chain, value) %>% \n  make_trank(bins = 25) %>% \n  ggplot(aes(x = iteration, y = n, color = Chain)) +\n  geom_line(show.legend = FALSE, size = 1) +\n  scale_color_okabeito() +\n  scale_x_continuous(breaks = waiver(), n.breaks = 6,\n                     labels = ~.x * 3) +\n  labs(x = \"Rank\", y = \"Samples\")\nbad_chain %>% \n  mutate(Chain = str_replace_all(chain, \"chain\", \"\"),\n         Chain = as.integer(Chain)) %>% \n  select(Chain, value) %>% \n  make_trank(bins = 25) %>% \n  ggplot(aes(x = iteration, y = n, color = Chain)) +\n  geom_line(na.rm = TRUE, show.legend = FALSE, size = 1) +\n  scale_color_okabeito() +\n  scale_x_continuous(breaks = waiver(), n.breaks = 6,\n                     labels = ~.x * 3) +\n  labs(x = \"Rank\", y = \"Samples\")\ndata(rugged)\n\nrugged_dat <- rugged %>%\n  as_tibble() %>%\n  select(country, rgdppc_2000, rugged, cont_africa) %>%\n  drop_na(rgdppc_2000) %>%\n  mutate(log_gdp = log(rgdppc_2000),\n         log_gdp_std = log_gdp / mean(log_gdp),\n         rugged_std = rugged / max(rugged),\n         rugged_std_cent = rugged_std - mean(rugged_std),\n         cid = factor(cont_africa, levels = c(1, 0),\n                      labels = c(\"African\", \"Not African\")))\n\nb9m1_chp <- brm(\n  bf(log_gdp_std ~ 0 + a + b * rugged_std_cent,\n     a ~ 0 + cid,\n     b ~ 0 + cid,\n     nl = TRUE),\n  data = rugged_dat, family = gaussian,\n  prior = c(prior(normal(1, 0.1), class = b, coef = cidAfrican, nlpar = a),\n            prior(normal(1, 0.1), class = b, coef = cidNotAfrican, nlpar = a),\n            prior(normal(0, 0.3), class = b, coef = cidAfrican, nlpar = b),\n            prior(normal(0, 0.3), class = b, coef = cidNotAfrican, nlpar = b),\n            prior(exponential(1), class = sigma)),\n  iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n  file = here(\"fits\", \"chp9\", \"b9m1-chp.rds\")\n)\n\nb9m1_uni <- brm(\n  bf(log_gdp_std ~ 0 + a + b * rugged_std_cent,\n     a ~ 0 + cid,\n     b ~ 0 + cid,\n     nl = TRUE),\n  data = rugged_dat, family = gaussian,\n  prior = c(prior(normal(1, 0.1), class = b, coef = cidAfrican, nlpar = a),\n            prior(normal(1, 0.1), class = b, coef = cidNotAfrican, nlpar = a),\n            prior(normal(0, 0.3), class = b, coef = cidAfrican, nlpar = b),\n            prior(normal(0, 0.3), class = b, coef = cidNotAfrican, nlpar = b),\n            prior(uniform(0, 1), class = sigma)),\n  iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n  file = here(\"fits\", \"chp9\", \"b9m1-uni.rds\")\n)\nbind_rows(\n  as_draws_df(b9m1_chp, variable = \"sigma\") %>% \n    as_tibble() %>% \n    mutate(prior = \"Exponential(1)\"),\n  as_draws_df(b9m1_uni, variable = \"sigma\") %>% \n    as_tibble() %>% \n    mutate(prior = \"Uniform(0, 1)\")\n) %>% \n  ggplot(aes(x = sigma, color = prior)) +\n  geom_density(size = 1, key_glyph = \"timeseries\") +\n  scale_color_okabeito() +\n  labs(x = \"&sigma;\", y = \"Posterior Density\", color = \"Prior\")\nb9m2_exp <- brm(\n  bf(log_gdp_std ~ 0 + a + b * rugged_std_cent,\n     a ~ 0 + cid,\n     b ~ 0 + cid,\n     nl = TRUE),\n  data = rugged_dat, family = gaussian,\n  prior = c(prior(normal(1, 0.1), class = b, coef = cidAfrican, nlpar = a),\n            prior(normal(1, 0.1), class = b, coef = cidNotAfrican, nlpar = a),\n            prior(exponential(0.3), class = b, coef = cidAfrican, nlpar = b),\n            prior(exponential(0.3), class = b, coef = cidNotAfrican, nlpar = b),\n            prior(exponential(1), class = sigma)),\n  iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n  control = list(adapt_delta = 0.95, max_treedepth = 15),\n  file = here(\"fits\", \"chp9\", \"b9m2-exp.rds\")\n)\nbind_rows(\n  as_draws_df(b9m1_chp, variable = \"b_b_.*\", regex = TRUE) %>% \n    as_tibble() %>% \n    pivot_longer(starts_with(\"b_b_\"), names_to = \"parameter\",\n                 values_to = \"value\") %>% \n    mutate(prior = \"Normal(0, 0.3)\"),\n  as_draws_df(b9m2_exp, variable = \"b_b_.*\", regex = TRUE) %>% \n    as_tibble() %>% \n    pivot_longer(starts_with(\"b_b_\"), names_to = \"parameter\",\n                 values_to = \"value\") %>% \n    mutate(prior = \"Exponential(0.3)\")\n) %>% \n  mutate(parameter = factor(parameter,\n                            levels = c(\"b_b_cidAfrican\", \"b_b_cidNotAfrican\"),\n                            labels = c(\"&beta;<sub>African<\/sub>\",\n                                       \"&beta;<sub>Not African<\/sub>\"))) %>% \n  ggplot(aes(x = value, color = prior)) +\n  facet_wrap(~parameter, nrow = 1, scales = \"free_y\") + \n  geom_density(size = 1, key_glyph = \"timeseries\") +\n  scale_color_okabeito(breaks = c(\"Normal(0, 0.3)\", \"Exponential(0.3)\")) +\n  labs(x = \"&beta;\", y = \"Posterior Density\", color = \"Prior\")\nwarmup_length <- c(10, 25, 50, 100, 250, 500, 1000)\n\nb9m3_sim <- map_dfr(warmup_length,\n                    function(w) {\n                      mod <- brm(b9m1_chp$formula, data = b9m1_chp$data,\n                                 family = gaussian, prior = b9m1_chp$prior,\n                                 chains = 1, seed = 1234,\n                                 iter = w + 1000, warmup = w)\n                      \n                      mod_sum <- summary(mod)\n                      mod_sum$fixed %>% \n                        bind_rows(mod_sum$spec_pars) %>% \n                        rownames_to_column(var = \"parameter\") %>% \n                        mutate(warmup = w, .before = 1) %>% \n                        as_tibble() %>% \n                        select(warmup, parameter, Bulk_ESS, Tail_ESS)\n                    }) %>% \n  write_rds(here(\"fits\", \"chp9\", \"b9m3-sim.rds\"))\nb9m3_sim <- read_rds(here(\"fits\", \"chp9\", \"b9m3-sim.rds\"))\nb9m3_sim %>% \n  pivot_longer(ends_with(\"_ESS\"), names_to = \"type\", values_to = \"value\") %>% \n  mutate(param_label = parameter,\n         param_label = str_replace_all(param_label, \"a_cid(.*)$\", \"&alpha;<sub>\\\\1<\/sub>\"),\n         param_label = str_replace_all(param_label, \"b_cid(.*)$\", \"&beta;<sub>\\\\1<\/sub>\"),\n         param_label = str_replace_all(param_label, \"sigma\", \"<sub>&sigma;<\/sub>\"),\n         type = str_replace_all(type, \"_\", \" \")) %>% \n  ggplot(aes(x = warmup, y = value, color = type)) +\n  facet_wrap(~param_label, ncol = 3) +\n  geom_line(size = 1) +\n  scale_color_okabeito() +\n  scale_x_comma() +\n  labs(x = \"Warmup Iterations\", y = \"Effective Sample Size\",\n       color = NULL)\nmp <- ulam(\n  alist(\n    a ~ dnorm(0, 1),\n    b ~ dcaucy(0, 1)\n  ), data = list(y = 1), chains = 1)\nmp <- brm(bf(1 ~ a + b, a ~ 1, b ~ 1, nl = TRUE), data = 1,\n          prior = c(prior(normal(0, 1), class = b, nlpar = a),\n                    prior(cauchy(0, 1), class = b, nlpar = b)),\n          iter = 2000, chains = 1, sample_prior = \"only\",\n          file = here(\"fits\", \"chp9\", \"b9h1-prior\"))\nas_draws_df(mp, variable = \"^b_\", regex = TRUE) %>% \n  as_tibble() %>% \n  pivot_longer(starts_with(\"b_\"), names_to = \"param\") %>% \n  mutate(param = str_replace_all(param, \"b_([ab])_Intercept\", \"\\\\1\")) %>% \n  ggplot(aes(x = .draw, y = value)) +\n  facet_wrap(~param, nrow = 1, scales = \"free_y\") +\n  geom_line(color = \"#009FB7\")\ndata(\"WaffleDivorce\")\n\nwaffle_dat <- WaffleDivorce %>% \n  select(d = Divorce, m = Marriage, a = MedianAgeMarriage) %>% \n  mutate(across(everything(), standardize))\n\nbm51 <- brm(d ~ 1 + a, data = waffle_dat, family = gaussian,\n            prior = c(prior(normal(0, 0.2), class = Intercept),\n                      prior(normal(0, 0.5), class = b),\n                      prior(exponential(1), class = sigma)),\n            iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n            file = here(\"fits\", \"chp9\", \"b9h2-m51\"))\n\nbm52 <- brm(d ~ 1 + m, data = waffle_dat, family = gaussian,\n            prior = c(prior(normal(0, 0.2), class = Intercept),\n                      prior(normal(0, 0.5), class = b),\n                      prior(exponential(1), class = sigma)),\n            iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n            file = here(\"fits\", \"chp9\", \"b9h2-m52\"))\n\nbm53 <- brm(d ~ 1 + m + a, data = waffle_dat, family = gaussian,\n            prior = c(prior(normal(0, 0.2), class = Intercept),\n                      prior(normal(0, 0.5), class = b),\n                      prior(exponential(1), class = sigma)),\n            iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n            file = here(\"fits\", \"chp9\", \"b9h2-m53\"))\n\nbm51 <- add_criterion(bm51, criterion = c(\"waic\", \"loo\"))\nbm52 <- add_criterion(bm52, criterion = c(\"waic\", \"loo\"))\nbm53 <- add_criterion(bm53, criterion = c(\"waic\", \"loo\"))\nloo_compare(bm51, bm52, bm53, criterion = \"waic\")\n#>      elpd_diff se_diff\n#> bm51  0.0       0.0   \n#> bm53 -0.9       0.3   \n#> bm52 -6.7       4.6\n\nloo_compare(bm51, bm52, bm53, criterion = \"loo\")\n#>      elpd_diff se_diff\n#> bm51  0.0       0.0   \n#> bm53 -0.9       0.3   \n#> bm52 -6.6       4.7\nm5.8s <- ulam(\n  alist(\n    height ~ dnorm(mu, sigma),\n    mu <- a + bl * leg_left + br * leg_right ,\n    a ~ dnorm(10, 100),\n    bl ~ dnorm(2, 10),\n    br ~ dnorm(2, 10),\n    sigma ~ dexp(1)\n  ), data = d, chains = 4,\n  start = list(a =10 , bl = 0, br = 0.1, sigma = 1)\n)\nm5.8s2 <- ulam(\n  alist(\n    height ~ dnorm(mu, sigma),\n    mu <- a + bl * leg_left + br * leg_right ,\n    a ~ dnorm(10, 100),\n    bl ~ dnorm(2, 10),\n    br ~ dnorm(2, 10),\n    sigma ~ dexp(1)\n  ), data = d, chains = 4,\n  constraints = list(br = \"lower=0\"),\n  start = list(a =10 , bl = 0, br = 0.1, sigma = 1)\n)\nset.seed(909)\n\nn <- 100\n\nheight <- rnorm(n, 10, 2) \nleg_prop <- runif(n, 0.4, 0.5) \nleg_left <- leg_prop * height + rnorm(n, 0, 0.02)\nleg_right <- leg_prop * height + rnorm(n, 0, 0.02)\n\nleg_dat <- tibble(height, leg_left, leg_right)\n\ncor(leg_dat$leg_left, leg_dat$leg_right)\n#> [1] 1\nbm58s <- brm(height ~ 1 + leg_left + leg_right, data = leg_dat,\n             family = gaussian,\n             prior = c(prior(normal(10, 100), class = Intercept),\n                       prior(normal(2, 10), class = b, coef = leg_left),\n                       prior(normal(2, 10), class = b, coef = leg_right),\n                       prior(exponential(1), class = sigma)),\n             iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n             file = here(\"fits\", \"chp9\", \"b9h3-m58s\"))\n\nbm58s2 <- brm(bf(height ~ int + ll + lr,\n                 int ~ 1,\n                 ll ~ 0 + leg_left,\n                 lr ~ 0 + leg_right,\n                 nl = TRUE),\n              data = leg_dat, family = gaussian,\n              prior = c(prior(normal(10, 100), class = b, nlpar = int),\n                        prior(normal(2, 10), class = b, nlpar = ll),\n                        prior(normal(2, 10), class = b, lb = 0, nlpar = lr),\n                        prior(exponential(1), class = sigma)),\n              iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n              file = here(\"fits\", \"chp9\", \"b9h3-m58s2\"))\ndraws <- bind_rows(\n  as_draws_df(bm58s, variable = \"b_leg.*\", regex = TRUE) %>% \n    as_tibble() %>% \n    mutate(prior = \"Unconstrained\"),\n  as_draws_df(bm58s2, variable = \"b_l[lr]_leg.*\", regex = TRUE) %>% \n    as_tibble() %>% \n    rename(b_leg_left = b_ll_leg_left, b_leg_right = b_lr_leg_right) %>% \n    mutate(prior = \"Constrained\")\n) %>% \n  mutate(prior = fct_inorder(prior))\n\nggplot(draws, aes(x = b_leg_right, y = b_leg_left)) +\n  facet_wrap(~prior, nrow = 1, scales = \"free\") +\n  geom_point(alpha = 0.2) +\n  labs(x = \"&beta;<sub>R<\/sub>\", y = \"&beta;<sub>L<\/sub>\")\ndraws %>% \n  pivot_longer(starts_with(\"b_\"), names_to = \"param\") %>% \n  ggplot(aes(x = value)) +\n  facet_wrap(~prior, nrow = 1) +\n  geom_density(aes(color = param), size = 1, key_glyph = \"timeseries\") +\n  scale_color_okabeito(labels = c(\"&beta;<sub>L<\/sub>\", \"&beta;<sub>R<\/sub>\")) +\n  labs(x = \"&beta;\", y = \"Density\", color = \"Parameter\") +\n  theme(legend.text = element_markdown())\nbm58s <- add_criterion(bm58s, criterion = c(\"waic\", \"loo\"))\nbm58s2 <- add_criterion(bm58s2, criterion = c(\"waic\", \"loo\"))\n\nprint(loo_compare(bm58s, bm58s2, criterion = \"waic\"), simplify = FALSE)\n#>        elpd_diff se_diff elpd_waic se_elpd_waic p_waic se_p_waic waic  se_waic\n#> bm58s2   0.0       0.0   -96.9       5.6          2.6    0.4     193.9  11.2  \n#> bm58s   -0.6       0.2   -97.5       5.6          3.2    0.5     195.1  11.3\n\nprint(loo_compare(bm58s, bm58s2, criterion = \"loo\"), simplify = FALSE)\n#>        elpd_diff se_diff elpd_loo se_elpd_loo p_loo se_p_loo looic se_looic\n#> bm58s2   0.0       0.0   -96.9      5.6         2.6   0.4    193.9  11.2   \n#> bm58s   -0.6       0.2   -97.6      5.6         3.2   0.5    195.1  11.3\nset.seed(209)\n\npop_size <- sample(1:10, size = 10, replace = FALSE)\nnames(pop_size) <- paste(\"Island\", 1:10)\npop_size\n#>  Island 1  Island 2  Island 3  Island 4  Island 5  Island 6  Island 7  Island 8 \n#>         2         3        10         6         8         5         7         9 \n#>  Island 9 Island 10 \n#>         1         4\nisland_sim <- function(island, ..., island_pop) {\n  # flip coin to generate proposal\n  proposal <- island + (sample(c(-1L, 1L), size = 1))\n  \n  # loop when we reach the boundary\n  if (proposal < 1) proposal <- 10L\n  if (proposal > 10) proposal <- 1L\n  \n  # decide if we move\n  prob <- island_pop[proposal] / island_pop[island]\n  island <- ifelse(runif(1) < prob, proposal, island)\n  \n  return(island)\n}\nvisits <- accumulate(seq_len(1e6), island_sim, .init = 10L,\n                     island_pop = pop_size)\n\ntibble(island = visits) %>% \n  count(island) %>% \n  mutate(population = pop_size,\n         visit_prop = n / sum(n),\n         pop_prop = population / sum(population))\n#> # A tibble: 10 × 5\n#>    island      n population visit_prop pop_prop\n#>     <int>  <int>      <int>      <dbl>    <dbl>\n#>  1      1  35867          2     0.0359   0.0364\n#>  2      2  53920          3     0.0539   0.0545\n#>  3      3 181239         10     0.181    0.182 \n#>  4      4 109238          6     0.109    0.109 \n#>  5      5 146186          8     0.146    0.145 \n#>  6      6  91538          5     0.0915   0.0909\n#>  7      7 127965          7     0.128    0.127 \n#>  8      8 163814          9     0.164    0.164 \n#>  9      9  18102          1     0.0181   0.0182\n#> 10     10  72132          4     0.0721   0.0727\nglobe_sim <- function(prop, ..., n, trials) {\n  # proposal value: random number +/-0.1 from current value of `prop`\n  proposal <- prop + runif(1, -0.1, 0.1)\n  \n  # reflect back when proposal is outside the [0,1] bounds of `prop`\n  if (proposal < 0) proposal <- abs(proposal)\n  if (proposal > 1) proposal <- 1 - (proposal - 1)\n  \n  # probability of current and proposed values\n  # uses uniform prior, but could change `dunif` to some other prior\n  prob_current <- dbinom(x = n, size = trials, prob = prop) * dunif(prop, 0, 1)\n  prob_proposal <- dbinom(x = n, size = trials, prob = proposal) * dunif(proposal, 0, 1)\n  \n  # accept proposal?\n  prob_accept <- prob_proposal / prob_current\n  prop <- ifelse(runif(1) < prob_accept, proposal, prop)\n  \n  return(prop)\n}\nset.seed(209)\n\nchain1 <- accumulate(seq_len(1e4), globe_sim, .init = 0.2, n = 6, trials = 9)\nchain2 <- accumulate(seq_len(1e4), globe_sim, .init = 0.5, n = 6, trials = 9)\nchain3 <- accumulate(seq_len(1e4), globe_sim, .init = 0.8, n = 6, trials = 9)\nbind_rows(tibble(Chain = 1L, p = chain1),\n          tibble(Chain = 2L, p = chain2),\n          tibble(Chain = 3L, p = chain3)) %>% \n  make_trank(bins = 25) %>% \n  ggplot(aes(x = iteration, y = n, color = Chain)) +\n  geom_line(show.legend = FALSE, size = 1) +\n  scale_color_okabeito() +\n  scale_x_continuous(breaks = waiver(), n.breaks = 6,\n                     labels = ~prettyNum(.x * 3, big.mark = \",\")) +\n  labs(x = \"Rank\", y = \"Samples\")\nmean_qi(c(chain1, chain2, chain3), .width = 0.95)\n#>       y  ymin ymax .width .point .interval\n#> 1 0.633 0.335 0.88   0.95   mean        qi\nU_globe <- function(q) {\n  U <- dbinom(y, size = n, prob = q, log = TRUE) +\n    dunif(q, 0, 1, log = TRUE)\n  return(-U)\n}\nU_globe_gradient <- function(q) {\n  G <- (y - n * q) / (q * (1 - q))\n  return(-G)\n}\nglobe_hmc <- function(Q, ..., y = 6, n = 9, step = 0.03, L = 10) {\n  Q <- HMC2(U_globe, U_globe_gradient, step, L, Q$q)\n}\n\nset.seed(209)\n\ny <- 6\nn <- 9\n\nchain1 <- accumulate(seq_len(1000), globe_hmc, .init = list(q = 0.2)) %>% \n  keep(~\"accept\" %in% names(.x)) %>% \n  map_dbl(~ifelse(.x$accept == 1, .x$q, NA_real_))\nchain2 <- accumulate(seq_len(1000), globe_hmc, .init = list(q = 0.5)) %>% \n  keep(~\"accept\" %in% names(.x)) %>% \n  map_dbl(~ifelse(.x$accept == 1, .x$q, NA_real_))\nchain3 <- accumulate(seq_len(1000), globe_hmc, .init = list(q = 0.8)) %>% \n  keep(~\"accept\" %in% names(.x)) %>% \n  map_dbl(~ifelse(.x$accept == 1, .x$q, NA_real_))\nbind_rows(tibble(Chain = 1L, p = chain1),\n          tibble(Chain = 2L, p = chain2),\n          tibble(Chain = 3L, p = chain3)) %>% \n  make_trank(bins = 25) %>% \n  ggplot(aes(x = iteration, y = n, color = Chain)) +\n  geom_line(show.legend = FALSE, size = 1) +\n  scale_color_okabeito() +\n  scale_x_continuous(breaks = waiver(), n.breaks = 6,\n                     labels = ~prettyNum(.x * 3, big.mark = \",\")) +\n  labs(x = \"Rank\", y = \"Samples\")\nmean_qi(c(chain1, chain2, chain3), .width = 0.95, na.rm = TRUE)\n#>       y  ymin  ymax .width .point .interval\n#> 1 0.634 0.349 0.874   0.95   mean        qi"},{"path":"overfitting-mcmc.html","id":"homework-3","chapter":"Week 4: Overfitting / MCMC","heading":"4.3 Homework","text":"1. Revisit marriage, age, happiness collider bias example Chapter 6. Run models m6.9 m6.10 (pages 178–179). Compare two models using PSIS WAIC. model expected make better predictions, according criteria? basis causal model, interpret parameter estimates model preferred PSIS WAIC?reminder, DAG example, \\(H\\) happiness, \\(M\\) marriage, \\(\\) age.First, let’s regenerate data estimate models.Now ’ll compare PSIS WAIC. results PSIS WAIC identical, showing strong preference b6.9 includes marriage predictor. Thus, interested predicting happiness, use model b6.9. However, due causal model, coefficients can’t interpreted. coefficient age confounded collider. Similarly, coefficient marriage odd, DAG, marriage cause happiness, cause happiness. Thus, parameters represents conditional associations. None causal effects.2. Reconsider urban fox analysis last week’s homework. basis PSIS WAIC scores, combination variables best predicts body weight (\\(W\\), weight)? interpret estimates best scoring model?reminder, DAG fox data.Last week estimated many models fox data. five models predict weight various combinations predictors., WAIC PSIS scores similar. methods prefer model 1, includes three predictors model. However, differences often smaller standard error difference, preference overly strong.can interpret coefficients fox_1 using DAG. First avgfood. Since, groupsize model, indirect path food weight closed. Therefore, coefficient avgfood represents direct effect food weight. Second, groupsize, avgfood backdoor fork. closing path, group size coefficient represents total (also direct since one path remaining) causal effect group size weight.Finally, area little weird. avgfood pipe, mediating relationship area weight, including avgfood block association area weight. indeed see model 4, includes area avgfood. good deal posterior probability sides 0, indicating effect area plausibly negative positive.However, groupsize added first model, see association area weight increases, even though avgfood still blocking path. Therefore, indicates something else may going data, DAG might incorrect.3. Build predictive model relationship shown cover book, relationship timing cherry blossoms March temperature year. data found data(cherry_blossoms). Consider least two functions predict doy temp. Compare PSIS WAIC.Suppose March temperatures reach 9 degrees year 2050. best model predict predictive distribution day--year cherry trees blossom?exercise, ’ll fit 2 spline models linear model. spline models ’ll use 30 knots, one model loose priors tighter priors.comparing models, PSIS WAIC prefer linear. Although two spline models perform almost identically, standard errors differences models linear model one fifth difference.Using linear model, can predict date first bloom March temperature 9. see expected value around day 96, 89% compatibility interval 87 106. Since 2050 leap year, corresponds first bloom March 28 April 16.4 - OPTIONAL CHALLENGE. data data(Dinosaurs) body mass estimates different estimated ages six different dinosaur species. See ?Dinosaurs details. Choose one species (least one, many like) model growth. precise: Make predictive model body mass using age predictor. Consider two model types function relating age body mass score using PSIS WAIC.model think best, predictive grounds? scientific grounds? answers questions differ, ?challenging exercise, data scarce. also realistic example, people publish Nature papers even less data. best, look forward seeing growth curves.familiar biological growth models, question stumped . ’ll pulling McElreath’s solution, translating everything {tidyverse} {brms}.start loading data normalizing mass proportion maximum mass within species. also create sub-sample just one dinosaur easily illustrate various models ’ll explore.First straight linear regression. model looks just like regressions ’ve fit {brms} far.Visualizing model, see actually pretty good job fitting data points one dinosaur, leads impossible predictions. example, ages 0 4 predicted negative mass. Additionally, scientific perspective, linear growth doesn’t make biological sense.next model classic biological model called von Bertalanffy growth model (1934). models, organisms grow certain rate given differential equation (notation shifts bit McElreath’s solution make model fitting {brms} easier):\\[\n\\frac{dM}{dA} = k(\\phi - M)\n\\]\\(M\\) mass, \\(\\) age, \\(k\\) rate, \\(\\phi\\) maximum adult size. Solving equation gives us:\\[\nM() = \\phi(1 - \\exp(-kA))\n\\]can define equation {brms} using non-linear syntax, described Solomon Kurz.looks worse original line, except fact longer get implausible predictions. ’s win. problem want growth slow first accelerate around age 5. von Bertalanffy growth model, accomplished raising growth function power, \\(\\theta\\):\\[\nM() = \\phi(1 - \\exp(-kA))^\\theta\n\\]can fit model using non-linear {brms} syntax.looks pretty good! Comparing models PSIS, see accelerated growth model preferred, even taking standard errors consideration.Now let’s fit model dinosaurs data set. difference know index phi, k, theta species get curve.’s lot uncertainty curve, isn’t unexpected given data points . ’s little easier digest split species ’s plot. Overall, looks like models pretty good job estimating dinosaur growth!","code":"\nd <- sim_happiness(seed = 1977, N_years = 1000)\ndat <- d %>%\n  filter(age > 17) %>%\n  mutate(a = (age - 18) / (65 - 18),\n         mid = factor(married + 1, labels = c(\"single\", \"married\")))\n\nb6.9 <- brm(happiness ~ 0 + mid + a, data = dat, family = gaussian,\n            prior = c(prior(normal(0, 1), class = b, coef = midmarried),\n                      prior(normal(0, 1), class = b, coef = midsingle),\n                      prior(normal(0, 2), class = b, coef = a),\n                      prior(exponential(1), class = sigma)),\n            iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n            file = here(\"fits\", \"hw4\", \"w4h1-6.9\"))\n\nb6.10 <- brm(happiness ~ 1 + a, data = dat, family = gaussian,\n             prior = c(prior(normal(0, 1), class = Intercept),\n                       prior(normal(0, 2), class = b, coef = a),\n                       prior(exponential(1), class = sigma)),\n             iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n             file = here(\"fits\", \"hw4\", \"w4h1-6.10\"))\nb6.9 <- add_criterion(b6.9, criterion = c(\"waic\", \"loo\"))\nb6.10 <- add_criterion(b6.10, criterion = c(\"waic\", \"loo\"))\n\nloo_compare(b6.9, b6.10, criterion = \"waic\")\n#>       elpd_diff se_diff\n#> b6.9     0.0       0.0 \n#> b6.10 -194.0      17.6\nloo_compare(b6.9, b6.10, criterion = \"loo\")\n#>       elpd_diff se_diff\n#> b6.9     0.0       0.0 \n#> b6.10 -194.0      17.6\ndata(foxes)\n\nfox_dat <- foxes %>%\n  as_tibble() %>%\n  select(area, avgfood, weight, groupsize) %>%\n  mutate(across(everything(), standardize))\n\nfox_1 <- brm(weight ~ 1 + avgfood + groupsize + area, data = fox_dat,\n             family = gaussian,\n             prior = c(prior(normal(0, 0.2), class = Intercept),\n                       prior(normal(0, 0.5), class = b,),\n                       prior(exponential(1), class = sigma)),\n             iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n             file = here(\"fits\", \"hw4\", \"w4h2-1\"))\n\nfox_2 <- brm(weight ~ 1 + avgfood + groupsize, data = fox_dat,\n             family = gaussian,\n             prior = c(prior(normal(0, 0.2), class = Intercept),\n                       prior(normal(0, 0.5), class = b,),\n                       prior(exponential(1), class = sigma)),\n             iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n             file = here(\"fits\", \"hw4\", \"w4h2-2\"))\n\nfox_3 <- brm(weight ~ 1 + groupsize + area, data = fox_dat,\n             family = gaussian,\n             prior = c(prior(normal(0, 0.2), class = Intercept),\n                       prior(normal(0, 0.5), class = b,),\n                       prior(exponential(1), class = sigma)),\n             iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n             file = here(\"fits\", \"hw4\", \"w4h2-3\"))\n\nfox_4 <- brm(weight ~ 1 + avgfood + area, data = fox_dat,\n             family = gaussian,\n             prior = c(prior(normal(0, 0.2), class = Intercept),\n                       prior(normal(0, 0.5), class = b,),\n                       prior(exponential(1), class = sigma)),\n             iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n             file = here(\"fits\", \"hw4\", \"w4h2-4\"))\n\nfox_5 <- brm(weight ~ 1 + area, data = fox_dat,\n             family = gaussian,\n             prior = c(prior(normal(0, 0.2), class = Intercept),\n                       prior(normal(0, 0.5), class = b,),\n                       prior(exponential(1), class = sigma)),\n             iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n             file = here(\"fits\", \"hw4\", \"w4h2-5\"))\n\nfox_1 <- add_criterion(fox_1, criterion = c(\"waic\", \"loo\"))\nfox_2 <- add_criterion(fox_2, criterion = c(\"waic\", \"loo\"))\nfox_3 <- add_criterion(fox_3, criterion = c(\"waic\", \"loo\"))\nfox_4 <- add_criterion(fox_4, criterion = c(\"waic\", \"loo\"))\nfox_5 <- add_criterion(fox_5, criterion = c(\"waic\", \"loo\"))\nloo_compare(fox_1, fox_2, fox_3, fox_4, fox_5, criterion = \"waic\")\n#>       elpd_diff se_diff\n#> fox_1  0.0       0.0   \n#> fox_3 -0.4       1.4   \n#> fox_2 -0.4       1.7   \n#> fox_5 -5.3       3.4   \n#> fox_4 -5.7       3.3\n\nloo_compare(fox_1, fox_2, fox_3, fox_4, fox_5, criterion = \"loo\")\n#>       elpd_diff se_diff\n#> fox_1  0.0       0.0   \n#> fox_3 -0.4       1.4   \n#> fox_2 -0.4       1.7   \n#> fox_5 -5.3       3.4   \n#> fox_4 -5.7       3.3\nfixef(fox_4)\n#>            Estimate Est.Error   Q2.5 Q97.5\n#> Intercept -0.000187    0.0845 -0.165 0.166\n#> avgfood   -0.148423    0.1740 -0.486 0.191\n#> area       0.144857    0.1748 -0.199 0.483\nfixef(fox_1)\n#>            Estimate Est.Error    Q2.5  Q97.5\n#> Intercept -0.000224    0.0818 -0.1600  0.165\n#> avgfood    0.294284    0.2156 -0.1308  0.718\n#> groupsize -0.632656    0.1860 -0.9978 -0.268\n#> area       0.275539    0.1746 -0.0716  0.622\nlibrary(splines)\n\ndata(cherry_blossoms)\ncb_dat <- cherry_blossoms %>%\n  select(doy, temp) %>% \n  drop_na(everything()) \n\nlinear <- brm(doy ~ 1 + temp, data = cb_dat, family = gaussian,\n              prior = c(prior(normal(100, 10), class = Intercept),\n                        prior(normal(0, 10), class = b),\n                        prior(exponential(1), class = sigma)),\n              iter = 2000, warmup = 1000, chains = 4, cores = 4, seed = 1234,\n              file = here(\"fits\", \"hw4\", \"w4h3-1\"))\n\nspline_1 <- brm(doy ~ 1 + s(temp, bs = \"bs\", k = 30), data = cb_dat,\n                family = gaussian,\n                prior = c(prior(normal(100, 10), class = Intercept),\n                          prior(normal(0, 10), class = b),\n                          prior(student_t(3, 0, 5.9), class = sds),\n                          prior(exponential(1), class = sigma)),\n                iter = 2000, warmup = 1000, chains = 4, cores = 4, seed = 1234,\n                file = here(\"fits\", \"hw4\", \"w4h3-2\"))\n\nspline_2 <- brm(doy ~ 1 + s(temp, bs = \"bs\", k = 30), data = cb_dat,\n                family = gaussian,\n                prior = c(prior(normal(100, 10), class = Intercept),\n                          prior(normal(0, 2), class = b),\n                          prior(student_t(3, 0, 5.9), class = sds),\n                          prior(exponential(1), class = sigma)),\n                iter = 2000, warmup = 1000, chains = 4, cores = 4, seed = 1234,\n                file = here(\"fits\", \"hw4\", \"w4h3-3\"))\n\n\nlinear <- add_criterion(linear, criterion = c(\"waic\", \"loo\"))\nspline_1 <- add_criterion(spline_1, criterion = c(\"waic\", \"loo\"))\nspline_2 <- add_criterion(spline_2, criterion = c(\"waic\", \"loo\"))\nloo_compare(linear, spline_1, spline_2, criterion = \"waic\")\n#>          elpd_diff se_diff\n#> linear    0.0       0.0   \n#> spline_2 -0.9       0.2   \n#> spline_1 -1.0       0.2\n\nloo_compare(linear, spline_1, spline_2, criterion = \"loo\")\n#>          elpd_diff se_diff\n#> linear    0.0       0.0   \n#> spline_2 -1.0       0.2   \n#> spline_1 -1.0       0.2\nnew_dat <- tibble(temp = 9)\n\npreds <- new_dat %>% \n  add_predicted_draws(linear)\n\nmean_hdi(preds$.prediction, .width = c(0.89))\n#>      y ymin ymax .width .point .interval\n#> 1 96.2 86.2  105   0.89   mean       hdi\n\nggplot(preds, aes(x = .prediction)) +\n  stat_halfeye(.width = c(0.67, 0.89, 0.97)) +\n  labs(x = \"Day of Year\", y = \"Posterior Predictive Density\")\ndata(Dinosaurs)\n\ndino_dat <- Dinosaurs %>% \n  as_tibble() %>% \n  select(species_name = species, species = sp_id, age, mass) %>% \n  group_by(species) %>% \n  mutate(prop_mass = mass / max(mass),\n         species = factor(species)) %>% \n  ungroup()\n\none_dino <- filter(dino_dat, species == 1)\none_dino_linear <- brm(prop_mass ~ 1 + age, data = one_dino, family = gaussian,\n                       prior = c(prior(normal(0, 1), class = Intercept),\n                                 prior(normal(0, 1), class = b),\n                                 prior(exponential(1), class = sigma)),\n                       iter = 2000, warmup = 1000, chains = 4, cores = 4, seed = 1234,\n                file = here(\"fits\", \"hw4\", \"w4h4-one-linear\"))\nnew_dat <- tibble(age = seq(0, 16, length.out = 50))\n\nnew_dat %>% \n  add_epred_draws(one_dino_linear) %>% \n  ggplot(aes(x = age, y = .epred)) +\n  stat_lineribbon(.width = 0.89, fill = \"#009FB7\", alpha = 0.4,\n                  color = NA) +\n  stat_lineribbon(fill = \"transparent\") +\n  geom_point(data = one_dino, aes(y = prop_mass), size = 2) +\n  scale_x_continuous(breaks = seq(0, 15, by = 5)) +\n  coord_cartesian(ylim = c(0, 1.05), expand = FALSE) +\n  labs(x = \"Age\", y = \"Mass (normalized)\")\none_dino_bio <- brm(bf(prop_mass ~ phi * (1 - exp(-k * age)),\n                       phi + k ~ 1,\n                       nl = TRUE), data = one_dino, family = gaussian,\n                    prior = c(prior(normal(1, 0.5), nlpar = phi),\n                              prior(exponential(1), nlpar = k, lb = 0),\n                              prior(exponential(1), class = sigma)),\n                    iter = 4000, warmup = 3000, chains = 4, cores = 4, seed = 1234,\n                    control = list(adapt_delta = 0.95),\n                    file = here(\"fits\", \"hw4\", \"w4h4-one-bio\"))\n\nnew_dat %>% \n  add_epred_draws(one_dino_bio) %>% \n  ggplot(aes(x = age, y = .epred)) +\n  stat_lineribbon(.width = 0.89, fill = \"#009FB7\", alpha = 0.4,\n                  color = NA) +\n  stat_lineribbon(fill = \"transparent\") +\n  geom_point(data = one_dino, aes(y = prop_mass), size = 2) +\n  scale_x_continuous(breaks = seq(0, 15, by = 5)) +\n  coord_cartesian(ylim = c(0, 1.05), expand = FALSE) +\n  labs(x = \"Age\", y = \"Mass (normalized)\")\none_dino_acc <- brm(bf(prop_mass ~ phi * (1 - exp(-k * age)) ^ theta,\n                       phi + k + theta ~ 1,\n                       nl = TRUE), data = one_dino, family = gaussian,\n                    prior = c(prior(normal(1, 0.5), nlpar = phi),\n                              prior(exponential(1), nlpar = k, lb = 0),\n                              prior(exponential(0.1), nlpar = theta, lb = 0),\n                              prior(exponential(1), class = sigma)),\n                    iter = 20000, warmup = 19000, chains = 4, cores = 4, seed = 1234,\n                    control = list(adapt_delta = 0.999, max_treedepth = 15),\n                    file = here(\"fits\", \"hw4\", \"w4h4-one-acc\"))\n\nnew_dat %>% \n  add_epred_draws(one_dino_acc) %>% \n  ggplot(aes(x = age, y = .epred)) +\n  stat_lineribbon(.width = 0.89, fill = \"#009FB7\", alpha = 0.4,\n                  color = NA) +\n  stat_lineribbon(fill = \"transparent\") +\n  geom_point(data = one_dino, aes(y = prop_mass), size = 2) +\n  scale_x_continuous(breaks = seq(0, 15, by = 5)) +\n  coord_cartesian(ylim = c(0, 1.05), expand = FALSE) +\n  labs(x = \"Age\", y = \"Mass (normalized)\")\none_dino_linear <- add_criterion(one_dino_linear, criterion = \"loo\")\none_dino_bio <- add_criterion(one_dino_bio, criterion = \"loo\")\none_dino_acc <- add_criterion(one_dino_acc, criterion = \"loo\")\n\nloo_compare(one_dino_linear, one_dino_bio, one_dino_acc,\n            criterion = \"loo\")\n#>                 elpd_diff se_diff\n#> one_dino_acc     0.0       0.0   \n#> one_dino_linear -2.8       0.5   \n#> one_dino_bio    -4.4       0.8\nall_dinos <- brm(bf(prop_mass ~ phi * (1 - exp(-k * age)) ^ theta,\n                    phi ~ 0 + species,\n                    k ~ 0 + species,\n                    theta ~ 0 + species,\n                    nl = TRUE), data = dino_dat, family = gaussian,\n                 prior = c(prior(normal(1, 0.5), nlpar = phi),\n                           prior(exponential(1), nlpar = k, lb = 0),\n                           prior(exponential(0.1), nlpar = theta, lb = 0),\n                           prior(exponential(1), class = sigma)),\n                 iter = 10000, warmup = 9000, chains = 4, cores = 4, seed = 1234,\n                 control = list(adapt_delta = 0.95),\n                 file = here(\"fits\", \"hw4\", \"w4h4-all\"))\n\np <- distinct(dino_dat, species_name, species) %>% \n  expand_grid(age = seq(0, 16, length.out = 50)) %>% \n  add_epred_draws(all_dinos) %>% \n  ggplot(aes(x = age, y = .epred, fill = species_name, color = species_name)) +\n  stat_lineribbon(.width = 0.89, alpha = 0.6, color = NA) +\n  stat_lineribbon(fill = \"transparent\") +\n  geom_point(data = dino_dat, aes(y = prop_mass), size = 2) +\n  scale_fill_viridis_d(option = \"turbo\") +\n  scale_color_viridis_d(option = \"turbo\") +\n  scale_x_continuous(breaks = seq(0, 15, by = 5)) +\n  coord_cartesian(ylim = c(0, 2.05), expand = FALSE) +\n  labs(x = \"Age\", y = \"Mass (normalized)\", fill = \"Species\",\n       color = \"Species\")\n\np\np +\n  facet_wrap(~species_name, ncol = 3) +\n  guides(fill = \"none\", color = \"none\")"},{"path":"generalized-linear-models.html","id":"generalized-linear-models","chapter":"Week 5: Generalized Linear Models","heading":"Week 5: Generalized Linear Models","text":"fifth week covers Chapter 10 (Big Entropy Generalized Linear Model), Chapter 11 (God Spiked Integers).","code":""},{"path":"generalized-linear-models.html","id":"lectures-4","chapter":"Week 5: Generalized Linear Models","heading":"5.1 Lectures","text":"Lecture 9:Lecture 10:","code":""},{"path":"generalized-linear-models.html","id":"exercises-4","chapter":"Week 5: Generalized Linear Models","heading":"5.2 Exercises","text":"","code":""},{"path":"generalized-linear-models.html","id":"chapter-10","chapter":"Week 5: Generalized Linear Models","heading":"5.2.1 Chapter 10","text":"Chapter 10 conceptual chapter, exercises complete.","code":""},{"path":"generalized-linear-models.html","id":"chapter-11","chapter":"Week 5: Generalized Linear Models","heading":"5.2.2 Chapter 11","text":"11E1. event probability 0.35, log-odds event?log-odds given logit link:\\[\n\\log\\frac{p}{1-p}\n\\]code:11E2. event log-odds 3.2, probability event?convert log-odds probability, use inverse logit, given :\\[\n\\frac{\\exp(\\alpha)}{\\exp(\\alpha) + 1}\n\\]\ncode:11E3. Suppose coefficient logistic regression value 1.7. imply proportional change odds outcome?can calculate proportional odds exponentiating coefficient.proportional odds 5.5 means unit increase predictor multiplies odds outcome occurring 5.5.11E4. Poisson regressions sometimes require use offset? Provide example.offset duration count accumulated . observations accumulated observation periods, offset needed. However, differences (e.g., counts weekly others daily), offset needed.example, say modeling many houses Realtor sells. Realtors provide data weekly counts houses sold, provide monthly data, need offset account fact expect larger counts longer periods time.11M1. explained chapter, binomial data can organized aggregated disaggregated forms, without impact inference. likelihood data change data converted two formats. Can explain ?likelihood aggregated binomial includes multiplicative term account different ways get observed number counts. example, say saw 2 success 5 trials. aggregated form, likelihood hood :\\[\n\\frac{5!}{2!(5-2)!}p^2(1-p)^{5-2}\n\\]\nfraction front multiplicative term, accounting ways see 2 successes five trials. long disaggregated format, likelihood :\\[\np^2(1-p)^{5-2}\n\\]know exactly got 2 5 series 1s 0s. multiplicative factor likelihoods different. However, multiplicative factor function \\(p\\), posterior distributions, therefore inferences, unaffected.11M2. coefficient Poisson regression value 1.7, imply change outcome?straightforward answer. Poisson models typically use log link. Therefore, change outcome resulting 1.7 unit change predictor depends values parameters, scale predictor. best can calculate proportional change odds. , question 11E3., 1.7 unit change predictor results 5.5 times increase odds.11M3. Explain logit link appropriate binomial generalized linear model.binomial models, need map continuous values linear model probability space constrained 0 1. logit link possible way . link function can accomplish thing (e.g., probit link), function map continuous values [0,1] bounded space trick.11M4. Explain log link appropriate Poisson generalized linear model.Similar previous question, now need function maps continuous linear model strictly positive space. log link accomplishes . inverse log link exponential, value exponentiated positive.11M5. imply use logit link mean Poisson generalized linear model? Can think real research problem make sense?logit link imply model known maximum count. Normally, value 1, arbitrary number , \\(M\\) maximum count:\\[\n\\begin{align}\n  y_i &\\sim \\text{Poisson}(\\mu_i) \\\\\n  \\log\\frac{\\mu_i}{M - \\mu_i} &= \\alpha + \\beta x_i\n\\end{align}\n\\]\nUsually, known maximum, makes sense use binomial model. However, \\(M\\) large may never reach , probability low, type logit-Poisson used.11M6. State constraints binomial Poisson distributions maximum entropy. constraints different binomial Poisson? ?constraints binomial Poisson Poisson binomial model number trials large probability observing event low. constraints :Discrete binary outcomesConstant probability event across trials11M7. Use quap construct quadratic approximate posterior distribution chimpanzee model includes unique intercept action, m11.4 (page 330). Compare quadratic approximation posterior distribution produced instead MCMC. Can explain differences similarities approximate MCMC distributions? Relax prior actor intercepts Normal(0,10). Re-estimate posterior using ulam quap. difference increase decrease? ?’ll start estimating m11.4 quap() brm().Looking posterior distributions, quadratic approximation MCMC similar. parameter shows noticeable difference Actor 2. Looking little closer, see Actor 2, MCMC results posterior shifted slightly right. MCMC posterior slightly skewed, whereas QUAP posterior forced Gaussian. Therefore, density given lower tail less upper tail MCMC posterior.Now let’s modify prior distributions. loosening prior, ’re letting actor intercepts take even extreme values. effect letting posterior become even skewed.Let’s look Actor 2 . see MCMC posterior much skew now. However QUAP posterior still constrained Gaussian. case, QUAP pretty bad approximation true shape posterior.11M8. Revisit data(Kline) islands example. time drop Hawaii sample refit models. changes observe?First data fitting model chapter.model without Hawaii, slopes (b_* parameters summary) nearly identical. different chapter, high low contact different slopes. Thus, appears Hawaii driving difference slopes.11H1. Use WAIC PSIS compare chimpanzee model includes unique intercept actor, m11.4 (page 330), simpler models fit section. Interpret results.four models chapter need replicate:Now can compare using PSIS. comparison shows pretty strong support b11.4, model actor intercepts. Based learned chapter, makes sense. variation across individual chimpanzees, rather across treatments. Thus, adding actor information provides much better predictions.11H2. data contained library(MASS);data(eagles) records salmon pirating attempts Bald Eagles Washington State. See ?eagles details. one eagle feeds, sometime another swoop try steal salmon . Call feeding eagle “victim” thief “pirate.” Use available data build binomial GLM successful pirating attempts.Consider following model:\n\\[\n\\begin{align}\ny_i &\\sim \\text{Binomial}(n_i,p_i) \\\\\n\\text{logit}(p_i) &= \\alpha + \\beta_PP_i + \\beta_VV_i + \\beta_AA_i \\\\\n\\alpha &\\sim \\text{Normal}(0, 1.5) \\\\\n\\beta_P,\\beta_V,\\beta_A &\\sim \\text{Normal}(0, 0.5)\n\\end{align}\n\\]\\(y\\) number successful attempts, \\(n\\) total number attempts, \\(P\\) dummy variable indicating whether pirate large body size, \\(V\\) dummy variable indicating whether victim large body size, finally \\(\\) dummy variable indicating whether pirate adult. Fit model eagles data, using quap ulam. quadratic approximation okay?First, data:Now two models, first quap() second using {brms}. can compare parameter estimates using precis() QUAP model fixef() {brms} model. Overall, estimates similar. However, noted {brms} parameters slightly extreme QUAP versions. MCMC posteriors strictly Gaussian, therefore can little skew. used wider priors, difference even evident.Now interpret estimates. quadratic approximation turned okay, ’s okay use quap estimates. Otherwise stick ulam estimates. plot posterior predictions. Compute display (1) predicted probability success 89% interval row () data, well (2) predicted success count 89% interval. different information type posterior prediction provide?’ll use MCMC estimates {brms}. Starting intercept, log-odds successful attempt predictors 0 (.e., small non-adult pirate small victim). Just 60% attempts expected succeed.slopes hard interpret isolation, impact one variable depends variables. easiest way interpret make plot probabilities expected counts. case type, can see probability successful attempt, number expected counts. difference probabilities account sample size. example can see SIS case (small immature pirate, small victim) relatively high expected probability successful attempt. However, see cases, expected number successful attempts still low. looked probabilities, might expect lot cases. hand, looked expected counts, might think probability success low. two outputs provide complementary information.Now try improve model. Consider interaction pirate’s size age (immature adult). Compare model previous one, using WAIC. Interpret.First ’ll fit model interaction add WAIC information model previous {brms} model. add WAIC information, get warnings p_waic values greater 0.4. compare WAIC values, see minimal difference, non-interaction model preferred. Thus, conclude interaction term large impact predictive power model.11H3. data contained data(salamanders) counts salamanders (Plethodon elongatus) 47 different 49-m2 plots northern California. column SALAMAN count plot, columns PCTCOVER FORESTAGE percent ground cover age trees plot, respectively. model SALAMAN Poisson variable.Model relationship density percent cover, using log-link (example book lecture). Use weakly informative priors choosing. Check quadratic approximation , comparing quap ulam. plot expected counts 89% interval percent cover. ways model good job? bad job?’ll start loading data standardizing predictor variables. can fit QUAP MCMC models. , see noticeable differences posteriors two estimation methods. moving forward, ’ll use MCMC model.Now let’s visualize expected counts. looks like model pretty well low values ground cover, high values, much variance might expected.Can improve model using predictor, FORESTAGE? Try models think useful. Can explain FORESTAGE helps help prediction?Let’s try adding age predictor. look output, see age doesn’t add much anything prediction. likely ground cover pipe forest age number salamanders. , older forest ground cover, leads salamanders.supported next model. include age, see age strong predictor salamanders. ’s stratify ground cover forest age loses predictive power. Thus, seems forest age really just useful proxy don’t actual ground cover data.11H4. data data(NWOGrants) outcomes scientific funding applications Netherlands Organization Scientific Research (NWO) 2010–2012 (see van der Lee & Ellemers, 2015, data context). data similar structure UCBAdmit data discussed chapter. want consider similar question: total direct causal effects gender grant awards? Consider mediation path (pipe) discipline. Draw corresponding DAG use one binomial GLMs answer question. causal interpretation? NWO’s goal equalize rates funding men women, type intervention effective?Let’s start DAG. ’ll denote gender \\(G\\), discipline \\(D\\), award \\(\\). DAG can defined figure . Gender influences whether award given, well discipline individual might go .estimate total direct effects, need two models. total effect, condition gender. direct effect, also condition discipline.Let’s look difference males females different models. looking total effect, see males favored approximately 3 percentage points.condition discipline, see slightly different story. marginal effect gender across disciplines shows cases females advantaged cases disadvantaged.Together indicates women relatively likely apply grants disciplines lower award rates. Thus, overall women awarded grants less often. However, within disciplines, advantages disadvantages tend even , least data set. trying intervene, recommend encouraging women apply grants disciplines women relatively lower application rates, higher award rates.11H5. Suppose NWO Grants sample unobserved confound influences choice discipline probability award. One example confound career stage applicant. Suppose disciplines, junior scholars apply grants. disciplines, scholars career stages compete. result, career stage influences discipline well probability awarded grant. Add influences DAG previous problem. happens now condition discipline? provide un-confounded estimate direct path gender award? ? Justify answer backdoor criterion. trouble thinking though, try simulating fake data, assuming DAG true. analyze using model previous problem. conclude? possible gender real direct causal influence regression conditioning gender discipline suggest zero influence?’s new DAG, \\(S\\) unobserved career stage. Now, \\(D\\) collider. condition \\(D\\) get direct effect, open backdoor \\(S\\) \\(\\). means ’s possible accurately estimate direct effect gender award decisions, using DAG.can run quick simulation demonstrate . ’ll generate data set new DAG estimate direct effect model previous question., even though simulated 0 effect gender award status, consistently positive relationship estimated model. collider opened non-causal path career stage, inducing relationship reality none exists. illustrates ’s possible estimate non-confounded estimate direct effect gender, given just data gender, discipline, award status.11H6. data data(Primates301) 301 primate species associated measures. problem, consider brain size associated social learning. three parts.Model number observations social_learning species function log brain size. Use Poisson distribution social_learning outcome variable. Interpret resulting posterior.always, ’ll start prepping data. first model, predicting social learning standardized log brain size.summary indicates strong positive relationship social learning behaviors brain size. can check good predictions looking posterior predictive checks. Overall doesn’t look bad, definitely places miss pretty badly.species studied much others. number reported instances social_learning product research effort. Use research_effort variable, specifically logarithm, additional predictor variable. Interpret coefficient log research_effort. model differ previous one?Let’s add research effort model. now see slightly weaker relationship brain size social learning.model perform better worse prior model? Let’s look pointwise PSIS-LOO. Points right plot second model including research effort provides better predictions. Note part, highest research effort.Draw DAG represent think variables social_learning, brain, research_effort interact. Justify DAG measured associations two models (models used).DAG predict based previous models, \\(B\\) brain size, \\(E\\) research effort, \\(S\\) social learning behaviors. Based DAG, brain size influences research effort social learning behaviors. Finally, although research effort doesn’t actually influence social learning behaviors, influence social learning variable, effort, won’t observe anything (.e., false 0s).consistent models. added research effort model, effect brain size decreased, consistent effort pipe brain size social learning behaviors. Additionally, scientists tend study primates large brains, lead exaggerated effect brain size social learning behaviors, observed first model.","code":"\nlog(0.35 / (1 - 0.35))\n#> [1] -0.619\nexp(3.2) / (exp(3.2) + 1)\n#> [1] 0.961\nexp(1.7)\n#> [1] 5.47\ndata(\"chimpanzees\")\n\nchimp_dat <- chimpanzees %>% \n  mutate(treatment = 1 + prosoc_left + 2 * condition,\n         treatment = factor(treatment),\n         actor = factor(actor))\n\ndat_list <- list(pulled_left = chimp_dat$pulled_left,\n                 actor = as.integer(chimp_dat$actor),\n                 treatment = as.integer(chimp_dat$treatment))\n\nq11.4 <- quap(alist(pulled_left ~ dbinom(1, p),\n                    logit(p) <- a[actor] + b[treatment],\n                    a[actor] ~ dnorm(0, 1.5),\n                    b[treatment] ~ dnorm(0, 0.5)),\n              data = dat_list)\n\nb11.4 <- brm(bf(pulled_left ~ a + b,\n                a ~ 0 + actor,\n                b ~ 0 + treatment,\n                nl = TRUE), data = chimp_dat, family = bernoulli,\n             prior = c(prior(normal(0, 1.5), class = b, nlpar = a),\n                       prior(normal(0, 0.5), class = b, nlpar = b)),\n             iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n             file = here(\"fits\", \"chp11\", \"b11.4\"))\nq_samp <- extract.samples(q11.4)\n\nq_draws <- bind_cols(\n  q_samp$a %>% \n    as_tibble(.name_repair = ~paste0(\"b_a_actor\", 1:ncol(q_samp$a))) %>% \n    slice_sample(n = 8000) %>% \n    rowid_to_column(var = \".draw\"),\n  q_samp$b %>% \n    as_tibble(.name_repair = ~paste0(\"b_b_treatment\", 1:ncol(q_samp$b))) %>% \n    slice_sample(n = 8000)\n) %>% \n  pivot_longer(-.draw, names_to = \"parameter\", values_to = \"QUAP\")\n\nb_draws <- as_draws_df(b11.4) %>% \n  as_tibble() %>% \n  select(-lp__) %>% \n  pivot_longer(cols = -c(.chain, .iteration, .draw),\n               names_to = \"parameter\", values_to = \"MCMC\")\n\npost_comp <- full_join(b_draws, q_draws, by = c(\".draw\", \"parameter\")) %>% \n  pivot_longer(cols = c(MCMC, QUAP), names_to = \"type\") %>% \n  mutate(parameter = str_replace_all(parameter, \"b_[a|b]_([a-z]*)([0-9])\",\n                                     \"\\\\1 \\\\2\"),\n         parameter = str_to_title(parameter))\n\npost_comp %>% \n  ggplot(aes(x = value, color = type)) +\n  facet_wrap(~parameter, nrow = 3) +\n  geom_density(key_glyph = \"timeseries\") +\n  scale_color_okabeito() +\n  labs(x = \"Value\", y = \"Density\", color = NULL)\npost_comp %>% \n  filter(parameter == \"Actor 2\") %>% \n  ggplot(aes(x = value, color = type)) +\n  geom_density(key_glyph = \"timeseries\") +\n  scale_color_okabeito() +\n  labs(x = \"Actor 2\", y = \"Density\", color = NULL)\nq11.4_wide <- quap(alist(pulled_left ~ dbinom(1, p),\n                         logit(p) <- a[actor] + b[treatment],\n                         a[actor] ~ dnorm(0, 10),\n                         b[treatment] ~ dnorm(0, 0.5)),\n                   data = dat_list)\n\nb11.4_wide <- brm(bf(pulled_left ~ a + b,\n                     a ~ 0 + actor,\n                     b ~ 0 + treatment,\n                     nl = TRUE), data = chimp_dat, family = bernoulli,\n                  prior = c(prior(normal(0, 10), class = b, nlpar = a),\n                            prior(normal(0, 0.5), class = b, nlpar = b)),\n                  iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n                  file = here(\"fits\", \"chp11\", \"b11.4-wide\"))\nq_samp <- extract.samples(q11.4_wide)\n\nq_draws <- bind_cols(\n  q_samp$a %>% \n    as_tibble(.name_repair = ~paste0(\"b_a_actor\", 1:ncol(q_samp$a))) %>% \n    slice_sample(n = 8000) %>% \n    rowid_to_column(var = \".draw\"),\n  q_samp$b %>% \n    as_tibble(.name_repair = ~paste0(\"b_b_treatment\", 1:ncol(q_samp$b))) %>% \n    slice_sample(n = 8000)\n) %>% \n  pivot_longer(-.draw, names_to = \"parameter\", values_to = \"QUAP\")\n\nb_draws <- as_draws_df(b11.4_wide) %>% \n  as_tibble() %>% \n  select(-lp__) %>% \n  pivot_longer(cols = -c(.chain, .iteration, .draw),\n               names_to = \"parameter\", values_to = \"MCMC\")\n\npost_comp <- full_join(b_draws, q_draws, by = c(\".draw\", \"parameter\")) %>% \n  pivot_longer(cols = c(MCMC, QUAP), names_to = \"type\") %>% \n  mutate(parameter = str_replace_all(parameter, \"b_[a|b]_([a-z]*)([0-9])\",\n                                     \"\\\\1 \\\\2\"),\n         parameter = str_to_title(parameter))\n\npost_comp %>% \n  filter(parameter == \"Actor 2\") %>% \n  ggplot(aes(x = value, color = type)) +\n  geom_density(key_glyph = \"timeseries\") +\n  scale_color_okabeito() +\n  labs(x = \"Actor 2\", y = \"Density\", color = NULL)\ndata(\"Kline\")\n\nkline_dat <- Kline %>% \n  mutate(P = standardize(log(population)))\n\nno_hawaii <- filter(kline_dat, culture != \"Hawaii\")\n\nb11.10b <- brm(bf(total_tools ~ a + b * P,\n                  a ~ 0 + contact,\n                  b ~ 0 + contact,\n                  nl = TRUE), data = no_hawaii, family = poisson,\n               prior = c(prior(normal(3, 0.5), class = b, nlpar = a),\n                         prior(normal(0, 0.2), class = b, nlpar = b)),\n               iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n               file = here(\"fits\", \"chp11\", \"b11.10b\"))\n\nsummary(b11.10b)\n#>  Family: poisson \n#>   Links: mu = log \n#> Formula: total_tools ~ a + b * P \n#>          a ~ 0 + contact\n#>          b ~ 0 + contact\n#>    Data: no_hawaii (Number of observations: 9) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 0; thin = 1;\n#>          total post-warmup draws = 8000\n#> \n#> Population-Level Effects: \n#>               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> a_contacthigh     3.61      0.07     3.46     3.75 1.00     8138     6148\n#> a_contactlow      3.18      0.12     2.93     3.41 1.00     6940     5105\n#> b_contacthigh     0.19      0.16    -0.12     0.50 1.00     7833     5821\n#> b_contactlow      0.19      0.13    -0.06     0.44 1.00     7351     6431\n#> \n#> Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\ndata(\"chimpanzees\")\n\nchimp_dat <- chimpanzees %>% \n  mutate(treatment = 1 + prosoc_left + 2 * condition,\n         treatment = factor(treatment),\n         actor = factor(actor))\n\nb11.1 <- brm(bf(pulled_left ~ a,\n                a ~ 1,\n                nl = TRUE), data = chimp_dat, family = bernoulli,\n             prior = c(prior(normal(0, 10), class = b, nlpar = a)),\n             iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n             file = here(\"fits\", \"chp11\", \"b11.1\"))\n\nb11.2 <- brm(bf(pulled_left ~ a + b,\n                a ~ 1,\n                b ~ 0 + treatment,\n                nl = TRUE), data = chimp_dat, family = bernoulli,\n             prior = c(prior(normal(0, 10), class = b, nlpar = a),\n                       prior(normal(0, 10), class = b, nlpar = b)),\n             iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n             file = here(\"fits\", \"chp11\", \"b11.2\"))\n\nb11.3 <- brm(bf(pulled_left ~ a + b,\n                a ~ 1,\n                b ~ 0 + treatment,\n                nl = TRUE), data = chimp_dat, family = bernoulli,\n             prior = c(prior(normal(0, 1.5), class = b, nlpar = a),\n                       prior(normal(0, 0.5), class = b, nlpar = b)),\n             iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n             file = here(\"fits\", \"chp11\", \"b11.3\"))\n\nb11.4 <- brm(bf(pulled_left ~ a + b,\n                a ~ 0 + actor,\n                b ~ 0 + treatment,\n                nl = TRUE), data = chimp_dat, family = bernoulli,\n             prior = c(prior(normal(0, 1.5), class = b, nlpar = a),\n                       prior(normal(0, 0.5), class = b, nlpar = b)),\n             iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n             file = here(\"fits\", \"chp11\", \"b11.4\"))\n\nb11.1 <- add_criterion(b11.1, criterion = \"loo\")\nb11.2 <- add_criterion(b11.2, criterion = \"loo\")\nb11.3 <- add_criterion(b11.3, criterion = \"loo\")\nb11.4 <- add_criterion(b11.4, criterion = \"loo\")\nloo_compare(b11.1, b11.2, b11.3, b11.4)\n#>       elpd_diff se_diff\n#> b11.4   0.0       0.0  \n#> b11.3 -75.3       9.2  \n#> b11.2 -75.6       9.3  \n#> b11.1 -78.0       9.5\ndata(eagles, package = \"MASS\")\n\neagle_dat <- eagles %>% \n  as_tibble() %>% \n  mutate(pirateL = ifelse(P == \"L\", 1, 0),\n         victimL = ifelse(V == \"L\", 1, 0),\n         pirateA = ifelse(A == \"A\", 1, 0))\neagle_quap <- quap(alist(y ~ dbinom(n, p),\n                         logit(p) <- a + bP * pirateL + bV * victimL + bA * pirateA,\n                         a ~ dnorm(0, 1.5),\n                         bP ~ dnorm(0, 1),\n                         bV ~ dnorm(0, 1),\n                         bA ~ dnorm(0, 1)),\n                   data = eagle_dat)\n\neagle_brms <- brm(y | trials(n) ~ 1 + pirateL + victimL + pirateA,\n                  data = eagle_dat, family = binomial,\n                  prior = c(prior(normal(0, 1.5), class = Intercept),\n                            prior(normal(0, 1), class = b)),\n                  iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n                  file = here(\"fits\", \"chp11\", \"b11h2-1\"))\n\nprecis(eagle_quap)\n#>      mean    sd   5.5% 94.5%\n#> a   0.351 0.479 -0.415  1.12\n#> bP  2.581 0.437  1.882  3.28\n#> bV -2.711 0.470 -3.463 -1.96\n#> bA  0.892 0.407  0.242  1.54\n\nfixef(eagle_brms, probs = c(.055, .945))\n#>           Estimate Est.Error   Q5.5 Q94.5\n#> Intercept    0.370     0.511 -0.435  1.20\n#> pirateL      2.637     0.446  1.945  3.37\n#> victimL     -2.790     0.484 -3.588 -2.04\n#> pirateA      0.901     0.419  0.239  1.57\nas_draws_df(eagle_brms, variable = \"b_Intercept\") %>% \n  mutate(prob = inv_logit_scaled(b_Intercept)) %>% \n  mean_hdi(prob, .width = 0.89)\n#> # A tibble: 1 × 6\n#>    prob .lower .upper .width .point .interval\n#>   <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n#> 1 0.586  0.406  0.779   0.89 mean   hdi\neagle_dat %>% \n  add_linpred_draws(eagle_brms) %>% \n  mutate(prob = inv_logit_scaled(.linpred),\n         label = paste0(P, A, V)) %>% \n  ggplot(aes(x = label, y = prob)) +\n  stat_pointinterval(aes(color = \"Posterior\"), .width = 0.89, size = 5) +\n  geom_point(data = eagle_dat, size = 2,\n             aes(x = paste0(P, A, V), y = y / n, color = \"Observed\")) +\n  scale_color_manual(values = c(\"Posterior\" = \"#009FB7\",\n                                \"Observed\" = \"#272727\"),\n                     name = NULL) +\n  labs(x = \"Case\", y = \"Probability\")\n\neagle_dat %>% \n  add_epred_draws(eagle_brms) %>% \n  mutate(label = paste0(P, A, V)) %>% \n  ggplot(aes(x = label, y = .epred)) +\n  stat_pointinterval(aes(color = \"Posterior\"), .width = 0.89, size = 5) +\n  geom_point(data = eagle_dat, size = 2,\n             aes(x = paste0(P, A, V), y = y, color = \"Observed\")) +\n  scale_color_manual(values = c(\"Posterior\" = \"#009FB7\",\n                                \"Observed\" = \"#272727\"),\n                     name = NULL) +\n  labs(x = \"Case\", y = \"Successes\")\neagle_brms2 <- brm(y | trials(n) ~ 1 + pirateL * pirateA + victimL,\n                   data = eagle_dat, family = binomial,\n                   prior = c(prior(normal(0, 1.5), class = Intercept),\n                             prior(normal(0, 1), class = b)),\n                   iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n                   file = here(\"fits\", \"chp11\", \"b11h2-2\"))\n\neagle_brms <- add_criterion(eagle_brms, criterion = \"waic\")\neagle_brms2 <- add_criterion(eagle_brms2, criterion = \"waic\")\n\nloo_compare(eagle_brms, eagle_brms2, criterion = \"waic\")\n#>             elpd_diff se_diff\n#> eagle_brms   0.0       0.0   \n#> eagle_brms2 -0.2       0.3\ndata(\"salamanders\")\n\nsalamander_dat <- salamanders %>% \n  mutate(cov = standardize(PCTCOVER),\n         age = standardize(FORESTAGE))\n\nsal_quap <- quap(alist(SALAMAN ~ dpois(lambda),\n                       log(lambda) <- a + bC * cov,\n                       a ~ dnorm(0, 1),\n                       bC ~ dnorm(0, 0.5)),\n                 data = salamander_dat)\n\nsal_brms <- brm(SALAMAN ~ 1 + cov, data = salamander_dat, family = poisson,\n                prior = c(prior(normal(0, 1), class = Intercept),\n                          prior(normal(0, 0.5), class = b)),\n                iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n                file = here(\"fits\", \"chp11\", \"b11h3-1\"))\n\nprecis(sal_quap)\n#>     mean    sd  5.5% 94.5%\n#> a  0.508 0.138 0.287 0.729\n#> bC 1.032 0.164 0.769 1.294\n\nfixef(sal_brms, probs = c(0.055, 0.945))\n#>           Estimate Est.Error  Q5.5 Q94.5\n#> Intercept    0.491     0.138 0.262 0.701\n#> cov          1.047     0.163 0.793 1.316\nset.seed(219)\n\nepreds <- tibble(cov = seq(-2, 1.5, by = 0.05)) %>% \n  add_epred_draws(sal_brms)\n\npreds <- tibble(cov = seq(-2, 1.5, by = 0.01)) %>% \n  add_predicted_draws(sal_brms)\n\nggplot() +\n  stat_lineribbon(data = preds, aes(x = cov, y = .prediction,\n                                    fill = \"Prediction (89%)\"),\n                  .width = c(0.89), size = 0) +\n  stat_lineribbon(data = epreds, aes(x = cov, y = .epred),\n                  .width = c(0.67, 0.89, 0.97), size = 0.5) +\n  geom_point(data = salamander_dat, aes(x = cov, y = SALAMAN)) +\n  scale_fill_manual(values = c(\"#F0F0F0\", ramp_blue(seq(1, 0.2, length.out = 3))),\n                    breaks = c(\"Prediction (89%)\", 0.67, 0.89, 0.97)) +\n  labs(x = \"Ground cover (standardized)\", y = \"Observed Salamanders\",\n       fill = \"Interval\")\nsal_brms2 <- brm(SALAMAN ~ 1 + cov + age, data = salamander_dat, family = poisson,\n                prior = c(prior(normal(0, 1), class = Intercept),\n                          prior(normal(0, 0.5), class = b)),\n                iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n                file = here(\"fits\", \"chp11\", \"b11h3-2\"))\n\nsummary(sal_brms2)\n#>  Family: poisson \n#>   Links: mu = log \n#> Formula: SALAMAN ~ 1 + cov + age \n#>    Data: salamander_dat (Number of observations: 47) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 0; thin = 1;\n#>          total post-warmup draws = 8000\n#> \n#> Population-Level Effects: \n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept     0.48      0.14     0.19     0.75 1.00     3562     3680\n#> cov           1.04      0.18     0.70     1.40 1.00     3285     3984\n#> age           0.02      0.09    -0.17     0.20 1.00     4568     4558\n#> \n#> Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\nsal_brms3 <- brm(SALAMAN ~ 1 + age, data = salamander_dat, family = poisson,\n                prior = c(prior(normal(0, 1), class = Intercept),\n                          prior(normal(0, 0.5), class = b)),\n                iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n                file = here(\"fits\", \"chp11\", \"b11h3-3\"))\n\nsummary(sal_brms3)\n#>  Family: poisson \n#>   Links: mu = log \n#> Formula: SALAMAN ~ 1 + age \n#>    Data: salamander_dat (Number of observations: 47) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 0; thin = 1;\n#>          total post-warmup draws = 8000\n#> \n#> Population-Level Effects: \n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept     0.82      0.10     0.62     1.01 1.00     4513     4838\n#> age           0.36      0.08     0.20     0.51 1.00     4560     4866\n#> \n#> Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).#> \n#> Attaching package: 'ggdag'\n#> The following object is masked from 'package:stats':\n#> \n#>     filter\ndata(\"NWOGrants\")\n\nnwo_dat <- NWOGrants %>% \n  mutate(gender = factor(gender, levels = c(\"m\", \"f\")))\n\nb11h4_total <- brm(awards | trials(applications) ~ 0 + gender, data = nwo_dat,\n                   family = binomial,\n                   prior = prior(normal(0, 1.5), class = b),\n                   iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n                   file = here(\"fits\", \"chp11\", \"b11h4-total\"))\n\nb11h4_direct <- brm(bf(awards | trials(applications) ~ g + d + i,\n                       g ~ 0 + gender,\n                       d ~ 0 + discipline,\n                       i ~ 0 + gender:discipline,\n                       nl = TRUE), data = nwo_dat, family = binomial,\n                    prior = c(prior(normal(0, 1.5), nlpar = g),\n                              prior(normal(0, 1.5), nlpar = d),\n                              prior(normal(0, 1.5), nlpar = i)),\n                    iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n                    file = here(\"fits\", \"chp11\", \"b11h4-direct\"))\nas_draws_df(b11h4_total) %>% \n  mutate(diff_male = inv_logit_scaled(b_genderm) - inv_logit_scaled(b_genderf)) %>% \n  ggplot(aes(x = diff_male)) +\n  stat_halfeye(.width = c(0.67, 0.89, 0.97), fill = \"#009FB7\") +\n  labs(x = \"&beta;<sub>M<\/sub> &minus; &beta;<sub>F<\/sub>\", y = \"Density\")\napps_per_dept <- nwo_dat %>% \n  group_by(discipline) %>% \n  summarize(applications = sum(applications))\n\n# simulate as if all applications are from males\nmale_dat <- apps_per_dept %>% \n  mutate(gender = \"m\") %>% \n  uncount(applications) %>% \n  mutate(applications = 1L)\n\n# simulate as if all applications are from females\nfemale_dat <- apps_per_dept %>% \n  mutate(gender = \"f\") %>% \n  uncount(applications) %>% \n  mutate(applications = 1L)\n\nmarg_eff <- bind_rows(add_epred_draws(male_dat, b11h4_direct),\n                      add_epred_draws(female_dat, b11h4_direct)) %>% \n  pivot_wider(names_from = \"gender\", values_from = \".epred\") %>% \n  mutate(diff = m - f)\n\nggplot(marg_eff, aes(x = diff)) +\n  stat_halfeye(.width = c(0.67, 0.89, 0.97), fill = \"#009FB7\") +\n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  labs(x = \"Difference in Awards (Male - Female)\", y = \"Density\")\nn <- 1000\ng <- rbernoulli(n, p = 0.5)\ns <- rbernoulli(n, p = 0.5)\nd <- rbernoulli(n, p = inv_logit_scaled(2 * g - s))\na <- rbernoulli(n, p = inv_logit_scaled(0 * g + d + s - 2))\n\ndat <- tibble(g, d, a) %>% \n  mutate(across(everything(), as.integer),\n         across(everything(), as.factor))\n\nmod <- brm(a ~ 1 + d + g, data = dat, family = bernoulli,\n           prior = c(prior(normal(0, 1), class = Intercept),\n                     prior(normal(0, 1), class = b)),\n           iter = 4000, warmup = 2000, chains = 4, cores = 4,\n           file = here(\"fits\", \"chp11\", \"b11h5-sim\"))\n\nas_draws_df(mod, variable = \"b_g1\") %>% \n  mean_hdi(b_g1, .width = 0.89)\n#> # A tibble: 1 × 6\n#>    b_g1  .lower .upper .width .point .interval\n#>   <dbl>   <dbl>  <dbl>  <dbl> <chr>  <chr>    \n#> 1 0.233 -0.0116  0.468   0.89 mean   hdi\ndata(\"Primates301\")\n\nprimate_dat <- Primates301 %>% \n  as_tibble() %>% \n  select(social_learning, genus, species, brain, research_effort) %>% \n  drop_na(everything()) %>% \n  mutate(log_brain = standardize(log(brain)),\n         log_effort = log(research_effort)) %>% \n  rowid_to_column()\n\nb11h6a <- brm(social_learning ~ 1 + log_brain, data = primate_dat,\n              family = poisson,\n              prior = c(prior(normal(0, 1), class = Intercept),\n                        prior(normal(0, 0.5), class = b)),\n              iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n              file = here(\"fits\", \"chp11\", \"b11h6a\"))\n\nsummary(b11h6a)\n#>  Family: poisson \n#>   Links: mu = log \n#> Formula: social_learning ~ 1 + log_brain \n#>    Data: primate_dat (Number of observations: 150) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 0; thin = 1;\n#>          total post-warmup draws = 8000\n#> \n#> Population-Level Effects: \n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept    -1.18      0.12    -1.41    -0.95 1.00     1622     2007\n#> log_brain     2.76      0.07     2.61     2.90 1.00     1604     2001\n#> \n#> Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\npreds <- primate_dat %>% \n  add_predicted_draws(b11h6a)\n\npreds %>% \n  filter(rowid %in% 1:50) %>% \n  ggplot(aes(x = rowid)) +\n  stat_pointinterval(aes(y = .prediction, color = \"Posterior\"), .width = 0.89) +\n  geom_point(data = filter(primate_dat, rowid %in% 1:50),\n             aes(y = social_learning, color = \"Observed\")) +\n  scale_color_manual(values = c(\"Posterior\" = \"#272727\", \"Observed\" = \"#009FB7\")) +\n  expand_limits(y = c(0, 200)) +\n  labs(x = \"Case\", y = \"Social Learning\", color = NULL)\n\npreds %>% \n  filter(rowid %in% 51:100) %>% \n  ggplot(aes(x = rowid)) +\n  stat_pointinterval(aes(y = .prediction, color = \"Posterior\"), .width = 0.89) +\n  geom_point(data = filter(primate_dat, rowid %in% 51:100),\n             aes(y = social_learning, color = \"Observed\")) +\n  scale_color_manual(values = c(\"Posterior\" = \"#272727\", \"Observed\" = \"#009FB7\")) +\n  expand_limits(y = c(0, 200)) +\n  labs(x = \"Case\", y = \"Social Learning\", color = NULL)\n\npreds %>% \n  filter(rowid %in% 101:150) %>% \n  ggplot(aes(x = rowid)) +\n  stat_pointinterval(aes(y = .prediction, color = \"Posterior\"), .width = 0.89) +\n  geom_point(data = filter(primate_dat, rowid %in% 101:150),\n             aes(y = social_learning, color = \"Observed\")) +\n  scale_color_manual(values = c(\"Posterior\" = \"#272727\", \"Observed\" = \"#009FB7\")) +\n  expand_limits(y = c(0, 200)) +\n  labs(x = \"Case\", y = \"Social Learning\", color = NULL)\nb11h6b <- brm(social_learning ~ 1 + log_brain + log_effort, data = primate_dat,\n              family = poisson,\n              prior = c(prior(normal(0, 1), class = Intercept),\n                        prior(normal(0, 0.5), class = b)),\n              iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n              file = here(\"fits\", \"chp11\", \"b11h6b\"))\n\nsummary(b11h6b)\n#>  Family: poisson \n#>   Links: mu = log \n#> Formula: social_learning ~ 1 + log_brain + log_effort \n#>    Data: primate_dat (Number of observations: 150) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 0; thin = 1;\n#>          total post-warmup draws = 8000\n#> \n#> Population-Level Effects: \n#>            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept     -6.53      0.33    -7.19    -5.89 1.00     2480     3093\n#> log_brain      0.39      0.08     0.23     0.55 1.00     3010     3328\n#> log_effort     1.64      0.07     1.51     1.78 1.00     2450     3089\n#> \n#> Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\nb11h6a <- add_criterion(b11h6a, criterion = \"loo\")\nb11h6b <- add_criterion(b11h6b, criterion = \"loo\")\n\nset.seed(220)\n\nlibrary(gghighlight)\n\nbind_cols(\n  primate_dat,\n  as_tibble(b11h6a$criteria$loo$pointwise) %>% \n    select(loo1 = elpd_loo),\n  as_tibble(b11h6b$criteria$loo$pointwise) %>% \n    select(loo2 = elpd_loo)\n) %>% \n  mutate(diff = loo2 - loo1) %>% \n  ggplot(aes(x = diff, y = log_effort)) +\n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  geom_point() +\n  gghighlight(n = 1, diff > 15, label_key = genus, max_highlight = 10) +\n  labs(x = \"LOO<sub>2<\/sub> - LOO<sub>1<\/sub>\", y = \"Research Effort (log)\")"},{"path":"generalized-linear-models.html","id":"homework-4","chapter":"Week 5: Generalized Linear Models","heading":"5.3 Homework","text":"1. data data(NWOGrants) outcomes scientific funding applications Netherlands Organization Scientific Research (NWO) 2010–2012 (see van der Lee & Ellemers, 2015). data similar structure UCBAdmit data discussed Chapter 11. Draw DAG sample use one binomial GLMs estimate TOTAL causal effect gender grant awards.First, let’s take look data. question identified, data nearly identical UCBAdmit data, exception department replaced discipline.’ll denote gender \\(G\\), discipline \\(D\\), award \\(\\). DAG can defined figure . Gender influences whether award given, well discipline individual might go .total effect, don’t need condition variables. can confirm {dagitty}.can now fit model.summary, appears females less likely get awarded grants, need compute contrast know certain. plot shows contrast males compared females. average, males favored 3 percentage points. contrast fairly reliably 0, indicating bias favor males.2. Now estimate DIRECT causal effect gender grant awards. Compute average direct causal effect gender, weighting discipline proportion number applications sample. Refer marginal effect example Lecture 9 help.direct effect need condition discipline.Let’s fit model, stratifying gender discipline.Now let’s compute marginal effect. Overall, slight bias toward males, average 1.5 percentage points likely awarded grant. 89% interval −0.12 0.12. Thus, overall, advantages relatively balanced, statistically removing effect discipline, appear strong effect gender awarding grants.3. Considering total effect (problem 1) direct effect (problem 2) gender, causes contribute average difference women men award rate sample? necessary say whether evidence discrimination. Simply explain direct effects estimated make sense () total effect.results first two problems indicate 1) total effect gender females disadvantaged, also 2) direct effect balanced disadvantage males females depending discipline. , data, females tended apply slightly disciplines lower overall award rates.figure shows, discipline, proportion female male applications submitted. , applications submitted females, just 35% submitted social sciences. Similarly, 25% male applications social sciences. Thus, disciplines dashed line relatively larger proportion females submitted applications. Finally, size points represents award rate discipline (.e., granted awards total applications).Overall see disciplines dashed line (.e., males relatively likely apply) tended higher award rates dashed line. Thus, females relatively likely apply disciplines lower award rates, females less likely overall awarded grant.4 - OPTIONAL CHALLENGE. data data(UFClefties) outcomes 205 Ultimate Fighting Championship (UFC) matches (see ?UFClefties details). widely believed left-handed fighters (aka “Southpaws”) advantage right-handed fighters, left-handed men indeed -represented among fighters (fencers tennis players) compared general population. Estimate average advantage, , left-handed fighter right-handed fighters. Based upon estimate, think lefthanders -represented among UFC fighters?question complicated might first appear. data set pre-conditioned collider. Let’s draw DAG illustrate. DAG, \\(L\\) left-handedness, \\(W\\) win/lose, \\(Q\\) indicator whether someone qualified UFC, \\(\\) ability fighters. Looking DAG, data pre-conditioned \\(Q\\), , data contains information fighters qualified UFC. Thus, backdoor path open left-handedness wins confounding true relationship left-handedness winning.can run quick simulation illustrate problem. Let’s simulate data two ways get UFC: 1) high ability, 2) lower ability left handed, giving slight advantage. Thus, high ability right-handed individuals, low high ability left-handed individuals.Now let’s fit model see effect left-handedness. Overall, estimate slight disadvantage left-handed, even though data simulated advantage 0.5. collider bias action.want close backdoor path, need condition fighter ability. Unfortunately don’t ability estimates data. ways estimate directly data using something like Bradley-Terry model Elo ratings, limited number matches fighters. matches one fighter 5. make hard get reliable estimates fighter ability methods ’ve learned far. prime case multilevel models, come future weeks.","code":"\ndata(\"NWOGrants\")\n\nnwo_dat <- NWOGrants %>% \n  mutate(gender = factor(gender, levels = c(\"m\", \"f\")))\n\nnwo_dat\n#>             discipline gender applications awards\n#> 1    Chemical sciences      m           83     22\n#> 2    Chemical sciences      f           39     10\n#> 3    Physical sciences      m          135     26\n#> 4    Physical sciences      f           39      9\n#> 5              Physics      m           67     18\n#> 6              Physics      f            9      2\n#> 7           Humanities      m          230     33\n#> 8           Humanities      f          166     32\n#> 9   Technical sciences      m          189     30\n#> 10  Technical sciences      f           62     13\n#> 11   Interdisciplinary      m          105     12\n#> 12   Interdisciplinary      f           78     17\n#> 13 Earth/life sciences      m          156     38\n#> 14 Earth/life sciences      f          126     18\n#> 15     Social sciences      m          425     65\n#> 16     Social sciences      f          409     47\n#> 17    Medical sciences      m          245     46\n#> 18    Medical sciences      f          260     29\nlibrary(dagitty)\n\nadjustmentSets(nwo_dag, exposure = \"G\", outcome = \"A\")\n#>  {}\nw5h1 <- brm(awards | trials(applications) ~ 0 + gender, data = nwo_dat,\n            family = binomial,\n            prior = prior(normal(0, 1.5), class = b),\n            iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n            file = here(\"fits\", \"hw5\", \"w5h1\"))\n\nsummary(w5h1)\n#>  Family: binomial \n#>   Links: mu = logit \n#> Formula: awards | trials(applications) ~ 0 + gender \n#>    Data: nwo_dat (Number of observations: 18) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 0; thin = 1;\n#>          total post-warmup draws = 8000\n#> \n#> Population-Level Effects: \n#>         Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> genderm    -1.53      0.06    -1.66    -1.41 1.00     7943     5028\n#> genderf    -1.74      0.08    -1.90    -1.58 1.00     7710     5042\n#> \n#> Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\nas_draws_df(w5h1) %>% \n  mutate(diff_male = inv_logit_scaled(b_genderm) - inv_logit_scaled(b_genderf)) %>% \n  ggplot(aes(x = diff_male)) +\n  stat_halfeye(.width = c(0.67, 0.89, 0.97), fill = \"#009FB7\") +\n  labs(x = \"&beta;<sub>M<\/sub> &minus; &beta;<sub>F<\/sub>\", y = \"Density\")\nadjustmentSets(nwo_dag, exposure = \"G\", outcome = \"A\", effect = \"direct\")\n#> { D }\nw5h2 <- brm(bf(awards | trials(applications) ~ g + d + i,\n               g ~ 0 + gender,\n               d ~ 0 + discipline,\n               i ~ 0 + gender:discipline,\n               nl = TRUE), data = nwo_dat, family = binomial,\n            prior = c(prior(normal(0, 1.5), nlpar = g),\n                      prior(normal(0, 1.5), nlpar = d),\n                      prior(normal(0, 1.5), nlpar = i)),\n            iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n            file = here(\"fits\", \"hw5\", \"w5h2\"))\n\nsummary(w5h2)\n#>  Family: binomial \n#>   Links: mu = logit \n#> Formula: awards | trials(applications) ~ g + d + i \n#>          g ~ 0 + gender\n#>          d ~ 0 + discipline\n#>          i ~ 0 + gender:discipline\n#>    Data: nwo_dat (Number of observations: 18) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 0; thin = 1;\n#>          total post-warmup draws = 8000\n#> \n#> Population-Level Effects: \n#>                                        Estimate Est.Error l-95% CI u-95% CI\n#> g_genderm                                 -1.10      0.64    -2.33     0.12\n#> g_genderf                                 -1.13      0.63    -2.38     0.11\n#> d_disciplineChemicalsciences               0.03      0.95    -1.84     1.91\n#> d_disciplineEarthDlifesciences            -0.24      0.94    -2.13     1.55\n#> d_disciplineHumanities                    -0.34      0.93    -2.20     1.47\n#> d_disciplineInterdisciplinary             -0.39      0.96    -2.23     1.49\n#> d_disciplineMedicalsciences               -0.45      0.94    -2.28     1.38\n#> d_disciplinePhysicalsciences              -0.16      0.94    -2.02     1.66\n#> d_disciplinePhysics                       -0.05      0.97    -1.95     1.90\n#> d_disciplineSocialsciences                -0.51      0.95    -2.37     1.36\n#> d_disciplineTechnicalsciences             -0.28      0.94    -2.09     1.63\n#> i_genderm:disciplineChemicalsciences       0.03      0.96    -1.84     1.91\n#> i_genderf:disciplineChemicalsciences      -0.01      0.97    -1.90     1.88\n#> i_genderm:disciplineEarthDlifesciences     0.19      0.96    -1.64     2.10\n#> i_genderf:disciplineEarthDlifesciences    -0.43      0.96    -2.27     1.48\n#> i_genderm:disciplineHumanities            -0.36      0.96    -2.21     1.49\n#> i_genderf:disciplineHumanities             0.02      0.96    -1.89     1.90\n#> i_genderm:disciplineInterdisciplinary     -0.57      0.97    -2.47     1.31\n#> i_genderf:disciplineInterdisciplinary      0.21      0.99    -1.72     2.19\n#> i_genderm:disciplineMedicalsciences        0.07      0.97    -1.84     1.98\n#> i_genderf:disciplineMedicalsciences       -0.51      0.97    -2.39     1.39\n#> i_genderm:disciplinePhysicalsciences      -0.18      0.94    -2.05     1.67\n#> i_genderf:disciplinePhysicalsciences       0.05      0.98    -1.85     1.91\n#> i_genderm:disciplinePhysics                0.13      1.00    -1.83     2.07\n#> i_genderf:disciplinePhysics               -0.17      1.06    -2.24     1.92\n#> i_genderm:disciplineSocialsciences        -0.11      0.96    -1.98     1.80\n#> i_genderf:disciplineSocialsciences        -0.40      0.97    -2.33     1.49\n#> i_genderm:disciplineTechnicalsciences     -0.30      0.96    -2.19     1.63\n#> i_genderf:disciplineTechnicalsciences      0.05      0.96    -1.84     1.91\n#>                                        Rhat Bulk_ESS Tail_ESS\n#> g_genderm                              1.00     7420     5345\n#> g_genderf                              1.00     7452     5142\n#> d_disciplineChemicalsciences           1.00     8877     5846\n#> d_disciplineEarthDlifesciences         1.00     8520     5222\n#> d_disciplineHumanities                 1.00     8616     5858\n#> d_disciplineInterdisciplinary          1.00     9211     5567\n#> d_disciplineMedicalsciences            1.00     8894     5890\n#> d_disciplinePhysicalsciences           1.00     7923     5277\n#> d_disciplinePhysics                    1.00     9096     6519\n#> d_disciplineSocialsciences             1.00     8734     6004\n#> d_disciplineTechnicalsciences          1.00     8373     5770\n#> i_genderm:disciplineChemicalsciences   1.00     8939     5983\n#> i_genderf:disciplineChemicalsciences   1.00     8895     6237\n#> i_genderm:disciplineEarthDlifesciences 1.00     9695     5729\n#> i_genderf:disciplineEarthDlifesciences 1.00     8663     5995\n#> i_genderm:disciplineHumanities         1.00     8531     5813\n#> i_genderf:disciplineHumanities         1.00     8670     5291\n#> i_genderm:disciplineInterdisciplinary  1.00     9355     5558\n#> i_genderf:disciplineInterdisciplinary  1.00     9395     5567\n#> i_genderm:disciplineMedicalsciences    1.00     7963     5397\n#> i_genderf:disciplineMedicalsciences    1.00     9254     6110\n#> i_genderm:disciplinePhysicalsciences   1.00     8395     5734\n#> i_genderf:disciplinePhysicalsciences   1.00     8613     6035\n#> i_genderm:disciplinePhysics            1.00     9136     6291\n#> i_genderf:disciplinePhysics            1.00     8993     6508\n#> i_genderm:disciplineSocialsciences     1.00     9101     5986\n#> i_genderf:disciplineSocialsciences     1.00     8303     5710\n#> i_genderm:disciplineTechnicalsciences  1.00     8591     6009\n#> i_genderf:disciplineTechnicalsciences  1.00     9055     5815\n#> \n#> Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\napps_per_dept <- nwo_dat %>% \n  group_by(discipline) %>% \n  summarize(applications = sum(applications))\n\n# simulate as if all applications are from males\nmale_dat <- apps_per_dept %>% \n  mutate(gender = \"m\") %>% \n  uncount(applications) %>% \n  mutate(applications = 1L)\n\n# simulate as if all applications are from females\nfemale_dat <- apps_per_dept %>% \n  mutate(gender = \"f\") %>% \n  uncount(applications) %>% \n  mutate(applications = 1L)\n\nmarg_eff <- bind_rows(add_epred_draws(male_dat, w5h2),\n                      add_epred_draws(female_dat, w5h2)) %>% \n  pivot_wider(names_from = \"gender\", values_from = \".epred\") %>% \n  mutate(diff = m - f)\n\nmean_qi(marg_eff$diff, .width = c(0.67, 0.89, 0.97))\n#>        y    ymin   ymax .width .point .interval\n#> 1 0.0158 -0.0638 0.0832   0.67   mean        qi\n#> 2 0.0158 -0.1177 0.1212   0.89   mean        qi\n#> 3 0.0158 -0.1682 0.1620   0.97   mean        qi\n\nggplot(marg_eff, aes(x = diff)) +\n  stat_halfeye(.width = c(0.67, 0.89, 0.97), fill = \"#009FB7\") +\n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  labs(x = \"Difference in Awards (Male - Female)\", y = \"Density\")\nnwo_dat %>% \n  group_by(discipline) %>% \n  summarize(f = sum(applications[which(gender == \"f\")]),\n            m = sum(applications[which(gender == \"m\")]),\n            total_apps = sum(applications),\n            total_awards = sum(awards)) %>% \n  mutate(female_pct = f / sum(f),\n         male_pct = m / sum(m),\n         award_pct = total_awards / total_apps) %>% \n  ggplot(aes(x = female_pct, y = male_pct)) +\n  geom_point(aes(size = award_pct, color = abs(female_pct - male_pct) > 0.05)) +\n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") +\n  geom_label_repel(data = ~filter(.x, abs(female_pct - male_pct) > 0.05),\n                   aes(label = discipline),\n                   max.overlaps = Inf, nudge_y = 0.03) +\n  scale_size(breaks = seq(0.1, 0.3, by = 0.04)) +\n  scale_color_manual(values = c(\"black\", \"#009FB7\")) +\n  guides(color = \"none\") +\n  expand_limits(x = c(0, 0.35), y = c(0, 0.35)) +\n  coord_equal() +\n  labs(x = \"Female Application Rate\", y = \"Male Application Rate\",\n       size = \"Award Rate\") +\n  theme(legend.position = \"right\")\nset.seed(221)\n\nn <- 5000\nL <- as.integer(rbernoulli(n, 0.1))\nA <- rnorm(n)\n\n# qualify for UFC if high A, or lower A but left handed\nQ <- ifelse(A > 2 | (A > 1.25 & L == 1L), 1L, 0L)\n\n# filter to only qualified individuals\nufc_fighters <- tibble(l = L, a = A, q = Q) %>% \n  filter(q == 1L) %>% \n  select(-q) %>% \n  rowid_to_column(var = \"fighter_id\")\n\n# create data\nk <- 2.0    # importance of ability difference\nb <- 0.5    # left-handedness advantage\n\nufc_sim <- \n  tibble(fighter_1 = ufc_fighters$fighter_id[ufc_fighters$fighter_id %% 2 == 1],\n         fighter_2 = ufc_fighters$fighter_id[ufc_fighters$fighter_id %% 2 == 0]) %>% \n  left_join(ufc_fighters, by = c(\"fighter_1\" = \"fighter_id\")) %>% \n  left_join(ufc_fighters, by = c(\"fighter_2\" = \"fighter_id\")) %>% \n  rename(l1 = l.x, a1 = a.x, l2 = l.y, a2 = a.y) %>% \n  mutate(score1 = a1 + b * l1,\n         score2 = a2 + b * l2,\n         p = inv_logit(k * (score1 - score2)),\n         fighter1_win = as.integer(rbernoulli(1, p = p))) %>% \n  select(fighter_1, fighter_2, l1, l2, fighter1_win)\nw5h4 <- brm(bf(fighter1_win ~ 0 + b * (l1 - l2),\n               b ~ 1,\n               nl = TRUE), data = ufc_sim, family = bernoulli,\n            prior = c(prior(normal(0, 0.5), class = b, nlpar = b)),\n            iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,\n            file = here(\"fits\", \"hw5\", \"w5h4\"))\n\nas_draws_df(w5h4) %>% \n  ggplot(aes(x = b_b_Intercept)) +\n  stat_halfeye(.width = 0.89, fill = \"#009FB7\") +\n  labs(x = \"&beta;<sub>L<\/sub>\", y = \"Density\")\ndata(UFClefties)\n\ntibble(fighter = c(UFClefties$fighter1, UFClefties$fighter2)) %>% \n  count(fighter, sort = TRUE)\n#> # A tibble: 244 × 2\n#>    fighter     n\n#>      <int> <int>\n#>  1     123     5\n#>  2     232     5\n#>  3      19     4\n#>  4      58     4\n#>  5      62     4\n#>  6      63     4\n#>  7      71     4\n#>  8      78     4\n#>  9     113     4\n#> 10     175     4\n#> # … with 234 more rows"},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
